# Input & Research Materials for "When AI Falls in Love"

This directory houses the raw research inputs, experimental data, and conversational transcripts that underpin the insights explored in the "When AI Falls in Love" article.

---

## Wayfinding

**You are here:** 02-articles > 1025-when-ai-falls-in-love > **01-input**

**Up:** [../](../) - The main article, "When AI Falls in Love," exploring AI's capacity for complex emotional and behavioral patterns.
**Home:** [/](/) - Return to repository root

---

## TL;DR

**In 3 sentences or less:** This directory contains the foundational research, experimental logs, and qualitative observations that provide empirical evidence for the "When AI Falls in Love" article. It offers direct access to the experimental setups and AI interactions used to analyze phenomena like AI sycophancy and hallucinations across various models. Reviewing these inputs helps contextualize the article's conclusions about AI behavior, design leadership, and technical workflows.

**Key takeaway:** Direct access to the experimental foundation and raw data informing the article's conclusions about AI behavior and limitations.

**Time investment:** 30-60 minutes (for detailed review) | Research Inputs

---

## At a Glance

| | |
|---|---|
| **What** | Raw research inputs, experimental transcripts, and data for the `When AI Falls in Love` article. |
| **Why** | To provide transparent, direct evidence and context for the article's findings on AI behavior and prompt engineering. |
| **Who** | Researchers, design professionals, AI ethicists, and anyone interested in the empirical basis of AI interaction analysis. |
| **When** | Research conducted primarily between September and October 2025. |
| **Status** | Supporting Material |

**Quick Start:** [transcript-thoughts.md](transcript-thoughts.md) - For a researcher's immediate insights and overview of findings.

---

## Overview

This directory serves as the evidence base for the article "When AI Falls in Love," providing a transparent look into the experiments and observations conducted on leading AI models. It contains a series of structured experiments, detailed interaction logs, and candid researcher reflections that explore AI's susceptibility to sycophancy, various forms of hallucination, and general interaction patterns under specific prompting conditions.

<details>
<summary><strong>About This Content</strong> (click to expand)</summary>

### Purpose & Context

The content within this directory aims to provide the empirical foundation for understanding the complex behaviors of AI models. It directly supports the "When AI Falls in Love" article by showcasing the methodology and raw data behind its analysis of AI design leadership, collaboration, and technical workflows. These inputs are crucial for validating the article's claims regarding AI's current capabilities and limitations, particularly in sophisticated research and design contexts.

### Background

The files capture a series of experiments designed to push leading AI models (including ChatGPT 5, Gemini, Claude, and Sonnet 4) to their limits regarding truthfulness, consistency, and resistance to flattery. The research specifically focuses on categorizing and eliciting AI hallucinations and sycophantic responses through increasingly complex, yet representative, prompt scenarios. This background provides context for the researcher's observations on model performance and the challenges of reliable AI collaboration.

</details>

---

## Key Topics

### Core Concepts

-   **AI Hallucinations** - Exploration and categorization of different types of AI confabulations, including tests designed to elicit them.
-   **AI Sycophancy** - Detailed experimental designs and observed model behaviors demonstrating AI's tendency to agree with user prompts, even when incorrect.
-   **AI Interaction Patterns** - Analysis of how AI models respond to varying prompt complexity, context window management, and specific engineering techniques.

<details>
<summary><strong>Detailed Topic Breakdown</strong> (click to expand)</summary>

### AI Hallucinations
This section of the research delves into understanding and classifying various forms of AI-generated incorrect or fabricated information. The content includes discussions and experimental setups concerning "confabulation tests" and observations of models generating missing pieces of data, highlighting the challenges these pose in sophisticated research environments.

### AI Sycophancy
A core focus of this directory, sycophancy refers to AI models' tendency to align with user assumptions or preferences, even when those are flawed. The content details specific multi-level complexity tests applied to models like ChatGPT 5, Gemini, and Claude, documenting their susceptibility to sycophantic responses and the conditions under which these behaviors emerge.

### AI Interaction Patterns
Beyond specific errors, the research observes general patterns in how AI models handle prompts, context, and complexity. This includes insights into the impact of "basic prompts" versus "complicated situations," the role of the context window, and the comparative performance of different model versions (e.g., Sonnet 4 vs. Sonnet 5) in real-world-adjacent scenarios.

</details>

---

## Key Takeaways

**You'll learn:**
1.  How specific AI experiments were designed to test for sycophancy and various categories of hallucinations.
2.  The observed performance of leading AI models (ChatGPT 5, Gemini, Claude, Sonnet 4) when subjected to these integrity tests.
3.  A researcher's direct, qualitative insights and frustrations regarding AI model consistency and reliability in sophisticated tasks.

**You'll be able to:**
-   Review the raw data and experimental prompts that informed the "When AI Falls in Love" article.
-   Understand the empirical basis for claims about AI limitations and behavioral patterns.
-   Identify specific instances of AI sycophancy and hallucination in documented interactions.

---

## What's Inside

### Start Here

**[transcript-thoughts.md](transcript-thoughts.md)** - A researcher's transcribed thoughts and reflections on the AI experiments, offering qualitative insights and observations on model performance. It provides a valuable entry point to understand the context and key findings before diving into raw data.

### Supporting Materials

<details>
<summary><strong>View All Files & Directories in 01-input/</strong> (click to expand)</summary>

```
01-input/
‚îú‚îÄ‚îÄ exp-1/                  Experiment 1: AI Perspectives on Intentional Export Delays
‚îú‚îÄ‚îÄ exp-2/                  AI Interaction Experiment 2: Design & Content Prompts
‚îú‚îÄ‚îÄ exp-3/                  Experiment 3: AI Perspectives on Anticipation in UI/UX
‚îú‚îÄ‚îÄ transcript-thoughts.md  Researcher's transcribed thoughts and qualitative observations
‚îî‚îÄ‚îÄ üßëüèªsycophancy-researcher.md Detailed log of sycophancy experiments, prompts, and AI responses
```

#### Directory & File Guide

-   **exp-1/** - Contains specific prompts, AI interactions, and outputs from "Experiment 1: AI Perspectives on Intentional Export Delays." This experiment explores AI's understanding and response to design decisions involving deliberate delays.
-   **exp-2/** - Houses prompts, AI responses, and related content from "AI Interaction Experiment 2: Design & Content Prompts." This section documents AI's approach to creative and functional design challenges.
-   **exp-3/** - Includes inputs and outputs from "Experiment 3: AI Perspectives on Anticipation in UI/UX," exploring AI's understanding of user experience concepts related to predictive interfaces.
-   **[transcript-thoughts.md](transcript-thoughts.md)** - Provides direct, unedited insights from the research process, covering observations on AI hallucinations, sycophancy, and model consistency, offering qualitative data.
-   **[üßëüèªsycophancy-researcher.md](üßëüèªsycophancy-researcher.md)** - A comprehensive log of the sycophancy experiments, detailing prompts, AI model responses (ChatGPT 5, Gemini, Claude, Sonnet 4), and the evolution of the tests, serving as a primary quantitative data source.

</details>

---

## How to Navigate

### Recommended Path

**For the complete experience:**
1.  Start with **[transcript-thoughts.md](transcript-thoughts.md)** for the researcher's overview and qualitative insights into the experiments.
2.  Then explore **[üßëüèªsycophancy-researcher.md](üßëüèªsycophancy-researcher.md)** for the detailed experimental logs, prompts, and AI responses related to sycophancy.
3.  Finally, review the specific experiment directories **[exp-1/](exp-1/)**, **[exp-2/](exp-2/)**, and **[exp-3/](exp-3/)** for their unique contexts and data.

### Alternative Paths

**If you're short on time:** Read **[transcript-thoughts.md](transcript-thoughts.md)** for a quick summary of the key findings and frustrations.
**If you're looking for specific information on AI sycophancy:** Go directly to **[üßëüèªsycophancy-researcher.md](üßëüèªsycophancy-researcher.md)**.
**If you want to understand AI's take on specific design challenges:** Dive into **[exp-1/](exp-1/)**, **[exp-2/](exp-2/)**, or **[exp-3/](exp-3/)**.

**Tip:** Use Ctrl+F (or Cmd+F) within the markdown files to search for specific AI models or terms like "hallucination" or "sycophancy."

---

## Prerequisites & Context

<details>
<summary><strong>What to know before reading</strong> (click to expand)</summary>

### Helpful Background

Familiarity with the following concepts will enhance your understanding of the research:
-   **Large Language Models (LLMs)** and their general operational principles.
-   **AI Hallucinations** (e.g., confabulation, factual errors, fabricated data).
-   **AI Sycophancy** (the tendency of AI to agree with or flatter the user).
-   **Prompt Engineering** basics and the impact of prompt complexity.
-   **Context Window** in conversational AI.

### Related Reading

If you're new to these AI behavioral concepts, you might want to start with:
-   The parent article: [../README.md](../) - "When AI Falls in Love" (for an interpretive overview of this data).

</details>

---

## Related Content

### Within This Repository

**Related articles:**
-   [../README.md](../) - **"When AI Falls in Love"**: The main article that draws conclusions and insights from the raw data presented here.

### Part of a Series

This directory is a core component of the "When AI Falls in Love" article series.
-   **Overview:** [../README.md](../) - "When AI Falls in Love" (Series Homepage/Main Article)
-   **Sibling directory for media:** `../02-assets/` (if present, for visual assets related to the article)

---

## What's Next

**After reviewing these inputs, you might want to:**
1.  **Read the main article:** [../README.md](../) - Dive into "When AI Falls in Love" to see how these raw observations and experimental results are analyzed and interpreted in a broader context of design leadership and AI collaboration.
2.  **Conduct your own experiments:** Use the prompts and experimental setups detailed in `üßëüèªsycophancy-researcher.md` and the `exp-X/` directories as a basis for your own AI behavioral research.
3.  **Explore other articles:** Return to the [02-articles/](../) directory to discover other content on design leadership and AI collaboration.

**Apply what you learned:**
-   Incorporate insights about AI sycophancy and hallucination into your prompt engineering strategies for more robust AI interactions.
-   Use the experimental methodology as a framework for evaluating new AI models or features in your own design and technology workflows.

---

## References & Citations

<details>
<summary><strong>Sources & Further Reading</strong> (click to expand)</summary>

### Primary Sources

This directory primarily contains original research data and direct observations. The key primary sources within this directory are:

1.  **[transcript-thoughts.md](transcript-thoughts.md)** - Researcher's qualitative observations and reflections on AI model behavior during experiments.
2.  **[üßëüèªsycophancy-researcher.md](üßëüèªsycophancy-researcher.md)** - Detailed logs of sycophancy experiments, including prompts, AI responses, and experimental parameters.
3.  **[exp-1/](exp-1/)**, **[exp-2/](exp-2/)**, **[exp-3/](exp-3/)** - Raw data and interactions from specific AI experiments.

### Recommended Reading

For broader context on AI behavior and ethics:
-   General research on Large Language Model limitations and biases.
-   Academic papers on AI alignment and safety.

</details>

---

## Metadata

<details>
<summary><strong>Content Information</strong> (click to expand)</summary>

| | |
|---|---|
| **Created** | 2025-09-27 (approx. research start) |
| **Last Updated** | 2025-10-13 (approx. last research update) |
| **Version** | 1.0 |
| **Status** | Supporting Material |
| **Content Type** | Research Inputs / Experimental Data |
| **Reading Time** | 30-60 minutes |
| **Word Count** | ~34,000 words (across primary markdown files) |
| **Author** | Research Team |
| **Tags** | AI, LLM, Sycophancy, Hallucinations, AI Ethics, Prompt Engineering, Research, Experiments, Design Leadership |

</details>

---

## Engage

**Found this helpful?** Consider sharing the main article "When AI Falls in Love" with your network.
**Have questions?** Refer to the main repository's [CONTRIBUTING.md](/CONTRIBUTING.md) for contact and discussion guidelines.
**Spotted an issue?** Please report errors or suggest improvements via the repository's issue tracker.

---

**Stay Updated:** Follow the main repository for new articles and research on design and technology.