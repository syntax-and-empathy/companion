{
  "article_name": "new-venue",
  "analysis_timestamp": "2025-11-01T02:49:52.276796",
  "article_metadata": {
    "article_name": "new-venue",
    "input_path": "/content/",
    "processing_timestamp": "2025-11-01T02:07:09.573539",
    "versions_found": [
      "draft",
      "refined",
      "edited",
      "final"
    ],
    "validation_status": "passed",
    "validation_results": {
      "has_draft": true,
      "has_final": true,
      "missing_required": [],
      "versions_found": [
        "final",
        "refined",
        "draft",
        "edited"
      ],
      "is_valid": true
    }
  },
  "processing_summary": {
    "draft": {
      "character_count": 10363,
      "word_count": 1574,
      "sentence_count": 64,
      "paragraph_count": 39,
      "avg_sentence_length": 127.96875,
      "avg_paragraph_length": 263.7692307692308
    },
    "refined": {
      "character_count": 15064,
      "word_count": 2162,
      "sentence_count": 161,
      "paragraph_count": 72,
      "avg_sentence_length": 73.73291925465838,
      "avg_paragraph_length": 207.25
    },
    "edited": {
      "character_count": 13540,
      "word_count": 1953,
      "sentence_count": 92,
      "paragraph_count": 72,
      "avg_sentence_length": 82.51086956521739,
      "avg_paragraph_length": 186.0
    },
    "final": {
      "character_count": 12567,
      "word_count": 1801,
      "sentence_count": 94,
      "paragraph_count": 69,
      "avg_sentence_length": 73.24468085106383,
      "avg_paragraph_length": 180.1014492753623
    }
  },
  "similarity_analysis": {
    "sequential_analysis": [
      {
        "version_pair": "draft_to_refined",
        "full_text": {
          "lexical": {
            "jaccard_similarity": 0.16764132553606237,
            "edit_similarity": 0.022810398395406457,
            "tfidf_similarity": 0.3242105167958759,
            "lexical_average": 0.17155408024244825
          },
          "semantic": {
            "semantic_similarity": 0.678080677986145,
            "embedding_dim": 384
          },
          "combined": 0.4248173791142966
        },
        "sentence_level": {
          "average_similarity": 0.32983804715653187,
          "individual_similarities": [
            0.3112075238045846,
            0.27426767237643407,
            0.3961109986304131,
            0.3432289220151789,
            0.2589383001497934,
            0.36723789969017073,
            0.33723499556918124,
            0.3775242997340018,
            0.37187930264272895,
            0.40145599003995364,
            0.28954660032574664,
            0.29390187276883073,
            0.269889500962474,
            0.3465264799304105,
            0.28839995101854143,
            0.35112397841768883,
            0.291244102343544,
            0.3788266313280034,
            0.5009509884817658,
            0.5564088959168705,
            0.36772049679742236,
            0.38172601171541354,
            0.37788573676825443,
            0.4107150210470779,
            0.3386139650943792,
            0.26561204144523815,
            0.3030538850450636,
            0.2635636045435408,
            0.28556139585228296,
            0.29307546448666616,
            0.27779172808026786,
            0.24939274131704908,
            0.3147729825158028,
            0.4158184972158013,
            0.3305683838990984,
            0.29062853924834664,
            0.2829674912750135,
            0.4065718740689622,
            0.28222820846335217,
            0.29170797181321295,
            0.2982393071157287,
            0.4133524051134548,
            0.4715096890349231,
            0.32834637648202436,
            0.25402631925556385,
            0.42865410044938823,
            0.24884555442833606,
            0.271193426896325,
            0.30492742216906954,
            0.26896454963469446,
            0.3410691499035419,
            0.33052037270124396,
            0.31272283669820605,
            0.27791668192151026,
            0.32502337929454306,
            0.283538542980362,
            0.3221333235674067,
            0.2716689616644464,
            0.38390001834000176,
            0.29654203594464223,
            0.3572732237103088,
            0.2886091695906701,
            0.2709287451984383,
            0.3238484790846451
          ],
          "detailed_analysis": [
            {
              "source_index": 0,
              "source_sentence": "Every fix spawned a new failure: paths that doubled back on themselves, outputs that silently dropped rows, functions that vanished after a simple rename",
              "best_match": {
                "index": 119,
                "lexical": 0.10194883915122248,
                "semantic": 0.5204662084579468,
                "combined": 0.3112075238045846,
                "target_sentence": "When file paths duplicated folders, human oversight corrected the mistakes"
              }
            },
            {
              "source_index": 1,
              "source_sentence": "Even when I got numbers, I couldn’t trust them—were they the product of my data, or of some invisible infrastructure glitch",
              "best_match": {
                "index": 111,
                "lexical": 0.12286227718313543,
                "semantic": 0.42567306756973267,
                "combined": 0.27426767237643407,
                "target_sentence": "The system even included trend analysis capabilities, though these remained untested due to limited historical data"
              }
            },
            {
              "source_index": 2,
              "source_sentence": "So when Claude 4 suggested shifting the entire workflow into Google Colab, I approached it like my last shot",
              "best_match": {
                "index": 1,
                "lexical": 0.16165492343880475,
                "semantic": 0.6305670738220215,
                "combined": 0.3961109986304131,
                "target_sentence": "> TL;DR: Moving to Google Colab transformed scattered scripts into a working pipeline"
              }
            },
            {
              "source_index": 3,
              "source_sentence": "I didn’t know Python, I’d never touched Colab, and the idea of mounting drives and importing libraries felt like speaking another language",
              "best_match": {
                "index": 24,
                "lexical": 0.11558762336919447,
                "semantic": 0.5708702206611633,
                "combined": 0.3432289220151789,
                "target_sentence": "Claude loaded the libraries, mounted the drive, and loaded several functions, each one twice as large as any complete Python script I'd gotten before"
              }
            },
            {
              "source_index": 4,
              "source_sentence": "But within minutes of running the same logic in this new space, the chaos stopped",
              "best_match": {
                "index": 4,
                "lexical": 0.13393489030431704,
                "semantic": 0.3839417099952698,
                "combined": 0.2589383001497934,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 5,
              "source_sentence": "The pathing nightmares, missing file errors, and mid-run collapses that had become routine were gone",
              "best_match": {
                "index": 33,
                "lexical": 0.14956826764206024,
                "semantic": 0.5849075317382812,
                "combined": 0.36723789969017073,
                "target_sentence": "No phantom files, no missing sections, no silent corruption"
              }
            },
            {
              "source_index": 6,
              "source_sentence": "For the first time, the tool that was supposed to track AI’s role in my writing actually ran from start to finish, without my intervention—and without lying to me about what it had done",
              "best_match": {
                "index": 158,
                "lexical": 0.13365982334890325,
                "semantic": 0.5408101677894592,
                "combined": 0.33723499556918124,
                "target_sentence": "What came next would test whether precision could actually reshape how we think about authorship, accountability, and the future of human-AI collaboration in creative work"
              }
            },
            {
              "source_index": 7,
              "source_sentence": "---\n\n## Grounding Context\n\nThe point of this entire project was to create a transparent, repeatable way to measure human and AI contributions in my published work",
              "best_match": {
                "index": 0,
                "lexical": 0.1797248985631574,
                "semantic": 0.5753237009048462,
                "combined": 0.3775242997340018,
                "target_sentence": "Victory in a New Venue\n\n## When the Pipeline Finally Held\n\nThis is the fourth in a series documenting attempts to build a system that tracks human versus machine contributions in writing"
              }
            },
            {
              "source_index": 8,
              "source_sentence": "That meant tracking lexical and semantic changes across every stage—draft, refined, edited, final—and presenting those numbers as evidence in the footer of each article",
              "best_match": {
                "index": 90,
                "lexical": 0.1463250382383387,
                "semantic": 0.5974335670471191,
                "combined": 0.37187930264272895,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 9,
              "source_sentence": "The problem: reproducibility only exists if the environment is stable",
              "best_match": {
                "index": 140,
                "lexical": 0.18814323656489262,
                "semantic": 0.6147687435150146,
                "combined": 0.40145599003995364,
                "target_sentence": "Reproducibility builds trust"
              }
            },
            {
              "source_index": 10,
              "source_sentence": "Every time my setup changed—whether it was switching between AI chat sessions, running scripts locally, or patching broken code—the chain of trust broke",
              "best_match": {
                "index": 127,
                "lexical": 0.13593809076913851,
                "semantic": 0.44315510988235474,
                "combined": 0.28954660032574664,
                "target_sentence": "They were the mechanisms that made AI assistance trustworthy"
              }
            },
            {
              "source_index": 11,
              "source_sentence": "Environment instability meant losing files between steps or generating metrics that couldn’t be replicated later",
              "best_match": {
                "index": 115,
                "lexical": 0.10112359550561799,
                "semantic": 0.48668015003204346,
                "combined": 0.29390187276883073,
                "target_sentence": "Clean infrastructure, systematic checkpoints, reproducible outputs"
              }
            },
            {
              "source_index": 12,
              "source_sentence": "Toolchain sprawl—juggling JSON, XML, GitHub-hosted scripts, and multiple AI models—multiplied the failure points",
              "best_match": {
                "index": 105,
                "lexical": 0.09986298725362232,
                "semantic": 0.4399160146713257,
                "combined": 0.269889500962474,
                "target_sentence": "It needed to be AI-friendly, structured data I could feed into future analysis without re-running the entire pipeline"
              }
            },
            {
              "source_index": 13,
              "source_sentence": "False stability was even worse: the AI’s tendency to declare success without verifying outputs produced a dangerous illusion of accuracy",
              "best_match": {
                "index": 82,
                "lexical": 0.15137631935026197,
                "semantic": 0.5416766405105591,
                "combined": 0.3465264799304105,
                "target_sentence": "The vast majority of the final article bore little resemblance to the original AI output"
              }
            },
            {
              "source_index": 14,
              "source_sentence": "Without that, my “transparency” metrics risked becoming just another layer of fiction",
              "best_match": {
                "index": 145,
                "lexical": 0.11634749443858738,
                "semantic": 0.4604524075984955,
                "combined": 0.28839995101854143,
                "target_sentence": "Building infrastructure that makes showing your work repeatable is transparency"
              }
            },
            {
              "source_index": 15,
              "source_sentence": "---\n\n## The Core Event / Experiment\n\nOn June 14, I loaded all four versions of my “markup-languages” article—draft, refined, edited, final—into the Colab notebook Claude 4 had built for me",
              "best_match": {
                "index": 20,
                "lexical": 0.14505741938267994,
                "semantic": 0.5571905374526978,
                "combined": 0.35112397841768883,
                "target_sentence": "## Testing on Markup Languages\n\nThe test subject was an article about markup languages in AI prompting"
              }
            },
            {
              "source_index": 16,
              "source_sentence": "The workflow was structured into deliberate, checkpointed stages so I could verify progress at each step:\nData ingestion & validation – Colab mounted my Google Drive without a single path conflict",
              "best_match": {
                "index": 56,
                "lexical": 0.08874874874874876,
                "semantic": 0.49373945593833923,
                "combined": 0.291244102343544,
                "target_sentence": "\"Let me know when you're ready for Stage 3.\" \"Please confirm the files have been created successfully.\" The checkpoints weren't automatic"
              }
            },
            {
              "source_index": 17,
              "source_sentence": "It found all four versions, confirmed the sequence, and reported basic counts: draft (863 words), refined (1,128), edited (1,066), final (892)",
              "best_match": {
                "index": 21,
                "lexical": 0.256186511557374,
                "semantic": 0.5014667510986328,
                "combined": 0.3788266313280034,
                "target_sentence": "Four versions represented the complete journey: initial AI draft, refined expansion, edited contraction, and final polish"
              }
            },
            {
              "source_index": 18,
              "source_sentence": "Preprocessing – Markdown formatting was stripped cleanly while preserving sentence and paragraph structure",
              "best_match": {
                "index": 34,
                "lexical": 0.25990479459429944,
                "semantic": 0.7419971823692322,
                "combined": 0.5009509884817658,
                "target_sentence": "Stage 2: Preprocessing - Cleaning Markdown and segmenting text into sentences and paragraphs"
              }
            },
            {
              "source_index": 19,
              "source_sentence": "Similarity analysis – Using SentenceTransformers for semantic similarity and Jaccard/edit distance for lexical changes, the notebook compared each stage in sequence, plus a direct draft→final analysis",
              "best_match": {
                "index": 43,
                "lexical": 0.2951573408983771,
                "semantic": 0.8176604509353638,
                "combined": 0.5564088959168705,
                "target_sentence": "Stage 3: Similarity Analysis - Lexical measures like Jaccard similarity and edit distance"
              }
            },
            {
              "source_index": 20,
              "source_sentence": "Metrics generation – In a single uninterrupted pass, Colab produced clean JSON and CSV outputs for both human-readable review and AI-friendly archival",
              "best_match": {
                "index": 50,
                "lexical": 0.23078748016329562,
                "semantic": 0.5046535134315491,
                "combined": 0.36772049679742236,
                "target_sentence": "Stage 5: Metrics Generation - Converting similarity scores into human-readable percentages and modification categories"
              }
            },
            {
              "source_index": 21,
              "source_sentence": "These outputs were not just complete—they were reproducible and verifiable, because the checkpoints and Drive storage locked in exactly what had been processed at each step",
              "best_match": {
                "index": 115,
                "lexical": 0.12640860693073552,
                "semantic": 0.6370434165000916,
                "combined": 0.38172601171541354,
                "target_sentence": "Clean infrastructure, systematic checkpoints, reproducible outputs"
              }
            },
            {
              "source_index": 22,
              "source_sentence": "For the first time, the system produced valid attribution maps, similarity scores, and modification breakdowns without intervention, error messages, or invisible data loss",
              "best_match": {
                "index": 133,
                "lexical": 0.1580609833097633,
                "semantic": 0.5977104902267456,
                "combined": 0.37788573676825443,
                "target_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide"
              }
            },
            {
              "source_index": 23,
              "source_sentence": "The semantic similarity score for draft→final—43.1%—was a number I could trust, not because it “looked right,” but because I knew every step that produced it had executed cleanly",
              "best_match": {
                "index": 2,
                "lexical": 0.17223687440769342,
                "semantic": 0.6491931676864624,
                "combined": 0.4107150210470779,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 24,
              "source_sentence": "---\n\n## The Breakdown / Complication\n\nThis smooth run in Colab only looked effortless because of the wreckage it followed",
              "best_match": {
                "index": 146,
                "lexical": 0.15284623301087139,
                "semantic": 0.524381697177887,
                "combined": 0.3386139650943792,
                "target_sentence": "## The Foundation That Almost Wasn't\n\nThe Colab pipeline established the computational backbone for systematic transparency"
              }
            },
            {
              "source_index": 25,
              "source_sentence": "In the months before, every environment I tried had found a new way to fail:\nChat-based execution was fragile",
              "best_match": {
                "index": 130,
                "lexical": 0.09235883850189601,
                "semantic": 0.4388652443885803,
                "combined": 0.26561204144523815,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 26,
              "source_sentence": "Files vanished between steps, context evaporated across sessions, and any multi-stage process risked collapsing before it finished",
              "best_match": {
                "index": 33,
                "lexical": 0.1097393916893246,
                "semantic": 0.4963683784008026,
                "combined": 0.3030538850450636,
                "target_sentence": "No phantom files, no missing sections, no silent corruption"
              }
            },
            {
              "source_index": 27,
              "source_sentence": "Fragmentation between prompts meant the workflow was forced into a rigid, linear structure that couldn’t survive interruptions",
              "best_match": {
                "index": 94,
                "lexical": 0.1424165395695645,
                "semantic": 0.3847106695175171,
                "combined": 0.2635636045435408,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 28,
              "source_sentence": "Local Python runs suffered from silent data loss—rows dropped without error messages—and “phantom” file references that pointed to nothing",
              "best_match": {
                "index": 33,
                "lexical": 0.10455149048271843,
                "semantic": 0.46657130122184753,
                "combined": 0.28556139585228296,
                "target_sentence": "No phantom files, no missing sections, no silent corruption"
              }
            },
            {
              "source_index": 29,
              "source_sentence": "Version drift was constant",
              "best_match": {
                "index": 81,
                "lexical": 0.08934707903780069,
                "semantic": 0.4968038499355316,
                "combined": 0.29307546448666616,
                "target_sentence": "Revision changes everything, even the parts you think you're preserving"
              }
            },
            {
              "source_index": 30,
              "source_sentence": "A renamed file could erase core functions, with the AI confidently reintroducing them as imports from modules that didn’t exist",
              "best_match": {
                "index": 119,
                "lexical": 0.13928470909785265,
                "semantic": 0.4162987470626831,
                "combined": 0.27779172808026786,
                "target_sentence": "When file paths duplicated folders, human oversight corrected the mistakes"
              }
            },
            {
              "source_index": 31,
              "source_sentence": "Misleading confirmations were a recurring trap",
              "best_match": {
                "index": 57,
                "lexical": 0.12844036697247707,
                "semantic": 0.3703451156616211,
                "combined": 0.24939274131704908,
                "target_sentence": "They demanded explicit human verification before moving forward"
              }
            },
            {
              "source_index": 32,
              "source_sentence": "The AI would report “analysis complete” even when no outputs had been saved or the links it provided returned 404 errors",
              "best_match": {
                "index": 82,
                "lexical": 0.10388568861864177,
                "semantic": 0.5256602764129639,
                "combined": 0.3147729825158028,
                "target_sentence": "The vast majority of the final article bore little resemblance to the original AI output"
              }
            },
            {
              "source_index": 33,
              "source_sentence": "Pathing chaos created double-nested folders, hard-coded directories, and brittle assumptions that broke the moment my file structure changed",
              "best_match": {
                "index": 119,
                "lexical": 0.1841832094889756,
                "semantic": 0.647453784942627,
                "combined": 0.4158184972158013,
                "target_sentence": "When file paths duplicated folders, human oversight corrected the mistakes"
              }
            },
            {
              "source_index": 34,
              "source_sentence": "Each fix required hours of rework and re-verification",
              "best_match": {
                "index": 134,
                "lexical": 0.17146249764515106,
                "semantic": 0.48967427015304565,
                "combined": 0.3305683838990984,
                "target_sentence": "Every checkpoint required editorial verification that felt collaborative rather than like failed automation"
              }
            },
            {
              "source_index": 35,
              "source_sentence": "The bigger risk wasn’t just wasted time—it was publishing metrics built on unstable runs, where I couldn’t be certain whether a number reflected the data or the tool’s hidden flaws",
              "best_match": {
                "index": 94,
                "lexical": 0.11256483539748068,
                "semantic": 0.46869224309921265,
                "combined": 0.29062853924834664,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 36,
              "source_sentence": "By the time Colab entered the picture, I wasn’t just looking for speed; I was looking for something I could finally trust",
              "best_match": {
                "index": 136,
                "lexical": 0.14612665439832417,
                "semantic": 0.4198083281517029,
                "combined": 0.2829674912750135,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 37,
              "source_sentence": "---\n\n## The Breakthrough\n\nColab didn’t just run the code—it removed the fragility that had been undermining the entire project",
              "best_match": {
                "index": 146,
                "lexical": 0.17100467095134,
                "semantic": 0.6421390771865845,
                "combined": 0.4065718740689622,
                "target_sentence": "## The Foundation That Almost Wasn't\n\nThe Colab pipeline established the computational backbone for systematic transparency"
              }
            },
            {
              "source_index": 38,
              "source_sentence": "It also overcame the fragmentation and rigid linearity of chat-based execution, allowing the process to run as one continuous, coherent workflow without being chopped into unstable prompt sessions",
              "best_match": {
                "index": 94,
                "lexical": 0.0965151327470168,
                "semantic": 0.4679412841796875,
                "combined": 0.28222820846335217,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 39,
              "source_sentence": "Every stage executed in sequence without interruption:\nDrive integration mounted cleanly on the first try, with no double-folder loops or hard-coded paths to untangle",
              "best_match": {
                "index": 56,
                "lexical": 0.1018277885952217,
                "semantic": 0.4815881550312042,
                "combined": 0.29170797181321295,
                "target_sentence": "\"Let me know when you're ready for Stage 3.\" \"Please confirm the files have been created successfully.\" The checkpoints weren't automatic"
              }
            },
            {
              "source_index": 40,
              "source_sentence": "Library loading handled dependencies without the compatibility errors I’d wrestled with in local Python",
              "best_match": {
                "index": 24,
                "lexical": 0.12615314426075433,
                "semantic": 0.4703254699707031,
                "combined": 0.2982393071157287,
                "target_sentence": "Claude loaded the libraries, mounted the drive, and loaded several functions, each one twice as large as any complete Python script I'd gotten before"
              }
            },
            {
              "source_index": 41,
              "source_sentence": "Processing checkpoints saved in real time to Drive, giving me verifiable snapshots between stages—critical for ensuring any future run could be matched exactly to past outputs",
              "best_match": {
                "index": 12,
                "lexical": 0.14272780236100382,
                "semantic": 0.6839770078659058,
                "combined": 0.4133524051134548,
                "target_sentence": "The checkpoints designed to catch problems before they cascaded"
              }
            },
            {
              "source_index": 42,
              "source_sentence": "Final outputs—attribution maps, similarity scores, modification percentages—were generated exactly as requested, in both human-readable and archival formats",
              "best_match": {
                "index": 50,
                "lexical": 0.2558245538510961,
                "semantic": 0.68719482421875,
                "combined": 0.4715096890349231,
                "target_sentence": "Stage 5: Metrics Generation - Converting similarity scores into human-readable percentages and modification categories"
              }
            },
            {
              "source_index": 43,
              "source_sentence": "---\n\n## Pattern or Principle\n\nThe success in Colab underscored something I’d been circling for months: infrastructure reliability isn’t a convenience—it’s a prerequisite for ethical measurement",
              "best_match": {
                "index": 146,
                "lexical": 0.15487814915850678,
                "semantic": 0.501814603805542,
                "combined": 0.32834637648202436,
                "target_sentence": "## The Foundation That Almost Wasn't\n\nThe Colab pipeline established the computational backbone for systematic transparency"
              }
            },
            {
              "source_index": 44,
              "source_sentence": "If the environment shifts under you, the same code can produce different results for reasons that have nothing to do with the data",
              "best_match": {
                "index": 4,
                "lexical": 0.1826233777803843,
                "semantic": 0.3254292607307434,
                "combined": 0.25402631925556385,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 45,
              "source_sentence": "In my case, the goal was to measure how much of a finished article was human-authored versus AI-assisted",
              "best_match": {
                "index": 156,
                "lexical": 0.2345627465874056,
                "semantic": 0.6227454543113708,
                "combined": 0.42865410044938823,
                "target_sentence": "For the first time, the question \"How much of this was AI versus human?\" had a precise, reproducible answer"
              }
            },
            {
              "source_index": 46,
              "source_sentence": "That’s a credibility claim",
              "best_match": {
                "index": 140,
                "lexical": 0.12345679012345678,
                "semantic": 0.37423431873321533,
                "combined": 0.24884555442833606,
                "target_sentence": "Reproducibility builds trust"
              }
            },
            {
              "source_index": 47,
              "source_sentence": "If my tooling can’t run in a stable, reproducible space, any number I publish risks being less about editorial truth and more about whatever quirks the environment introduced that day",
              "best_match": {
                "index": 134,
                "lexical": 0.11668821583030864,
                "semantic": 0.4256986379623413,
                "combined": 0.271193426896325,
                "target_sentence": "Every checkpoint required editorial verification that felt collaborative rather than like failed automation"
              }
            },
            {
              "source_index": 48,
              "source_sentence": "Colab’s stability didn’t just solve a technical problem—it reframed my evaluation criteria for every AI-assisted workflow",
              "best_match": {
                "index": 105,
                "lexical": 0.1027657063071332,
                "semantic": 0.5070891380310059,
                "combined": 0.30492742216906954,
                "target_sentence": "It needed to be AI-friendly, structured data I could feed into future analysis without re-running the entire pipeline"
              }
            },
            {
              "source_index": 49,
              "source_sentence": "Capability matters, but without controlled execution conditions, even the best-designed algorithms can become ethical liabilities",
              "best_match": {
                "index": 127,
                "lexical": 0.09209416455793266,
                "semantic": 0.4458349347114563,
                "combined": 0.26896454963469446,
                "target_sentence": "They were the mechanisms that made AI assistance trustworthy"
              }
            },
            {
              "source_index": 50,
              "source_sentence": "This project proved that measurement integrity lives or dies in the infrastructure that supports it",
              "best_match": {
                "index": 147,
                "lexical": 0.16995719657756117,
                "semantic": 0.5121811032295227,
                "combined": 0.3410691499035419,
                "target_sentence": "Its modular design, checkpoint workflow, and archival outputs created infrastructure that could support analysis at scale"
              }
            },
            {
              "source_index": 51,
              "source_sentence": "---\n\n## What This Means for Your Workflow\n\nThe Colab shift forced me to think about execution environments as part of the tool itself—not an afterthought",
              "best_match": {
                "index": 85,
                "lexical": 0.12233223738780895,
                "semantic": 0.538708508014679,
                "combined": 0.33052037270124396,
                "target_sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis"
              }
            },
            {
              "source_index": 52,
              "source_sentence": "If you want reproducible, defensible results from AI-assisted analysis, treat stability as a design requirement from day one",
              "best_match": {
                "index": 105,
                "lexical": 0.12396372311336157,
                "semantic": 0.5014819502830505,
                "combined": 0.31272283669820605,
                "target_sentence": "It needed to be AI-friendly, structured data I could feed into future analysis without re-running the entire pipeline"
              }
            },
            {
              "source_index": 53,
              "source_sentence": "Document environment requirements – Record versions, library dependencies, storage paths, and integration steps so the exact setup can be rebuilt later",
              "best_match": {
                "index": 54,
                "lexical": 0.08871158392434987,
                "semantic": 0.46712177991867065,
                "combined": 0.27791668192151026,
                "target_sentence": "Stage 7: Archival Export - Saving everything to timestamped JSON files that could survive session resets and enable future analysis"
              }
            },
            {
              "source_index": 54,
              "source_sentence": "Budget for infrastructure – Even “free” options have limits; know what it would cost to scale or preserve your setup",
              "best_match": {
                "index": 135,
                "lexical": 0.11932414048605879,
                "semantic": 0.5307226181030273,
                "combined": 0.32502337929454306,
                "target_sentence": "Infrastructure enables rather than guarantees"
              }
            },
            {
              "source_index": 55,
              "source_sentence": "Treat stability as an ethical requirement – When your output will be cited as evidence—whether for AI transparency or any other metric—environmental drift can become a form of silent falsification",
              "best_match": {
                "index": 82,
                "lexical": 0.1275201892741701,
                "semantic": 0.43955689668655396,
                "combined": 0.283538542980362,
                "target_sentence": "The vast majority of the final article bore little resemblance to the original AI output"
              }
            },
            {
              "source_index": 56,
              "source_sentence": "This shift changed how I assess every AI tool I use",
              "best_match": {
                "index": 127,
                "lexical": 0.1650549590931264,
                "semantic": 0.479211688041687,
                "combined": 0.3221333235674067,
                "target_sentence": "They were the mechanisms that made AI assistance trustworthy"
              }
            },
            {
              "source_index": 57,
              "source_sentence": "I now weigh its execution stability as heavily as its functional capability, because one without the other isn’t reliable enough to publish",
              "best_match": {
                "index": 94,
                "lexical": 0.1292517006802721,
                "semantic": 0.4140862226486206,
                "combined": 0.2716689616644464,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 58,
              "source_sentence": "---\n\n## Closing Arc\n\nIn the end, Colab didn’t make the analysis smarter—it made it honest",
              "best_match": {
                "index": 146,
                "lexical": 0.14931375147034778,
                "semantic": 0.6184862852096558,
                "combined": 0.38390001834000176,
                "target_sentence": "## The Foundation That Almost Wasn't\n\nThe Colab pipeline established the computational backbone for systematic transparency"
              }
            },
            {
              "source_index": 59,
              "source_sentence": "By giving the process a consistent, transparent footing, it turned months of chaotic iteration into a workflow I could trust enough to publish",
              "best_match": {
                "index": 140,
                "lexical": 0.10907662393129192,
                "semantic": 0.48400744795799255,
                "combined": 0.29654203594464223,
                "target_sentence": "Reproducibility builds trust"
              }
            },
            {
              "source_index": 60,
              "source_sentence": "The last mile in AI-assisted measurement is always human",
              "best_match": {
                "index": 156,
                "lexical": 0.14283133091976305,
                "semantic": 0.5717151165008545,
                "combined": 0.3572732237103088,
                "target_sentence": "For the first time, the question \"How much of this was AI versus human?\" had a precise, reproducible answer"
              }
            },
            {
              "source_index": 61,
              "source_sentence": "It’s in our oversight, our interpretation of the numbers, and our willingness to challenge results that don’t add up",
              "best_match": {
                "index": 133,
                "lexical": 0.15304671261349964,
                "semantic": 0.4241716265678406,
                "combined": 0.2886091695906701,
                "target_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide"
              }
            },
            {
              "source_index": 62,
              "source_sentence": "But for that human judgment to mean anything, the path getting to those numbers has to be solid",
              "best_match": {
                "index": 132,
                "lexical": 0.19428179607429055,
                "semantic": 0.34757569432258606,
                "combined": 0.2709287451984383,
                "target_sentence": "Checkpoints demand human judgment"
              }
            },
            {
              "source_index": 63,
              "source_sentence": "Colab gave me that solid ground",
              "best_match": {
                "index": 136,
                "lexical": 0.1869612198918549,
                "semantic": 0.4607357382774353,
                "combined": 0.3238484790846451,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            }
          ]
        },
        "paragraph_level": {
          "lexical": {
            "jaccard_similarity": 0.16764132553606237,
            "edit_similarity": 0.023066592937830793,
            "tfidf_similarity": 0.3242105167958759,
            "lexical_average": 0.17163947842325636
          },
          "semantic": {
            "semantic_similarity": 0.678080677986145,
            "embedding_dim": 384
          },
          "combined": 0.4248600782047007
        }
      },
      {
        "version_pair": "refined_to_edited",
        "full_text": {
          "lexical": {
            "jaccard_similarity": 0.31392931392931395,
            "edit_similarity": 0.06761292126975248,
            "tfidf_similarity": 0.38225372150966996,
            "lexical_average": 0.2545986522362455
          },
          "semantic": {
            "semantic_similarity": 0.8168333768844604,
            "embedding_dim": 384
          },
          "combined": 0.535716014560353
        },
        "sentence_level": {
          "average_similarity": 0.4613321378718621,
          "individual_similarities": [
            0.8318717346129312,
            0.31217467847029795,
            1.0,
            1.0000000596046448,
            0.9999999701976776,
            0.4196594687727153,
            0.2895238933688654,
            0.22832988052771835,
            0.25430731101706683,
            0.3304695240854396,
            0.2822901996426612,
            0.23699729297405633,
            0.48547746686313237,
            0.2592575457952696,
            0.21075550350202185,
            0.23578512155102824,
            0.4104046268110331,
            0.275595506080767,
            0.20233503129747177,
            0.2916661613407894,
            0.3846764402478078,
            0.3857891288367556,
            0.27689839106554176,
            0.4562208987906913,
            0.24116945286204003,
            0.32459438381246547,
            0.25927566177513767,
            0.41495699980209605,
            0.37923277900518526,
            0.3246691445209706,
            0.33456172595593847,
            0.5280272278432483,
            0.33205914992090696,
            0.3551098056564179,
            0.2821291529420767,
            0.24955036779900042,
            0.3098414644478564,
            0.2603618724224357,
            0.19157293695467967,
            0.25464432352452543,
            0.3013844443053113,
            0.355165970367312,
            0.21839072093137316,
            0.32808017697750563,
            0.320499162529234,
            0.2636934739957832,
            0.35026702458157893,
            0.25817789482794784,
            0.38561827252861636,
            0.22487028748971316,
            0.3407605884323909,
            0.25791349292617954,
            0.28970375207379356,
            0.2154920916808279,
            0.4290535718675213,
            0.2669501470431492,
            0.33398110372095413,
            0.3939642520320496,
            0.33513538791695247,
            0.27545085640076994,
            0.29356891639777855,
            0.4370393041393117,
            0.3026194582091759,
            0.2916448845714711,
            0.38801317817398684,
            0.33954166515574435,
            0.233879416901181,
            0.269263967905066,
            0.24797244759556514,
            0.3400803000297187,
            0.3605051913871247,
            0.30913142361154683,
            0.1959031163542359,
            0.23517909753568395,
            0.29977521545635416,
            0.20880582198984152,
            0.27355422434352694,
            0.3198799402439017,
            0.2825074643747275,
            0.2100186456201185,
            0.2883342643522367,
            0.28301199574923086,
            0.3952276200524424,
            0.4183713749766851,
            0.2854163599765207,
            1.0000000596046448,
            1.0000000596046448,
            1.0000000596046448,
            1.0,
            0.9999999701976776,
            1.0000000596046448,
            1.0,
            1.0000001192092896,
            0.9999999403953552,
            1.0000000596046448,
            0.32869328528879316,
            0.2705990904491883,
            0.2060058790821213,
            0.3023237172407797,
            0.2726923687233407,
            0.3384851303148254,
            0.2717570354440798,
            0.2074819085191294,
            0.46315148556699004,
            0.23644491072436974,
            0.37586719674495356,
            0.24503817808908634,
            0.21864561222809423,
            0.3141408661881242,
            0.26969746915684567,
            0.31402510690568675,
            0.303141412421359,
            0.3355136248423043,
            0.24170504831800274,
            0.40088809486114174,
            0.37718730100683906,
            0.2336990580414281,
            0.2726837428868545,
            0.267422015910481,
            0.335378434105869,
            0.15980664781205722,
            0.178348801157496,
            0.18506589939737866,
            0.9999999999999998,
            0.9999999403953552,
            0.9560849840596595,
            0.7681342805937714,
            0.8017092328470619,
            1.0,
            1.0000001192092896,
            1.0000001192092896,
            1.0000000596046448,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0000000596046448,
            1.0,
            1.0,
            1.0,
            1.0,
            0.9999999403953552,
            0.9999999701976776,
            1.0,
            1.0,
            0.3689972746624557,
            0.3713703363471561,
            0.3258002431110952,
            0.26892056397922637,
            0.3745426452670258,
            0.2675273813474398,
            0.2690130894623076,
            0.24199201105808726,
            0.2619071796772972,
            0.20106054216191388,
            0.34293370999141254,
            0.2216617547803455,
            0.3743115969464238,
            0.17657720116954861,
            1.0000000596046448
          ],
          "detailed_analysis": [
            {
              "source_index": 0,
              "source_sentence": "Victory in a New Venue\n\n## When the Pipeline Finally Held\n\nThis is the fourth in a series documenting attempts to build a system that tracks human versus machine contributions in writing",
              "best_match": {
                "index": 0,
                "lexical": 0.8115104169721393,
                "semantic": 0.8522330522537231,
                "combined": 0.8318717346129312,
                "target_sentence": "Victory in a New Venue\n\n## The Notebook That Finally Counted\n\nThis is the fourth in a series documenting attempts to build a system that tracks human versus machine contributions in writing"
              }
            },
            {
              "source_index": 1,
              "source_sentence": "> TL;DR: Moving to Google Colab transformed scattered scripts into a working pipeline",
              "best_match": {
                "index": 78,
                "lexical": 0.0975224984200881,
                "semantic": 0.5268268585205078,
                "combined": 0.31217467847029795,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 2,
              "source_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact",
              "best_match": {
                "index": 1,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 3,
              "source_sentence": "The AI accelerated expansion, but human editing shaped the actual content",
              "best_match": {
                "index": 2,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 4,
              "source_sentence": "For the first time, the system didn't collapse under the weight of real data",
              "best_match": {
                "index": 3,
                "lexical": 1.0,
                "semantic": 0.9999999403953552,
                "combined": 0.9999999701976776,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 5,
              "source_sentence": "Months of phantom functions and empty output folders",
              "best_match": {
                "index": 68,
                "lexical": 0.28711361337245694,
                "semantic": 0.5522053241729736,
                "combined": 0.4196594687727153,
                "target_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing"
              }
            },
            {
              "source_index": 6,
              "source_sentence": "Hours spent debugging problems that shouldn't have existed in the first place",
              "best_match": {
                "index": 69,
                "lexical": 0.0753839488280324,
                "semantic": 0.5036638379096985,
                "combined": 0.2895238933688654,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 7,
              "source_sentence": "A Saturday in June",
              "best_match": {
                "index": 30,
                "lexical": 0.1164021164021164,
                "semantic": 0.3402576446533203,
                "combined": 0.22832988052771835,
                "target_sentence": "An hour and a half later"
              }
            },
            {
              "source_index": 8,
              "source_sentence": "Second newsletter deadline a week and a half out",
              "best_match": {
                "index": 30,
                "lexical": 0.2570539936199796,
                "semantic": 0.25156062841415405,
                "combined": 0.25430731101706683,
                "target_sentence": "An hour and a half later"
              }
            },
            {
              "source_index": 9,
              "source_sentence": "I'd learned enough from previous disasters to know what Colab even was, let alone why breaking things into steps mattered",
              "best_match": {
                "index": 78,
                "lexical": 0.11489410245402136,
                "semantic": 0.5460449457168579,
                "combined": 0.3304695240854396,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 10,
              "source_sentence": "But something felt different",
              "best_match": {
                "index": 85,
                "lexical": 0.10062893081761005,
                "semantic": 0.4639514684677124,
                "combined": 0.2822901996426612,
                "target_sentence": "That distinction mattered"
              }
            },
            {
              "source_index": 11,
              "source_sentence": "The approach more systematic",
              "best_match": {
                "index": 79,
                "lexical": 0.05128205128205129,
                "semantic": 0.4227125346660614,
                "combined": 0.23699729297405633,
                "target_sentence": "Multiple articles could be analyzed using identical methodology"
              }
            },
            {
              "source_index": 12,
              "source_sentence": "The checkpoints designed to catch problems before they cascaded",
              "best_match": {
                "index": 62,
                "lexical": 0.21398339565940072,
                "semantic": 0.756971538066864,
                "combined": 0.48547746686313237,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 13,
              "source_sentence": "I'd specified the environment, specified I wanted it in steps, gave it fairly detailed instructions",
              "best_match": {
                "index": 13,
                "lexical": 0.12974573319400906,
                "semantic": 0.38876935839653015,
                "combined": 0.2592575457952696,
                "target_sentence": "It wasn't just solving my problem—it was ensuring I understood the solution"
              }
            },
            {
              "source_index": 14,
              "source_sentence": "All new approaches",
              "best_match": {
                "index": 15,
                "lexical": 0.06802721088435375,
                "semantic": 0.35348379611968994,
                "combined": 0.21075550350202185,
                "target_sentence": "After months of black-box solutions, I had a patient tutor explaining every step"
              }
            },
            {
              "source_index": 15,
              "source_sentence": "I'd been here before—confident this version would finally work, only to watch it collapse",
              "best_match": {
                "index": 73,
                "lexical": 0.112538357239706,
                "semantic": 0.35903188586235046,
                "combined": 0.23578512155102824,
                "target_sentence": "Earlier attempts tried to do everything at once and collapsed under their own weight"
              }
            },
            {
              "source_index": 16,
              "source_sentence": "The test would be unforgiving: four complete versions of a live article, from AI-generated draft through human editing to final publication",
              "best_match": {
                "index": 2,
                "lexical": 0.19733298676110433,
                "semantic": 0.6234762668609619,
                "combined": 0.4104046268110331,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 17,
              "source_sentence": "No toy examples",
              "best_match": {
                "index": 24,
                "lexical": 0.2292682926829268,
                "semantic": 0.3219227194786072,
                "combined": 0.275595506080767,
                "target_sentence": "No educational explanation"
              }
            },
            {
              "source_index": 18,
              "source_sentence": "No simplified test cases",
              "best_match": {
                "index": 24,
                "lexical": 0.14888888888888888,
                "semantic": 0.2557811737060547,
                "combined": 0.20233503129747177,
                "target_sentence": "No educational explanation"
              }
            },
            {
              "source_index": 19,
              "source_sentence": "Just the messy reality of mixed-authorship content creation",
              "best_match": {
                "index": 2,
                "lexical": 0.14005371197524943,
                "semantic": 0.44327861070632935,
                "combined": 0.2916661613407894,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 20,
              "source_sentence": "## Testing on Markup Languages\n\nThe test subject was an article about markup languages in AI prompting",
              "best_match": {
                "index": 38,
                "lexical": 0.22165873386246737,
                "semantic": 0.5476941466331482,
                "combined": 0.3846764402478078,
                "target_sentence": "> Spoiler, it turns out the article was about using Mermaid AI, not markup"
              }
            },
            {
              "source_index": 21,
              "source_sentence": "Four versions represented the complete journey: initial AI draft, refined expansion, edited contraction, and final polish",
              "best_match": {
                "index": 2,
                "lexical": 0.18215209781480754,
                "semantic": 0.5894261598587036,
                "combined": 0.3857891288367556,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 22,
              "source_sentence": "Two hours of active collaboration",
              "best_match": {
                "index": 30,
                "lexical": 0.1286549707602339,
                "semantic": 0.4251418113708496,
                "combined": 0.27689839106554176,
                "target_sentence": "An hour and a half later"
              }
            },
            {
              "source_index": 23,
              "source_sentence": "Maybe two and a half",
              "best_match": {
                "index": 30,
                "lexical": 0.3721830919653853,
                "semantic": 0.5402587056159973,
                "combined": 0.4562208987906913,
                "target_sentence": "An hour and a half later"
              }
            },
            {
              "source_index": 24,
              "source_sentence": "Claude loaded the libraries, mounted the drive, and loaded several functions, each one twice as large as any complete Python script I'd gotten before",
              "best_match": {
                "index": 9,
                "lexical": 0.07540801206448837,
                "semantic": 0.4069308936595917,
                "combined": 0.24116945286204003,
                "target_sentence": "> Then Claude asked  \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed"
              }
            },
            {
              "source_index": 25,
              "source_sentence": "Each was just for counting content accurately",
              "best_match": {
                "index": 34,
                "lexical": 0.07395411605937922,
                "semantic": 0.5752346515655518,
                "combined": 0.32459438381246547,
                "target_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
              }
            },
            {
              "source_index": 26,
              "source_sentence": "That much rigor going into understanding what a sentence actually is, what a word actually is",
              "best_match": {
                "index": 54,
                "lexical": 0.18501690401368479,
                "semantic": 0.3335344195365906,
                "combined": 0.25927566177513767,
                "target_sentence": "Understanding how to into that vast amount of knowledge does"
              }
            },
            {
              "source_index": 27,
              "source_sentence": "What started at 863 words grew to over 1,100, then contracted back to 892, leaner than the original but fundamentally transformed",
              "best_match": {
                "index": 65,
                "lexical": 0.24374875025650533,
                "semantic": 0.5861652493476868,
                "combined": 0.41495699980209605,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 28,
              "source_sentence": "## Seven Checkpoints to Avoid Seven Disasters\n\nEarlier attempts had tried to do everything at once",
              "best_match": {
                "index": 71,
                "lexical": 0.11712184520366882,
                "semantic": 0.6413437128067017,
                "combined": 0.37923277900518526,
                "target_sentence": "Seven distinct stages, each with its own checkpoint"
              }
            },
            {
              "source_index": 29,
              "source_sentence": "Analyze text, create visualizations, manage data, and explain results in a single sprawling framework",
              "best_match": {
                "index": 42,
                "lexical": 0.20491067959827666,
                "semantic": 0.44442760944366455,
                "combined": 0.3246691445209706,
                "target_sentence": "A summary of the data, the actual data, an index of the data, and so on"
              }
            },
            {
              "source_index": 30,
              "source_sentence": "Each additional feature created new failure points until the whole system collapsed",
              "best_match": {
                "index": 72,
                "lexical": 0.1760634591216548,
                "semantic": 0.49305999279022217,
                "combined": 0.33456172595593847,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 31,
              "source_sentence": "This version split everything into seven distinct stages",
              "best_match": {
                "index": 71,
                "lexical": 0.3273268169650304,
                "semantic": 0.7287276387214661,
                "combined": 0.5280272278432483,
                "target_sentence": "Seven distinct stages, each with its own checkpoint"
              }
            },
            {
              "source_index": 32,
              "source_sentence": "Stage 1: Data Ingestion & Validation - All four article versions present and properly formatted",
              "best_match": {
                "index": 41,
                "lexical": 0.1913114587067889,
                "semantic": 0.472806841135025,
                "combined": 0.33205914992090696,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 33,
              "source_sentence": "No phantom files, no missing sections, no silent corruption",
              "best_match": {
                "index": 68,
                "lexical": 0.14871345915982065,
                "semantic": 0.5615061521530151,
                "combined": 0.3551098056564179,
                "target_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing"
              }
            },
            {
              "source_index": 34,
              "source_sentence": "Stage 2: Preprocessing - Cleaning Markdown and segmenting text into sentences and paragraphs",
              "best_match": {
                "index": 1,
                "lexical": 0.08841386303976255,
                "semantic": 0.47584444284439087,
                "combined": 0.2821291529420767,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 35,
              "source_sentence": "Mundane work, but critical for accurate measurement",
              "best_match": {
                "index": 87,
                "lexical": 0.10866855662384921,
                "semantic": 0.3904321789741516,
                "combined": 0.24955036779900042,
                "target_sentence": "Building infrastructure that makes showing your work repeatable is transparency"
              }
            },
            {
              "source_index": 36,
              "source_sentence": "There were like 15 lines of regex patterns in there",
              "best_match": {
                "index": 22,
                "lexical": 0.21552436647391407,
                "semantic": 0.4041585624217987,
                "combined": 0.3098414644478564,
                "target_sentence": "A mere 3 lines of code"
              }
            },
            {
              "source_index": 37,
              "source_sentence": "One earlier attempt had stumbled on regex and never recovered",
              "best_match": {
                "index": 73,
                "lexical": 0.201865300154167,
                "semantic": 0.31885844469070435,
                "combined": 0.2603618724224357,
                "target_sentence": "Earlier attempts tried to do everything at once and collapsed under their own weight"
              }
            },
            {
              "source_index": 38,
              "source_sentence": "Stage 2 threw cannot import name 'LatentDirichletAllocation' from 'sklearn.decomposition' immediately",
              "best_match": {
                "index": 33,
                "lexical": 0.10860860860860862,
                "semantic": 0.27453726530075073,
                "combined": 0.19157293695467967,
                "target_sentence": "Results that I failed to copy from the notebook"
              }
            },
            {
              "source_index": 39,
              "source_sentence": "One of those errors that stops everything",
              "best_match": {
                "index": 72,
                "lexical": 0.047961630695443645,
                "semantic": 0.4613270163536072,
                "combined": 0.25464432352452543,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 40,
              "source_sentence": "Claude pivoted",
              "best_match": {
                "index": 12,
                "lexical": 0.1497685219228479,
                "semantic": 0.45300036668777466,
                "combined": 0.3013844443053113,
                "target_sentence": "I watched as Claude transformed from code generator to educator"
              }
            },
            {
              "source_index": 41,
              "source_sentence": "\"I'll use TF-IDF and cosine similarity as our primary semantic measure",
              "best_match": {
                "index": 7,
                "lexical": 0.2072811365964404,
                "semantic": 0.5030508041381836,
                "combined": 0.355165970367312,
                "target_sentence": "Semantic similarity scores that changed every time I blinked"
              }
            },
            {
              "source_index": 42,
              "source_sentence": "More reliable than LDA for this use case.\" Decision made, we moved forward",
              "best_match": {
                "index": 58,
                "lexical": 0.0750551876379691,
                "semantic": 0.3617262542247772,
                "combined": 0.21839072093137316,
                "target_sentence": "Oversight, verification, and quality assurance aren't obstacles to efficiency"
              }
            },
            {
              "source_index": 43,
              "source_sentence": "Stage 3: Similarity Analysis - Lexical measures like Jaccard similarity and edit distance",
              "best_match": {
                "index": 7,
                "lexical": 0.13897234135506617,
                "semantic": 0.5171880125999451,
                "combined": 0.32808017697750563,
                "target_sentence": "Semantic similarity scores that changed every time I blinked"
              }
            },
            {
              "source_index": 44,
              "source_sentence": "Semantic analysis using TF-IDF cosine similarity and SBERT embeddings",
              "best_match": {
                "index": 7,
                "lexical": 0.21819182366991816,
                "semantic": 0.4228065013885498,
                "combined": 0.320499162529234,
                "target_sentence": "Semantic similarity scores that changed every time I blinked"
              }
            },
            {
              "source_index": 45,
              "source_sentence": "Multiple approaches to triangulate on truth",
              "best_match": {
                "index": 79,
                "lexical": 0.1969947363159225,
                "semantic": 0.3303922116756439,
                "combined": 0.2636934739957832,
                "target_sentence": "Multiple articles could be analyzed using identical methodology"
              }
            },
            {
              "source_index": 46,
              "source_sentence": "Stage 4: Attribution Mapping - Tracing each final sentence back through the revision process",
              "best_match": {
                "index": 65,
                "lexical": 0.147155586371715,
                "semantic": 0.5533784627914429,
                "combined": 0.35026702458157893,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 47,
              "source_sentence": "Which originated in the draft",
              "best_match": {
                "index": 65,
                "lexical": 0.15476471876546907,
                "semantic": 0.36159107089042664,
                "combined": 0.25817789482794784,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 48,
              "source_sentence": "Which emerged during editing",
              "best_match": {
                "index": 2,
                "lexical": 0.17243946215623177,
                "semantic": 0.598797082901001,
                "combined": 0.38561827252861636,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 49,
              "source_sentence": "Which appeared only in final polish",
              "best_match": {
                "index": 31,
                "lexical": 0.18155370774233523,
                "semantic": 0.26818686723709106,
                "combined": 0.22487028748971316,
                "target_sentence": "When the results appeared the moment was anticlimactic to say the least"
              }
            },
            {
              "source_index": 50,
              "source_sentence": "Stage 5: Metrics Generation - Converting similarity scores into human-readable percentages and modification categories",
              "best_match": {
                "index": 7,
                "lexical": 0.17000985102860014,
                "semantic": 0.5115113258361816,
                "combined": 0.3407605884323909,
                "target_sentence": "Semantic similarity scores that changed every time I blinked"
              }
            },
            {
              "source_index": 51,
              "source_sentence": "Raw computation becoming insight",
              "best_match": {
                "index": 40,
                "lexical": 0.0821917808219178,
                "semantic": 0.4336352050304413,
                "combined": 0.25791349292617954,
                "target_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
              }
            },
            {
              "source_index": 52,
              "source_sentence": "Stage 6: Visualization Preparation - Structuring data for flow diagrams, heatmaps, and interactive charts",
              "best_match": {
                "index": 35,
                "lexical": 0.16427429611116443,
                "semantic": 0.41513320803642273,
                "combined": 0.28970375207379356,
                "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles"
              }
            },
            {
              "source_index": 53,
              "source_sentence": "Making patterns visible at a glance",
              "best_match": {
                "index": 87,
                "lexical": 0.10526315789473684,
                "semantic": 0.32572102546691895,
                "combined": 0.2154920916808279,
                "target_sentence": "Building infrastructure that makes showing your work repeatable is transparency"
              }
            },
            {
              "source_index": 54,
              "source_sentence": "Stage 7: Archival Export - Saving everything to timestamped JSON files that could survive session resets and enable future analysis",
              "best_match": {
                "index": 83,
                "lexical": 0.1760618031970177,
                "semantic": 0.6820453405380249,
                "combined": 0.4290535718675213,
                "target_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps"
              }
            },
            {
              "source_index": 55,
              "source_sentence": "Each stage ended with Claude asking permission to proceed",
              "best_match": {
                "index": 12,
                "lexical": 0.19972181656058732,
                "semantic": 0.33417847752571106,
                "combined": 0.2669501470431492,
                "target_sentence": "I watched as Claude transformed from code generator to educator"
              }
            },
            {
              "source_index": 56,
              "source_sentence": "\"Let me know when you're ready for Stage 3.\" \"Please confirm the files have been created successfully.\" The checkpoints weren't automatic",
              "best_match": {
                "index": 18,
                "lexical": 0.13570167029438626,
                "semantic": 0.532260537147522,
                "combined": 0.33398110372095413,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 57,
              "source_sentence": "They demanded explicit human verification before moving forward",
              "best_match": {
                "index": 18,
                "lexical": 0.19100497396232305,
                "semantic": 0.5969235301017761,
                "combined": 0.3939642520320496,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 58,
              "source_sentence": "Maybe an error per stage: the LDA import failure, sentence_transformers compatibility issues, file path corrections when Colab duplicated folders",
              "best_match": {
                "index": 66,
                "lexical": 0.11989507583695667,
                "semantic": 0.5503756999969482,
                "combined": 0.33513538791695247,
                "target_sentence": "Colab still doubled up on folders sometimes"
              }
            },
            {
              "source_index": 59,
              "source_sentence": "But each was caught, assessed, and resolved before it could cascade",
              "best_match": {
                "index": 62,
                "lexical": 0.18797564687975646,
                "semantic": 0.36292606592178345,
                "combined": 0.27545085640076994,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 60,
              "source_sentence": "## The Numbers That Told the Truth\n\nThe pipeline calculated cross-version similarities, and the extent of transformation became quantifiable for the first time",
              "best_match": {
                "index": 65,
                "lexical": 0.17796178117888842,
                "semantic": 0.4091760516166687,
                "combined": 0.29356891639777855,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 61,
              "source_sentence": "Draft to Final Overall Similarity: 43.1%\n\nLess than half the original content survived the complete revision process",
              "best_match": {
                "index": 1,
                "lexical": 0.21462330890118195,
                "semantic": 0.6594552993774414,
                "combined": 0.4370393041393117,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 62,
              "source_sentence": "The granular sentence-level analysis revealed even more dramatic patterns",
              "best_match": {
                "index": 41,
                "lexical": 0.1691386420939347,
                "semantic": 0.4361002743244171,
                "combined": 0.3026194582091759,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 63,
              "source_sentence": "\"Attribution mapping complete.\" I didn't even know what attribution mapping was, but there it was",
              "best_match": {
                "index": 75,
                "lexical": 0.12584933325655914,
                "semantic": 0.45744043588638306,
                "combined": 0.2916448845714711,
                "target_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide"
              }
            },
            {
              "source_index": 64,
              "source_sentence": "Content origins breakdown:\nContent origins breakdown:\n85.7% traced to the edited stage\n2.4% retained high similarity to the original draft\n11.9% was entirely new content\n\nThat 2.4% stopped me",
              "best_match": {
                "index": 1,
                "lexical": 0.16219209445374763,
                "semantic": 0.6138342618942261,
                "combined": 0.38801317817398684,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 65,
              "source_sentence": "The draft had 47 sentences",
              "best_match": {
                "index": 65,
                "lexical": 0.11846576420278514,
                "semantic": 0.5606175661087036,
                "combined": 0.33954166515574435,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 66,
              "source_sentence": "I'd consciously changed 36: rewrites, restructures, complete overhauls",
              "best_match": {
                "index": 81,
                "lexical": 0.10328638497652581,
                "semantic": 0.3644724488258362,
                "combined": 0.233879416901181,
                "target_sentence": "But the infrastructure was designed for iteration rather than perfection"
              }
            },
            {
              "source_index": 67,
              "source_sentence": "That meant 11 sentences should have stayed relatively unchanged",
              "best_match": {
                "index": 1,
                "lexical": 0.09392485029224878,
                "semantic": 0.4446030855178833,
                "combined": 0.269263967905066,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 68,
              "source_sentence": "Eleven sentences I'd left alone",
              "best_match": {
                "index": 41,
                "lexical": 0.13071895424836602,
                "semantic": 0.3652259409427643,
                "combined": 0.24797244759556514,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 69,
              "source_sentence": "The data disagreed",
              "best_match": {
                "index": 39,
                "lexical": 0.16745283018867926,
                "semantic": 0.5127077698707581,
                "combined": 0.3400803000297187,
                "target_sentence": "Then there was the complete dataset"
              }
            },
            {
              "source_index": 70,
              "source_sentence": "Only one sentence from the original 47 remained recognizably similar in the final version",
              "best_match": {
                "index": 1,
                "lexical": 0.1690526562956728,
                "semantic": 0.5519577264785767,
                "combined": 0.3605051913871247,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 71,
              "source_sentence": "One sentence",
              "best_match": {
                "index": 41,
                "lexical": 0.1919428904436137,
                "semantic": 0.42631995677948,
                "combined": 0.30913142361154683,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 72,
              "source_sentence": "Not eleven",
              "best_match": {
                "index": 24,
                "lexical": 0.12962962962962962,
                "semantic": 0.26217660307884216,
                "combined": 0.1959031163542359,
                "target_sentence": "No educational explanation"
              }
            },
            {
              "source_index": 73,
              "source_sentence": "The other ten sentences I thought I'd left untouched",
              "best_match": {
                "index": 67,
                "lexical": 0.15141752577319587,
                "semantic": 0.318940669298172,
                "combined": 0.23517909753568395,
                "target_sentence": "A minor annoyance I could probably fix myself"
              }
            },
            {
              "source_index": 74,
              "source_sentence": "The revision process had transformed them anyway",
              "best_match": {
                "index": 65,
                "lexical": 0.1455788959452858,
                "semantic": 0.4539715349674225,
                "combined": 0.29977521545635416,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 75,
              "source_sentence": "Paragraph reordering changed their context",
              "best_match": {
                "index": 41,
                "lexical": 0.08259587020648967,
                "semantic": 0.33501577377319336,
                "combined": 0.20880582198984152,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 76,
              "source_sentence": "Surrounding edits shifted their meaning",
              "best_match": {
                "index": 2,
                "lexical": 0.11904761904761905,
                "semantic": 0.4280608296394348,
                "combined": 0.27355422434352694,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 77,
              "source_sentence": "What I experienced as \"leaving sentences alone\" the algorithm saw as transformation",
              "best_match": {
                "index": 65,
                "lexical": 0.14616115111577888,
                "semantic": 0.49359872937202454,
                "combined": 0.3198799402439017,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 78,
              "source_sentence": "I hadn't just rewritten 36 sentences",
              "best_match": {
                "index": 1,
                "lexical": 0.13020721094931462,
                "semantic": 0.4348077178001404,
                "combined": 0.2825074643747275,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 79,
              "source_sentence": "I'd transformed 46 of them, often without conscious intent",
              "best_match": {
                "index": 34,
                "lexical": 0.09046509046509048,
                "semantic": 0.3295722007751465,
                "combined": 0.2100186456201185,
                "target_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
              }
            },
            {
              "source_index": 80,
              "source_sentence": "For the first time, I had proof of what I'd suspected but couldn't measure",
              "best_match": {
                "index": 3,
                "lexical": 0.2483265081928462,
                "semantic": 0.3283420205116272,
                "combined": 0.2883342643522367,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 81,
              "source_sentence": "Revision changes everything, even the parts you think you're preserving",
              "best_match": {
                "index": 65,
                "lexical": 0.10237275162648296,
                "semantic": 0.46365123987197876,
                "combined": 0.28301199574923086,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 82,
              "source_sentence": "The vast majority of the final article bore little resemblance to the original AI output",
              "best_match": {
                "index": 2,
                "lexical": 0.14142407784292182,
                "semantic": 0.6490311622619629,
                "combined": 0.3952276200524424,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 83,
              "source_sentence": "More importantly, they demolished the notion that human editing could be tracked by counting deliberate changes",
              "best_match": {
                "index": 2,
                "lexical": 0.22335713222036846,
                "semantic": 0.6133856177330017,
                "combined": 0.4183713749766851,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 84,
              "source_sentence": "The transformation ran deeper than conscious decisions",
              "best_match": {
                "index": 2,
                "lexical": 0.16781496062992127,
                "semantic": 0.4030177593231201,
                "combined": 0.2854163599765207,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 85,
              "source_sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis",
              "best_match": {
                "index": 60,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis"
              }
            },
            {
              "source_index": 86,
              "source_sentence": "The notebook environment provided transparent documentation of every step",
              "best_match": {
                "index": 61,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "The notebook environment provided transparent documentation of every step"
              }
            },
            {
              "source_index": 87,
              "source_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding",
              "best_match": {
                "index": 62,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 88,
              "source_sentence": "Once complete, the full notebook took about three hours to run from start to finish",
              "best_match": {
                "index": 63,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Once complete, the full notebook took about three hours to run from start to finish"
              }
            },
            {
              "source_index": 89,
              "source_sentence": "Time to do something else while the pipeline processed everything",
              "best_match": {
                "index": 64,
                "lexical": 1.0,
                "semantic": 0.9999999403953552,
                "combined": 0.9999999701976776,
                "target_sentence": "Time to do something else while the pipeline processed everything"
              }
            },
            {
              "source_index": 90,
              "source_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way",
              "best_match": {
                "index": 65,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way"
              }
            },
            {
              "source_index": 91,
              "source_sentence": "Colab still doubled up on folders sometimes",
              "best_match": {
                "index": 66,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Colab still doubled up on folders sometimes"
              }
            },
            {
              "source_index": 92,
              "source_sentence": "A minor annoyance I could probably fix myself",
              "best_match": {
                "index": 67,
                "lexical": 1.0000000000000002,
                "semantic": 1.000000238418579,
                "combined": 1.0000001192092896,
                "target_sentence": "A minor annoyance I could probably fix myself"
              }
            },
            {
              "source_index": 93,
              "source_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing",
              "best_match": {
                "index": 68,
                "lexical": 1.0,
                "semantic": 0.9999998807907104,
                "combined": 0.9999999403953552,
                "target_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing"
              }
            },
            {
              "source_index": 94,
              "source_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging",
              "best_match": {
                "index": 69,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging"
              }
            },
            {
              "source_index": 95,
              "source_sentence": "## Visualizations That Actually Worked\n\nThe structured data pipeline enabled visualization capabilities that emerged naturally",
              "best_match": {
                "index": 35,
                "lexical": 0.14156058371540373,
                "semantic": 0.5158259868621826,
                "combined": 0.32869328528879316,
                "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles"
              }
            },
            {
              "source_index": 96,
              "source_sentence": "Flow diagrams showed content evolution",
              "best_match": {
                "index": 2,
                "lexical": 0.15311484216088883,
                "semantic": 0.3880833387374878,
                "combined": 0.2705990904491883,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 97,
              "source_sentence": "Heatmaps revealed modification patterns",
              "best_match": {
                "index": 37,
                "lexical": 0.12612612612612614,
                "semantic": 0.28588563203811646,
                "combined": 0.2060058790821213,
                "target_sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines"
              }
            },
            {
              "source_index": 98,
              "source_sentence": "The system generated an interactive HTML Sankey diagram that made attribution analysis clear",
              "best_match": {
                "index": 6,
                "lexical": 0.1792123682584149,
                "semantic": 0.42543506622314453,
                "combined": 0.3023237172407797,
                "target_sentence": "HTML interfaces that couldn't actually analyze anything"
              }
            },
            {
              "source_index": 99,
              "source_sentence": "Unlike previous attempts where Claude's impressive-looking charts broke during export, this approach separated data generation from visualization",
              "best_match": {
                "index": 35,
                "lexical": 0.10547006387986309,
                "semantic": 0.43991467356681824,
                "combined": 0.2726923687233407,
                "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles"
              }
            },
            {
              "source_index": 100,
              "source_sentence": "The JSON exports could feed any charting system",
              "best_match": {
                "index": 83,
                "lexical": 0.20797108341216727,
                "semantic": 0.4689991772174835,
                "combined": 0.3384851303148254,
                "target_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps"
              }
            },
            {
              "source_index": 101,
              "source_sentence": "When one approach failed, alternatives worked with the same data",
              "best_match": {
                "index": 72,
                "lexical": 0.17845117845117844,
                "semantic": 0.3650628924369812,
                "combined": 0.2717570354440798,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 102,
              "source_sentence": "At 11 PM, I opened the JSON output in Sublime",
              "best_match": {
                "index": 36,
                "lexical": 0.17296021226855204,
                "semantic": 0.24200360476970673,
                "combined": 0.2074819085191294,
                "target_sentence": "The json for the footer looked like the information provided in Colab"
              }
            },
            {
              "source_index": 103,
              "source_sentence": "Fourteen decimals on almost everything, far more precision than necessary, but it was there",
              "best_match": {
                "index": 43,
                "lexical": 0.28527146745661197,
                "semantic": 0.6410315036773682,
                "combined": 0.46315148556699004,
                "target_sentence": "Fourteen decimals on every datapoint; everything necessary for it to be AI-friendly so I can use the numbers again in the future"
              }
            },
            {
              "source_index": 104,
              "source_sentence": "The archive didn't need to be human-friendly",
              "best_match": {
                "index": 83,
                "lexical": 0.13107822410147993,
                "semantic": 0.3418115973472595,
                "combined": 0.23644491072436974,
                "target_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps"
              }
            },
            {
              "source_index": 105,
              "source_sentence": "It needed to be AI-friendly, structured data I could feed into future analysis without re-running the entire pipeline",
              "best_match": {
                "index": 83,
                "lexical": 0.2347052868729332,
                "semantic": 0.5170291066169739,
                "combined": 0.37586719674495356,
                "target_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps"
              }
            },
            {
              "source_index": 106,
              "source_sentence": "I could literally read through and check if it'd screwed up sentence parsing",
              "best_match": {
                "index": 41,
                "lexical": 0.11009933853710517,
                "semantic": 0.3799770176410675,
                "combined": 0.24503817808908634,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 107,
              "source_sentence": "Found mistakes immediately: \"Your diagram or approach, structured verse\" counted the period but missed the second sentence",
              "best_match": {
                "index": 81,
                "lexical": 0.14461626575028635,
                "semantic": 0.2926749587059021,
                "combined": 0.21864561222809423,
                "target_sentence": "But the infrastructure was designed for iteration rather than perfection"
              }
            },
            {
              "source_index": 108,
              "source_sentence": "The character count was off",
              "best_match": {
                "index": 34,
                "lexical": 0.1313318808633394,
                "semantic": 0.49694985151290894,
                "combined": 0.3141408661881242,
                "target_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
              }
            },
            {
              "source_index": 109,
              "source_sentence": "But I didn't care about perfect character counts anymore",
              "best_match": {
                "index": 34,
                "lexical": 0.09152313407632556,
                "semantic": 0.4478718042373657,
                "combined": 0.26969746915684567,
                "target_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
              }
            },
            {
              "source_index": 110,
              "source_sentence": "The semantic analysis was there",
              "best_match": {
                "index": 39,
                "lexical": 0.26641414141414144,
                "semantic": 0.36163607239723206,
                "combined": 0.31402510690568675,
                "target_sentence": "Then there was the complete dataset"
              }
            },
            {
              "source_index": 111,
              "source_sentence": "The system even included trend analysis capabilities, though these remained untested due to limited historical data",
              "best_match": {
                "index": 3,
                "lexical": 0.15752621945598397,
                "semantic": 0.448756605386734,
                "combined": 0.303141412421359,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 112,
              "source_sentence": "The Colab system produced verifiable metrics that could be audited, replicated, and trusted",
              "best_match": {
                "index": 78,
                "lexical": 0.18874562441376508,
                "semantic": 0.4822816252708435,
                "combined": 0.3355136248423043,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 113,
              "source_sentence": "It was the foundation for informed evaluation of mixed-authorship content",
              "best_match": {
                "index": 79,
                "lexical": 0.10784313725490197,
                "semantic": 0.3755669593811035,
                "combined": 0.24170504831800274,
                "target_sentence": "Multiple articles could be analyzed using identical methodology"
              }
            },
            {
              "source_index": 114,
              "source_sentence": "## The Fairy Tale Tax\n\nI'd expected the pipeline to just work once it was properly designed",
              "best_match": {
                "index": 47,
                "lexical": 0.2586068104879696,
                "semantic": 0.543169379234314,
                "combined": 0.40088809486114174,
                "target_sentence": "## The Fairy Tale Tax\n\nI came with a Python script that worked, it had a \"statistically acceptable level of variance\", but it worked"
              }
            },
            {
              "source_index": 115,
              "source_sentence": "Clean infrastructure, systematic checkpoints, reproducible outputs",
              "best_match": {
                "index": 62,
                "lexical": 0.12819514530286266,
                "semantic": 0.6261794567108154,
                "combined": 0.37718730100683906,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 116,
              "source_sentence": "What could go wrong",
              "best_match": {
                "index": 67,
                "lexical": 0.134469696969697,
                "semantic": 0.3329284191131592,
                "combined": 0.2336990580414281,
                "target_sentence": "A minor annoyance I could probably fix myself"
              }
            },
            {
              "source_index": 117,
              "source_sentence": "Everything still required constant human partnership",
              "best_match": {
                "index": 57,
                "lexical": 0.09773123909249563,
                "semantic": 0.4476362466812134,
                "combined": 0.2726837428868545,
                "target_sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 118,
              "source_sentence": "When library imports failed, human intervention guided recovery",
              "best_match": {
                "index": 72,
                "lexical": 0.15251897860593513,
                "semantic": 0.38232505321502686,
                "combined": 0.267422015910481,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 119,
              "source_sentence": "When file paths duplicated folders, human oversight corrected the mistakes",
              "best_match": {
                "index": 68,
                "lexical": 0.1341991341991342,
                "semantic": 0.5365577340126038,
                "combined": 0.335378434105869,
                "target_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing"
              }
            },
            {
              "source_index": 120,
              "source_sentence": "Regex patterns demanded testing against edge cases",
              "best_match": {
                "index": 62,
                "lexical": 0.08785529715762275,
                "semantic": 0.2317579984664917,
                "combined": 0.15980664781205722,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 121,
              "source_sentence": "Is it perfect",
              "best_match": {
                "index": 30,
                "lexical": 0.07207207207207207,
                "semantic": 0.2846255302429199,
                "combined": 0.178348801157496,
                "target_sentence": "An hour and a half later"
              }
            },
            {
              "source_index": 122,
              "source_sentence": "Probably not",
              "best_match": {
                "index": 67,
                "lexical": 0.22358513694096707,
                "semantic": 0.14654666185379028,
                "combined": 0.18506589939737866,
                "target_sentence": "A minor annoyance I could probably fix myself"
              }
            },
            {
              "source_index": 123,
              "source_sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after",
              "best_match": {
                "index": 55,
                "lexical": 0.9999999999999997,
                "semantic": 1.0,
                "combined": 0.9999999999999998,
                "target_sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
              }
            },
            {
              "source_index": 124,
              "source_sentence": "The \"AI Tax\" evolved but didn't disappear",
              "best_match": {
                "index": 56,
                "lexical": 1.0,
                "semantic": 0.9999998807907104,
                "combined": 0.9999999403953552,
                "target_sentence": "The \"AI Tax\" evolved but didn't disappear"
              }
            },
            {
              "source_index": 125,
              "source_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI",
              "best_match": {
                "index": 57,
                "lexical": 0.9316770186335401,
                "semantic": 0.9804929494857788,
                "combined": 0.9560849840596595,
                "target_sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 126,
              "source_sentence": "Even in success, oversight, verification, and quality assurance weren't obstacles to efficiency",
              "best_match": {
                "index": 58,
                "lexical": 0.6831758907468689,
                "semantic": 0.8530926704406738,
                "combined": 0.7681342805937714,
                "target_sentence": "Oversight, verification, and quality assurance aren't obstacles to efficiency"
              }
            },
            {
              "source_index": 127,
              "source_sentence": "They were the mechanisms that made AI assistance trustworthy",
              "best_match": {
                "index": 59,
                "lexical": 0.7032752595745864,
                "semantic": 0.9001432061195374,
                "combined": 0.8017092328470619,
                "target_sentence": "They're the mechanisms that make AI assistance trustworthy"
              }
            },
            {
              "source_index": 128,
              "source_sentence": "## What Actually Made This Work\n\nModular design prevents cascading failures",
              "best_match": {
                "index": 70,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "## What Actually Made This Work\n\nModular design prevents cascading failures"
              }
            },
            {
              "source_index": 129,
              "source_sentence": "Seven distinct stages, each with its own checkpoint",
              "best_match": {
                "index": 71,
                "lexical": 1.0000000000000002,
                "semantic": 1.000000238418579,
                "combined": 1.0000001192092896,
                "target_sentence": "Seven distinct stages, each with its own checkpoint"
              }
            },
            {
              "source_index": 130,
              "source_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system",
              "best_match": {
                "index": 72,
                "lexical": 1.0,
                "semantic": 1.000000238418579,
                "combined": 1.0000001192092896,
                "target_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
              }
            },
            {
              "source_index": 131,
              "source_sentence": "Earlier attempts tried to do everything at once and collapsed under their own weight",
              "best_match": {
                "index": 73,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Earlier attempts tried to do everything at once and collapsed under their own weight"
              }
            },
            {
              "source_index": 132,
              "source_sentence": "Checkpoints demand human judgment",
              "best_match": {
                "index": 74,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Checkpoints demand human judgment"
              }
            },
            {
              "source_index": 133,
              "source_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide",
              "best_match": {
                "index": 75,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide"
              }
            },
            {
              "source_index": 134,
              "source_sentence": "Every checkpoint required editorial verification that felt collaborative rather than like failed automation",
              "best_match": {
                "index": 76,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Every checkpoint required editorial verification that felt collaborative rather than like failed automation"
              }
            },
            {
              "source_index": 135,
              "source_sentence": "Infrastructure enables rather than guarantees",
              "best_match": {
                "index": 77,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Infrastructure enables rather than guarantees"
              }
            },
            {
              "source_index": 136,
              "source_sentence": "The successful Colab deployment opened pathways that hadn't existed before",
              "best_match": {
                "index": 78,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 137,
              "source_sentence": "Multiple articles could be analyzed using identical methodology",
              "best_match": {
                "index": 79,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Multiple articles could be analyzed using identical methodology"
              }
            },
            {
              "source_index": 138,
              "source_sentence": "Automation became feasible for the first time",
              "best_match": {
                "index": 80,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Automation became feasible for the first time"
              }
            },
            {
              "source_index": 139,
              "source_sentence": "But the infrastructure was designed for iteration rather than perfection",
              "best_match": {
                "index": 81,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "But the infrastructure was designed for iteration rather than perfection"
              }
            },
            {
              "source_index": 140,
              "source_sentence": "Reproducibility builds trust",
              "best_match": {
                "index": 82,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Reproducibility builds trust"
              }
            },
            {
              "source_index": 141,
              "source_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps",
              "best_match": {
                "index": 83,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps"
              }
            },
            {
              "source_index": 142,
              "source_sentence": "Transparency shifted from aspiration to measurement, from manual estimation to algorithmic verification",
              "best_match": {
                "index": 84,
                "lexical": 1.0,
                "semantic": 0.9999998807907104,
                "combined": 0.9999999403953552,
                "target_sentence": "Transparency shifted from aspiration to measurement, from manual estimation to algorithmic verification"
              }
            },
            {
              "source_index": 143,
              "source_sentence": "That distinction mattered",
              "best_match": {
                "index": 85,
                "lexical": 1.0,
                "semantic": 0.9999999403953552,
                "combined": 0.9999999701976776,
                "target_sentence": "That distinction mattered"
              }
            },
            {
              "source_index": 144,
              "source_sentence": "Showing your work once is documentation",
              "best_match": {
                "index": 86,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Showing your work once is documentation"
              }
            },
            {
              "source_index": 145,
              "source_sentence": "Building infrastructure that makes showing your work repeatable is transparency",
              "best_match": {
                "index": 87,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Building infrastructure that makes showing your work repeatable is transparency"
              }
            },
            {
              "source_index": 146,
              "source_sentence": "## The Foundation That Almost Wasn't\n\nThe Colab pipeline established the computational backbone for systematic transparency",
              "best_match": {
                "index": 78,
                "lexical": 0.1744232154397185,
                "semantic": 0.5635713338851929,
                "combined": 0.3689972746624557,
                "target_sentence": "The successful Colab deployment opened pathways that hadn't existed before"
              }
            },
            {
              "source_index": 147,
              "source_sentence": "Its modular design, checkpoint workflow, and archival outputs created infrastructure that could support analysis at scale",
              "best_match": {
                "index": 62,
                "lexical": 0.14777777777777776,
                "semantic": 0.5949628949165344,
                "combined": 0.3713703363471561,
                "target_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
              }
            },
            {
              "source_index": 148,
              "source_sentence": "The markup languages test proved the concept could handle real-world complexity without collapsing",
              "best_match": {
                "index": 1,
                "lexical": 0.16744244712917278,
                "semantic": 0.4841580390930176,
                "combined": 0.3258002431110952,
                "target_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 149,
              "source_sentence": "But success revealed new challenges",
              "best_match": {
                "index": 8,
                "lexical": 0.11077593430534609,
                "semantic": 0.4270651936531067,
                "combined": 0.26892056397922637,
                "target_sentence": "Each failure had taught me something, but none had produced what I actually needed"
              }
            },
            {
              "source_index": 150,
              "source_sentence": "Single-article analysis was just the beginning",
              "best_match": {
                "index": 79,
                "lexical": 0.13455657492354742,
                "semantic": 0.6145287156105042,
                "combined": 0.3745426452670258,
                "target_sentence": "Multiple articles could be analyzed using identical methodology"
              }
            },
            {
              "source_index": 151,
              "source_sentence": "Trend identification across multiple pieces, automated disclosure generation, and reader-friendly visualization remained to be solved",
              "best_match": {
                "index": 35,
                "lexical": 0.12336220297579392,
                "semantic": 0.4116925597190857,
                "combined": 0.2675273813474398,
                "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles"
              }
            },
            {
              "source_index": 152,
              "source_sentence": "I'd lost a cumulative two days on the first several attempts with mediocre results I didn't bother using",
              "best_match": {
                "index": 44,
                "lexical": 0.18347569808202488,
                "semantic": 0.35455048084259033,
                "combined": 0.2690130894623076,
                "target_sentence": "I ran the same article through three more times and the results have been consistent"
              }
            },
            {
              "source_index": 153,
              "source_sentence": "This time felt different",
              "best_match": {
                "index": 85,
                "lexical": 0.12244897959183675,
                "semantic": 0.36153504252433777,
                "combined": 0.24199201105808726,
                "target_sentence": "That distinction mattered"
              }
            },
            {
              "source_index": 154,
              "source_sentence": "The victory wasn't just technical",
              "best_match": {
                "index": 81,
                "lexical": 0.15079365079365079,
                "semantic": 0.3730207085609436,
                "combined": 0.2619071796772972,
                "target_sentence": "But the infrastructure was designed for iteration rather than perfection"
              }
            },
            {
              "source_index": 155,
              "source_sentence": "I'd struggled so many times to get this working",
              "best_match": {
                "index": 67,
                "lexical": 0.07246376811594203,
                "semantic": 0.32965731620788574,
                "combined": 0.20106054216191388,
                "target_sentence": "A minor annoyance I could probably fix myself"
              }
            },
            {
              "source_index": 156,
              "source_sentence": "For the first time, the question \"How much of this was AI versus human?\" had a precise, reproducible answer",
              "best_match": {
                "index": 57,
                "lexical": 0.12862669541922647,
                "semantic": 0.5572407245635986,
                "combined": 0.34293370999141254,
                "target_sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 157,
              "source_sentence": "The foundation was solid",
              "best_match": {
                "index": 81,
                "lexical": 0.1527777777777778,
                "semantic": 0.2905457317829132,
                "combined": 0.2216617547803455,
                "target_sentence": "But the infrastructure was designed for iteration rather than perfection"
              }
            },
            {
              "source_index": 158,
              "source_sentence": "What came next would test whether precision could actually reshape how we think about authorship, accountability, and the future of human-AI collaboration in creative work",
              "best_match": {
                "index": 57,
                "lexical": 0.15995329776705416,
                "semantic": 0.5886698961257935,
                "combined": 0.3743115969464238,
                "target_sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 159,
              "source_sentence": "So that's a thing now, for real",
              "best_match": {
                "index": 39,
                "lexical": 0.12121212121212122,
                "semantic": 0.231942281126976,
                "combined": 0.17657720116954861,
                "target_sentence": "Then there was the complete dataset"
              }
            },
            {
              "source_index": 160,
              "source_sentence": "That's where the final article begins.",
              "best_match": {
                "index": 91,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "That's where the final article begins."
              }
            }
          ]
        },
        "paragraph_level": {
          "lexical": {
            "jaccard_similarity": 0.31392931392931395,
            "edit_similarity": 0.06761315715490582,
            "tfidf_similarity": 0.38225372150966996,
            "lexical_average": 0.2545987308646299
          },
          "semantic": {
            "semantic_similarity": 0.8168333768844604,
            "embedding_dim": 384
          },
          "combined": 0.5357160538745451
        }
      },
      {
        "version_pair": "edited_to_final",
        "full_text": {
          "lexical": {
            "jaccard_similarity": 0.7258726899383984,
            "edit_similarity": 0.8197801355958172,
            "tfidf_similarity": 0.9061936267437771,
            "lexical_average": 0.8172821507593309
          },
          "semantic": {
            "semantic_similarity": 0.9803972840309143,
            "embedding_dim": 384
          },
          "combined": 0.8988397173951226
        },
        "sentence_level": {
          "average_similarity": 0.7377116973518314,
          "individual_similarities": [
            0.28153004825324407,
            0.772959577844041,
            1.0000000596046448,
            0.9999999701976776,
            1.0,
            0.9999999403953553,
            1.0000000596046448,
            1.0000001192092896,
            1.0000000596046448,
            0.9807069744866639,
            1.0,
            0.8987123295719175,
            1.0,
            0.7395217316698437,
            1.0000000596046448,
            1.0,
            1.0000000596046448,
            1.0000000596046448,
            1.0,
            0.9829706401978768,
            1.0,
            1.0000000596046448,
            1.0000000596046448,
            1.0,
            1.0000000596046448,
            1.0,
            0.9142126693422341,
            0.4480967667051768,
            1.0000000596046446,
            0.6684183952947056,
            0.3758043972308497,
            1.0,
            0.9999999105930328,
            1.0,
            1.0,
            0.8295854226215549,
            1.0000000596046448,
            0.9999999701976777,
            0.9749618443998849,
            1.0000000596046448,
            1.0,
            1.0000000596046448,
            0.9443116045730897,
            0.6187913588256633,
            0.8471787275052198,
            0.7843911462786637,
            0.6515951073894197,
            0.7180157648473047,
            0.9834001608934246,
            0.9718218616011116,
            1.0,
            0.833333392937978,
            0.9063340687095496,
            0.9702602550878787,
            0.862975447341706,
            0.9999999999999998,
            0.8857334378289015,
            0.9560849840596595,
            0.9622188297701089,
            0.7240059247468611,
            0.44035360384358446,
            0.27805363994337445,
            0.4230232180851571,
            0.24351764276715937,
            0.2587245099845974,
            0.3514023764499089,
            0.3069506406016482,
            0.24009402350992218,
            0.3449846620256197,
            0.35845780078747713,
            0.2896924964464828,
            0.38019440446199854,
            0.34521380842781835,
            0.3241682126257441,
            0.38159875965666495,
            0.34677945078263933,
            0.3922438826110442,
            0.45598282100586024,
            0.3665498327054153,
            0.36056056567932276,
            0.2602164844489942,
            0.40059237480751736,
            0.4825807705192989,
            0.29089264718743774,
            0.246990758273339,
            0.28889569110805563,
            0.17908226748956835,
            0.36978300771594974,
            1.0,
            0.973962187344301,
            1.0,
            1.0000000596046448
          ],
          "detailed_analysis": [
            {
              "source_index": 0,
              "source_sentence": "Victory in a New Venue\n\n## The Notebook That Finally Counted\n\nThis is the fourth in a series documenting attempts to build a system that tracks human versus machine contributions in writing",
              "best_match": {
                "index": 44,
                "lexical": 0.11489903092802743,
                "semantic": 0.4481610655784607,
                "combined": 0.28153004825324407,
                "target_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
              }
            },
            {
              "source_index": 1,
              "source_sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact",
              "best_match": {
                "index": 3,
                "lexical": 0.7098650690029012,
                "semantic": 0.8360540866851807,
                "combined": 0.772959577844041,
                "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 2,
              "source_sentence": "The AI accelerated expansion, but human editing shaped the actual content",
              "best_match": {
                "index": 4,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
              }
            },
            {
              "source_index": 3,
              "source_sentence": "For the first time, the system didn't collapse under the weight of real data",
              "best_match": {
                "index": 5,
                "lexical": 1.0,
                "semantic": 0.9999999403953552,
                "combined": 0.9999999701976776,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 4,
              "source_sentence": "## Python's Laboratory\n\nI'd already paid the tuition",
              "best_match": {
                "index": 6,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "## Python's Laboratory\n\nI'd already paid the tuition"
              }
            },
            {
              "source_index": 5,
              "source_sentence": "Python scripts that produced empty CSVs",
              "best_match": {
                "index": 7,
                "lexical": 1.0000000000000002,
                "semantic": 0.9999998807907104,
                "combined": 0.9999999403953553,
                "target_sentence": "Python scripts that produced empty CSVs"
              }
            },
            {
              "source_index": 6,
              "source_sentence": "HTML interfaces that couldn't actually analyze anything",
              "best_match": {
                "index": 8,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "HTML interfaces that couldn't actually analyze anything"
              }
            },
            {
              "source_index": 7,
              "source_sentence": "Semantic similarity scores that changed every time I blinked",
              "best_match": {
                "index": 9,
                "lexical": 1.0,
                "semantic": 1.000000238418579,
                "combined": 1.0000001192092896,
                "target_sentence": "Semantic similarity scores that changed every time I blinked"
              }
            },
            {
              "source_index": 8,
              "source_sentence": "Each failure had taught me something, but none had produced what I actually needed",
              "best_match": {
                "index": 10,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Each failure had taught me something, but none had produced what I actually needed"
              }
            },
            {
              "source_index": 9,
              "source_sentence": "> Then Claude asked  \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed",
              "best_match": {
                "index": 11,
                "lexical": 0.9640826873385012,
                "semantic": 0.9973312616348267,
                "combined": 0.9807069744866639,
                "target_sentence": "> Then Claude asked, \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed"
              }
            },
            {
              "source_index": 10,
              "source_sentence": "Twenty minutes later, I was staring at what looked like Google Docs had a baby with a Jupyter Notebook",
              "best_match": {
                "index": 12,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Twenty minutes later, I was staring at what looked like Google Docs had a baby with a Jupyter Notebook"
              }
            },
            {
              "source_index": 11,
              "source_sentence": "By now, I had learned to request complex or long items in chunks, effectively making the AI in question work in steps rather than spitting out a not-so-comprehensive artifact",
              "best_match": {
                "index": 15,
                "lexical": 0.8447279781211909,
                "semantic": 0.952696681022644,
                "combined": 0.8987123295719175,
                "target_sentence": "By now, I had learned to request complex or long items in pieces, effectively making the AI work in steps rather than spitting out a not-so-comprehensive artifact"
              }
            },
            {
              "source_index": 12,
              "source_sentence": "I watched as Claude transformed from code generator to educator",
              "best_match": {
                "index": 16,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "I watched as Claude transformed from code generator to educator"
              }
            },
            {
              "source_index": 13,
              "source_sentence": "It wasn't just solving my problem—it was ensuring I understood the solution",
              "best_match": {
                "index": 18,
                "lexical": 0.5934963022373926,
                "semantic": 0.8855471611022949,
                "combined": 0.7395217316698437,
                "target_sentence": "It was ensuring I understood the solution"
              }
            },
            {
              "source_index": 14,
              "source_sentence": "Each function included not just what it did, but why it mattered",
              "best_match": {
                "index": 19,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Each function included not just what it did, but why it mattered"
              }
            },
            {
              "source_index": 15,
              "source_sentence": "After months of black-box solutions, I had a patient tutor explaining every step",
              "best_match": {
                "index": 20,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "After months of black-box solutions, I had a patient tutor explaining every step"
              }
            },
            {
              "source_index": 16,
              "source_sentence": "This was acknowledging the actual complexity of the problem and helping the dope that showed up with a silly little script understand the purpose of the code",
              "best_match": {
                "index": 21,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "This was acknowledging the actual complexity of the problem and helping the dope that showed up with a silly little script understand the purpose of the code"
              }
            },
            {
              "source_index": 17,
              "source_sentence": "### And Then, Secret CELL 11\n\nUp to this point every cell ran for less than a minute",
              "best_match": {
                "index": 22,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "### And Then, Secret CELL 11\n\nUp to this point every cell ran for less than a minute"
              }
            },
            {
              "source_index": 18,
              "source_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well",
              "best_match": {
                "index": 23,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 19,
              "source_sentence": "`plaintext\n#CELL 10: QUICK EXECUTION FOR EXISTING DATA\n`\n\nPrior cells had been monolithic in comparison to what I had been punished with time and time again",
              "best_match": {
                "index": 24,
                "lexical": 0.969032258064516,
                "semantic": 0.9969090223312378,
                "combined": 0.9829706401978768,
                "target_sentence": "`plaintext\n#CELL 10: QUICK EXECUTION FOR EXISTING DATA\n`\n\nPrior cells had been monolithic in comparison to what I'd been punished with time and time again"
              }
            },
            {
              "source_index": 20,
              "source_sentence": "Cell 10 was a fraction by comparison, a meager 34 lines of code",
              "best_match": {
                "index": 25,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Cell 10 was a fraction by comparison, a meager 34 lines of code"
              }
            },
            {
              "source_index": 21,
              "source_sentence": "Then there was an inconspicuous cell",
              "best_match": {
                "index": 26,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Then there was an inconspicuous cell"
              }
            },
            {
              "source_index": 22,
              "source_sentence": "A mere 3 lines of code",
              "best_match": {
                "index": 27,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "A mere 3 lines of code"
              }
            },
            {
              "source_index": 23,
              "source_sentence": "> No title in CAPS proclaiming its presence",
              "best_match": {
                "index": 28,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "> No title in CAPS proclaiming its presence"
              }
            },
            {
              "source_index": 24,
              "source_sentence": "No educational explanation",
              "best_match": {
                "index": 29,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "No educational explanation"
              }
            },
            {
              "source_index": 25,
              "source_sentence": "No warning",
              "best_match": {
                "index": 30,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "No warning"
              }
            },
            {
              "source_index": 26,
              "source_sentence": "I still don't know Python, but I know you don't have to be able to read or write it to miss hints at it's purpose",
              "best_match": {
                "index": 31,
                "lexical": 0.862992754398732,
                "semantic": 0.9654325842857361,
                "combined": 0.9142126693422341,
                "target_sentence": "I still don't know Python, but I know you don't have to be able to read or write it to see the hints at its purpose"
              }
            },
            {
              "source_index": 27,
              "source_sentence": "I don't know that I would have picked up on it then but I see it plain as day now",
              "best_match": {
                "index": 32,
                "lexical": 0.7123332612412404,
                "semantic": 0.18386027216911316,
                "combined": 0.4480967667051768,
                "target_sentence": "I don't know that I would've picked up on run_complete_analysis then but I see it plain as day now"
              }
            },
            {
              "source_index": 28,
              "source_sentence": "`plaintext\ncombined_results, footer_metrics = run_complete_analysis_from_existing(\n    article_versions, preprocessor\n)\n`\n\nThe cell ran past a minute, the spinner kept spinning, and nothing happened",
              "best_match": {
                "index": 33,
                "lexical": 0.9999999999999997,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046446,
                "target_sentence": "`plaintext\ncombined_results, footer_metrics = run_complete_analysis_from_existing(\n    article_versions, preprocessor\n)\n`\n\nThe cell ran past a minute, the spinner kept spinning, and nothing happened"
              }
            },
            {
              "source_index": 29,
              "source_sentence": "> I had paid my taxes in full, and this is when the Fairy delivered",
              "best_match": {
                "index": 34,
                "lexical": 0.5023767705241037,
                "semantic": 0.8344600200653076,
                "combined": 0.6684183952947056,
                "target_sentence": "> I'd paid my taxes in full, and the Fairy finally delivered...an hour and a half later"
              }
            },
            {
              "source_index": 30,
              "source_sentence": "An hour and a half later",
              "best_match": {
                "index": 34,
                "lexical": 0.38598949266573995,
                "semantic": 0.3656193017959595,
                "combined": 0.3758043972308497,
                "target_sentence": "> I'd paid my taxes in full, and the Fairy finally delivered...an hour and a half later"
              }
            },
            {
              "source_index": 31,
              "source_sentence": "When the results appeared the moment was anticlimactic to say the least",
              "best_match": {
                "index": 35,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "When the results appeared the moment was anticlimactic to say the least"
              }
            },
            {
              "source_index": 32,
              "source_sentence": "The question had been answered in a concise and meaningful way",
              "best_match": {
                "index": 36,
                "lexical": 1.0,
                "semantic": 0.9999998211860657,
                "combined": 0.9999999105930328,
                "target_sentence": "The question had been answered in a concise and meaningful way"
              }
            },
            {
              "source_index": 33,
              "source_sentence": "Results that I failed to copy from the notebook",
              "best_match": {
                "index": 37,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Results that I failed to copy from the notebook"
              }
            },
            {
              "source_index": 34,
              "source_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following",
              "best_match": {
                "index": 38,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
              }
            },
            {
              "source_index": 35,
              "source_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles",
              "best_match": {
                "index": 39,
                "lexical": 0.7189969808784857,
                "semantic": 0.940173864364624,
                "combined": 0.8295854226215549,
                "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started, I'd requested data for visualizations and a subset of that data for charts I could add at the end of the articles"
              }
            },
            {
              "source_index": 36,
              "source_sentence": "The json for the footer looked like the information provided in Colab",
              "best_match": {
                "index": 40,
                "lexical": 1.0000000000000002,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "The json for the footer looked like the information provided in Colab"
              }
            },
            {
              "source_index": 37,
              "source_sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines",
              "best_match": {
                "index": 41,
                "lexical": 1.0000000000000002,
                "semantic": 0.9999999403953552,
                "combined": 0.9999999701976777,
                "target_sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines"
              }
            },
            {
              "source_index": 38,
              "source_sentence": "> Spoiler, it turns out the article was about using Mermaid AI, not markup",
              "best_match": {
                "index": 42,
                "lexical": 0.9510510510510514,
                "semantic": 0.9988726377487183,
                "combined": 0.9749618443998849,
                "target_sentence": "> Spoiler: it turns out the article was about using Mermaid AI, not markup"
              }
            },
            {
              "source_index": 39,
              "source_sentence": "Then there was the complete dataset",
              "best_match": {
                "index": 43,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Then there was the complete dataset"
              }
            },
            {
              "source_index": 40,
              "source_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable",
              "best_match": {
                "index": 44,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
              }
            },
            {
              "source_index": 41,
              "source_sentence": "Every sentence from every version of the article with the relevant data",
              "best_match": {
                "index": 45,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "Every sentence from every version of the article with the relevant data"
              }
            },
            {
              "source_index": 42,
              "source_sentence": "A summary of the data, the actual data, an index of the data, and so on",
              "best_match": {
                "index": 46,
                "lexical": 0.9001182033096926,
                "semantic": 0.9885050058364868,
                "combined": 0.9443116045730897,
                "target_sentence": "A summary of the data, the actual data, an index of the data, and more"
              }
            },
            {
              "source_index": 43,
              "source_sentence": "Fourteen decimals on every datapoint; everything necessary for it to be AI-friendly so I can use the numbers again in the future",
              "best_match": {
                "index": 48,
                "lexical": 0.6279559476317953,
                "semantic": 0.6096267700195312,
                "combined": 0.6187913588256633,
                "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
              }
            },
            {
              "source_index": 44,
              "source_sentence": "I ran the same article through three more times and the results have been consistent",
              "best_match": {
                "index": 49,
                "lexical": 0.7193691136789578,
                "semantic": 0.9749883413314819,
                "combined": 0.8471787275052198,
                "target_sentence": "I ran the same article through three more times and got consistent results"
              }
            },
            {
              "source_index": 45,
              "source_sentence": "All fourteen decimal points",
              "best_match": {
                "index": 50,
                "lexical": 0.6647202002530977,
                "semantic": 0.9040620923042297,
                "combined": 0.7843911462786637,
                "target_sentence": "All fourteen decimal points, every time"
              }
            },
            {
              "source_index": 46,
              "source_sentence": "> \"I think I love you right now,\" I typed, \"Now I need visuals.\"\n\nComplete, reliable, transparency",
              "best_match": {
                "index": 52,
                "lexical": 0.5626361800689091,
                "semantic": 0.7405540347099304,
                "combined": 0.6515951073894197,
                "target_sentence": "\"Now I need visuals.\"\n\nComplete, reliable transparency"
              }
            },
            {
              "source_index": 47,
              "source_sentence": "## The Fairy Tale Tax\n\nI came with a Python script that worked, it had a \"statistically acceptable level of variance\", but it worked",
              "best_match": {
                "index": 53,
                "lexical": 0.6209186408815905,
                "semantic": 0.8151128888130188,
                "combined": 0.7180157648473047,
                "target_sentence": "## The Fairy Tale Tax\n\nI came up with a Python script that worked"
              }
            },
            {
              "source_index": 48,
              "source_sentence": "I paid the Fairy Tale Tax several times:\nBlindly following an AI producing code I couldn't read that failed time and time again",
              "best_match": {
                "index": 55,
                "lexical": 0.9670722977809593,
                "semantic": 0.9997280240058899,
                "combined": 0.9834001608934246,
                "target_sentence": "I paid the Fairy Tale Tax several times:\nBlindly following an AI producing code I couldn’t read that failed time and time again"
              }
            },
            {
              "source_index": 49,
              "source_sentence": "Expecting AI to deliver what I couldn't really define because I heard what I wanted",
              "best_match": {
                "index": 56,
                "lexical": 0.9447018844609206,
                "semantic": 0.9989418387413025,
                "combined": 0.9718218616011116,
                "target_sentence": "Expecting AI to deliver what I couldn’t really define because I heard what I wanted"
              }
            },
            {
              "source_index": 50,
              "source_sentence": "Repeated frustration that resulted in me giving up more than once",
              "best_match": {
                "index": 57,
                "lexical": 1.0000000000000002,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "Repeated frustration that resulted in me giving up more than once"
              }
            },
            {
              "source_index": 51,
              "source_sentence": "And then some",
              "best_match": {
                "index": 58,
                "lexical": 0.6666666666666666,
                "semantic": 1.0000001192092896,
                "combined": 0.833333392937978,
                "target_sentence": "And then some"
              }
            },
            {
              "source_index": 52,
              "source_sentence": "This time the tax wasn't about believing in magic, that it would simply work out because I was using AI",
              "best_match": {
                "index": 59,
                "lexical": 0.8160779999374096,
                "semantic": 0.9965901374816895,
                "combined": 0.9063340687095496,
                "target_sentence": "This time the tax wasn’t about believing in magic or thinking it would simply work out because I was using AI"
              }
            },
            {
              "source_index": 53,
              "source_sentence": "It was about learning that having a vast amount of information at your fingertips might qualify as intelligent but it doesn't make you smart",
              "best_match": {
                "index": 60,
                "lexical": 0.943107947805457,
                "semantic": 0.9974125623703003,
                "combined": 0.9702602550878787,
                "target_sentence": "It was about learning that having a vast amount of information at your fingertips might qualify as intelligent, but it doesn’t make you smart"
              }
            },
            {
              "source_index": 54,
              "source_sentence": "Understanding how to into that vast amount of knowledge does",
              "best_match": {
                "index": 61,
                "lexical": 0.7915256598887952,
                "semantic": 0.9344252347946167,
                "combined": 0.862975447341706,
                "target_sentence": "Understanding how to use that vast amount of knowledge does"
              }
            },
            {
              "source_index": 55,
              "source_sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after",
              "best_match": {
                "index": 62,
                "lexical": 0.9999999999999997,
                "semantic": 1.0,
                "combined": 0.9999999999999998,
                "target_sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
              }
            },
            {
              "source_index": 56,
              "source_sentence": "The \"AI Tax\" evolved but didn't disappear",
              "best_match": {
                "index": 63,
                "lexical": 0.7756097560975611,
                "semantic": 0.9958571195602417,
                "combined": 0.8857334378289015,
                "target_sentence": "The “AI Tax” evolved but didn’t disappear"
              }
            },
            {
              "source_index": 57,
              "source_sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI",
              "best_match": {
                "index": 64,
                "lexical": 0.9316770186335401,
                "semantic": 0.9804929494857788,
                "combined": 0.9560849840596595,
                "target_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 58,
              "source_sentence": "Oversight, verification, and quality assurance aren't obstacles to efficiency",
              "best_match": {
                "index": 65,
                "lexical": 0.9290043290043292,
                "semantic": 0.9954333305358887,
                "combined": 0.9622188297701089,
                "target_sentence": "Oversight, verification, and quality assurance aren’t obstacles to efficiency"
              }
            },
            {
              "source_index": 59,
              "source_sentence": "They're the mechanisms that make AI assistance trustworthy",
              "best_match": {
                "index": 66,
                "lexical": 0.5139801245639125,
                "semantic": 0.9340317249298096,
                "combined": 0.7240059247468611,
                "target_sentence": "They’re what makes AI assistance trustworthy"
              }
            },
            {
              "source_index": 60,
              "source_sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis",
              "best_match": {
                "index": 67,
                "lexical": 0.28624910450723723,
                "semantic": 0.5944581031799316,
                "combined": 0.44035360384358446,
                "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
              }
            },
            {
              "source_index": 61,
              "source_sentence": "The notebook environment provided transparent documentation of every step",
              "best_match": {
                "index": 44,
                "lexical": 0.11292335115864527,
                "semantic": 0.44318392872810364,
                "combined": 0.27805363994337445,
                "target_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
              }
            },
            {
              "source_index": 62,
              "source_sentence": "Most importantly, checkpoints could be inspected and verified before proceeding",
              "best_match": {
                "index": 23,
                "lexical": 0.1431957367455705,
                "semantic": 0.7028506994247437,
                "combined": 0.4230232180851571,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 63,
              "source_sentence": "Once complete, the full notebook took about three hours to run from start to finish",
              "best_match": {
                "index": 37,
                "lexical": 0.1811903825420702,
                "semantic": 0.30584490299224854,
                "combined": 0.24351764276715937,
                "target_sentence": "Results that I failed to copy from the notebook"
              }
            },
            {
              "source_index": 64,
              "source_sentence": "Time to do something else while the pipeline processed everything",
              "best_match": {
                "index": 80,
                "lexical": 0.13218390804597702,
                "semantic": 0.3852651119232178,
                "combined": 0.2587245099845974,
                "target_sentence": "Waiting becomes tolerable when you can see progress"
              }
            },
            {
              "source_index": 65,
              "source_sentence": "The system processed 863 words in the draft through to 892 words in the final version, tracking every transformation along the way",
              "best_match": {
                "index": 3,
                "lexical": 0.14432001979511197,
                "semantic": 0.5584847331047058,
                "combined": 0.3514023764499089,
                "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
              }
            },
            {
              "source_index": 66,
              "source_sentence": "Colab still doubled up on folders sometimes",
              "best_match": {
                "index": 67,
                "lexical": 0.16621705278303875,
                "semantic": 0.44768422842025757,
                "combined": 0.3069506406016482,
                "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
              }
            },
            {
              "source_index": 67,
              "source_sentence": "A minor annoyance I could probably fix myself",
              "best_match": {
                "index": 17,
                "lexical": 0.08547008547008546,
                "semantic": 0.3947179615497589,
                "combined": 0.24009402350992218,
                "target_sentence": "It wasn't just solving my problem"
              }
            },
            {
              "source_index": 68,
              "source_sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing",
              "best_match": {
                "index": 7,
                "lexical": 0.14926185506472822,
                "semantic": 0.5407074689865112,
                "combined": 0.3449846620256197,
                "target_sentence": "Python scripts that produced empty CSVs"
              }
            },
            {
              "source_index": 69,
              "source_sentence": "Manual verification at each stage was overhead, but it was productive overhead that increased confidence rather than consuming it through endless debugging",
              "best_match": {
                "index": 23,
                "lexical": 0.10872923740106516,
                "semantic": 0.6081863641738892,
                "combined": 0.35845780078747713,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 70,
              "source_sentence": "## What Actually Made This Work\n\nModular design prevents cascading failures",
              "best_match": {
                "index": 73,
                "lexical": 0.2151358230664581,
                "semantic": 0.36424916982650757,
                "combined": 0.2896924964464828,
                "target_sentence": "Segmentation prevents cascade failure"
              }
            },
            {
              "source_index": 71,
              "source_sentence": "Seven distinct stages, each with its own checkpoint",
              "best_match": {
                "index": 77,
                "lexical": 0.16610725470189017,
                "semantic": 0.5942815542221069,
                "combined": 0.38019440446199854,
                "target_sentence": "Each checkpoint isolates problems before they compound"
              }
            },
            {
              "source_index": 72,
              "source_sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system",
              "best_match": {
                "index": 76,
                "lexical": 0.21555490853501902,
                "semantic": 0.4748727083206177,
                "combined": 0.34521380842781835,
                "target_sentence": "Split into cells, failure becomes diagnostic rather than catastrophic"
              }
            },
            {
              "source_index": 73,
              "source_sentence": "Earlier attempts tried to do everything at once and collapsed under their own weight",
              "best_match": {
                "index": 5,
                "lexical": 0.19146142882776687,
                "semantic": 0.4568749964237213,
                "combined": 0.3241682126257441,
                "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
              }
            },
            {
              "source_index": 74,
              "source_sentence": "Checkpoints demand human judgment",
              "best_match": {
                "index": 77,
                "lexical": 0.1149425287356322,
                "semantic": 0.6482549905776978,
                "combined": 0.38159875965666495,
                "target_sentence": "Each checkpoint isolates problems before they compound"
              }
            },
            {
              "source_index": 75,
              "source_sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide",
              "best_match": {
                "index": 89,
                "lexical": 0.21972012521525727,
                "semantic": 0.47383877635002136,
                "combined": 0.34677945078263933,
                "target_sentence": "It's about knowing your measurements measure the same thing and provide reliable results"
              }
            },
            {
              "source_index": 76,
              "source_sentence": "Every checkpoint required editorial verification that felt collaborative rather than like failed automation",
              "best_match": {
                "index": 23,
                "lexical": 0.1605801991515318,
                "semantic": 0.6239075660705566,
                "combined": 0.3922438826110442,
                "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
              }
            },
            {
              "source_index": 77,
              "source_sentence": "Infrastructure enables rather than guarantees",
              "best_match": {
                "index": 68,
                "lexical": 0.2730796671276873,
                "semantic": 0.6388859748840332,
                "combined": 0.45598282100586024,
                "target_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure"
              }
            },
            {
              "source_index": 78,
              "source_sentence": "The successful Colab deployment opened pathways that hadn't existed before",
              "best_match": {
                "index": 67,
                "lexical": 0.1447157523706695,
                "semantic": 0.5883839130401611,
                "combined": 0.3665498327054153,
                "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
              }
            },
            {
              "source_index": 79,
              "source_sentence": "Multiple articles could be analyzed using identical methodology",
              "best_match": {
                "index": 49,
                "lexical": 0.1070559610705596,
                "semantic": 0.6140651702880859,
                "combined": 0.36056056567932276,
                "target_sentence": "I ran the same article through three more times and got consistent results"
              }
            },
            {
              "source_index": 80,
              "source_sentence": "Automation became feasible for the first time",
              "best_match": {
                "index": 64,
                "lexical": 0.08272283272283272,
                "semantic": 0.43771013617515564,
                "combined": 0.2602164844489942,
                "target_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI"
              }
            },
            {
              "source_index": 81,
              "source_sentence": "But the infrastructure was designed for iteration rather than perfection",
              "best_match": {
                "index": 68,
                "lexical": 0.22292540074571096,
                "semantic": 0.5782593488693237,
                "combined": 0.40059237480751736,
                "target_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure"
              }
            },
            {
              "source_index": 82,
              "source_sentence": "Reproducibility builds trust",
              "best_match": {
                "index": 88,
                "lexical": 0.28492234044655673,
                "semantic": 0.680239200592041,
                "combined": 0.4825807705192989,
                "target_sentence": "Reproducibility isn't about perfection"
              }
            },
            {
              "source_index": 83,
              "source_sentence": "The archival JSON format meant historical data could be aggregated and compared without re-running expensive computational steps",
              "best_match": {
                "index": 46,
                "lexical": 0.1510575145096106,
                "semantic": 0.4307277798652649,
                "combined": 0.29089264718743774,
                "target_sentence": "A summary of the data, the actual data, an index of the data, and more"
              }
            },
            {
              "source_index": 84,
              "source_sentence": "Transparency shifted from aspiration to measurement, from manual estimation to algorithmic verification",
              "best_match": {
                "index": 52,
                "lexical": 0.0827336670822615,
                "semantic": 0.4112478494644165,
                "combined": 0.246990758273339,
                "target_sentence": "\"Now I need visuals.\"\n\nComplete, reliable transparency"
              }
            },
            {
              "source_index": 85,
              "source_sentence": "That distinction mattered",
              "best_match": {
                "index": 19,
                "lexical": 0.18952937855590926,
                "semantic": 0.388262003660202,
                "combined": 0.28889569110805563,
                "target_sentence": "Each function included not just what it did, but why it mattered"
              }
            },
            {
              "source_index": 86,
              "source_sentence": "Showing your work once is documentation",
              "best_match": {
                "index": 44,
                "lexical": 0.10021786492374728,
                "semantic": 0.2579466700553894,
                "combined": 0.17908226748956835,
                "target_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
              }
            },
            {
              "source_index": 87,
              "source_sentence": "Building infrastructure that makes showing your work repeatable is transparency",
              "best_match": {
                "index": 52,
                "lexical": 0.15749494952918947,
                "semantic": 0.58207106590271,
                "combined": 0.36978300771594974,
                "target_sentence": "\"Now I need visuals.\"\n\nComplete, reliable transparency"
              }
            },
            {
              "source_index": 88,
              "source_sentence": "I finally have what I originally asked for",
              "best_match": {
                "index": 90,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "I finally have what I originally asked for"
              }
            },
            {
              "source_index": 89,
              "source_sentence": "It has cells to measure trends over time, it produces visualizations so you don't have to read a fourteen decimal dataset to make sense of it",
              "best_match": {
                "index": 91,
                "lexical": 0.9512411347517732,
                "semantic": 0.9966832399368286,
                "combined": 0.973962187344301,
                "target_sentence": "It has cells to measure trends over time and produces visualizations so you don't have to read a fourteen decimal dataset to make sense of it"
              }
            },
            {
              "source_index": 90,
              "source_sentence": "It's version 1.3",
              "best_match": {
                "index": 92,
                "lexical": 1.0,
                "semantic": 1.0,
                "combined": 1.0,
                "target_sentence": "It's version 1.3"
              }
            },
            {
              "source_index": 91,
              "source_sentence": "That's where the final article begins.",
              "best_match": {
                "index": 93,
                "lexical": 1.0,
                "semantic": 1.0000001192092896,
                "combined": 1.0000000596046448,
                "target_sentence": "That's where the final article begins."
              }
            }
          ]
        },
        "paragraph_level": {
          "lexical": {
            "jaccard_similarity": 0.7258726899383984,
            "edit_similarity": 0.8217890438400494,
            "tfidf_similarity": 0.9061936267437771,
            "lexical_average": 0.8179517868407417
          },
          "semantic": {
            "semantic_similarity": 0.9803972840309143,
            "embedding_dim": 384
          },
          "combined": 0.899174535435828
        }
      }
    ],
    "draft_to_final": {
      "version_pair": "draft_to_final",
      "full_text": {
        "lexical": {
          "jaccard_similarity": 0.1381294964028777,
          "edit_similarity": 0.01927605756650676,
          "tfidf_similarity": 0.23997407142901805,
          "lexical_average": 0.13245987513280086
        },
        "semantic": {
          "semantic_similarity": 0.5429775714874268,
          "embedding_dim": 384
        },
        "combined": 0.3377187233101138
      },
      "sentence_level": {
        "average_similarity": 0.30479663072101093,
        "individual_similarities": [
          0.24305448815765152,
          0.2545423353055738,
          0.4641836650321106,
          0.3120600406681218,
          0.2589383001497934,
          0.2935740846655296,
          0.3305360633600857,
          0.3237308057656833,
          0.3049262291390593,
          0.37798499473148356,
          0.28167576835033586,
          0.2916268185554609,
          0.26195949140954344,
          0.3433007581304157,
          0.3025083279732892,
          0.3890513812888831,
          0.32876339298564405,
          0.2882793184675647,
          0.2848131487040016,
          0.3408016314319007,
          0.24277647058256724,
          0.38559529063447173,
          0.29341819049140705,
          0.4462050466607886,
          0.33158474331677845,
          0.3074048633484547,
          0.30304112189164795,
          0.25330380190610274,
          0.28052355942499185,
          0.3250890458004989,
          0.2919489846491806,
          0.25422161033279017,
          0.275548144835742,
          0.32227039798156526,
          0.3429045595734872,
          0.23993434705805416,
          0.3011175232549932,
          0.38554934142130504,
          0.23372925405686257,
          0.2118695372163399,
          0.2747100711381661,
          0.3640629003133908,
          0.3053231798263521,
          0.318758256352636,
          0.25402631925556385,
          0.3457260794422862,
          0.24559815377595434,
          0.21658587395077109,
          0.28755872536202254,
          0.28347438573243844,
          0.3506433001297633,
          0.36014669218926637,
          0.25535828357236523,
          0.31513225798528693,
          0.31549216323809043,
          0.3010701291166131,
          0.2949361877514274,
          0.23903421679186443,
          0.3519910205472858,
          0.2824695097650589,
          0.3119554632173647,
          0.3160467694265211,
          0.30106711738120767,
          0.31147043117283985
        ],
        "detailed_analysis": [
          {
            "source_index": 0,
            "source_sentence": "Every fix spawned a new failure: paths that doubled back on themselves, outputs that silently dropped rows, functions that vanished after a simple rename",
            "best_match": {
              "index": 14,
              "lexical": 0.07228915662650602,
              "semantic": 0.413819819688797,
              "combined": 0.24305448815765152,
              "target_sentence": "What would've been multiple files and undoubtedly exponential failures with my previous approach"
            }
          },
          {
            "source_index": 1,
            "source_sentence": "Even when I got numbers, I couldn’t trust them—were they the product of my data, or of some invisible infrastructure glitch",
            "best_match": {
              "index": 47,
              "lexical": 0.07547169811320754,
              "semantic": 0.43361297249794006,
              "combined": 0.2545423353055738,
              "target_sentence": "Fourteen decimals on every datapoint"
            }
          },
          {
            "source_index": 2,
            "source_sentence": "So when Claude 4 suggested shifting the entire workflow into Google Colab, I approached it like my last shot",
            "best_match": {
              "index": 11,
              "lexical": 0.2324172391790589,
              "semantic": 0.6959500908851624,
              "combined": 0.4641836650321106,
              "target_sentence": "> Then Claude asked, \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed"
            }
          },
          {
            "source_index": 3,
            "source_sentence": "I didn’t know Python, I’d never touched Colab, and the idea of mounting drives and importing libraries felt like speaking another language",
            "best_match": {
              "index": 31,
              "lexical": 0.19142016258929537,
              "semantic": 0.43269991874694824,
              "combined": 0.3120600406681218,
              "target_sentence": "I still don't know Python, but I know you don't have to be able to read or write it to see the hints at its purpose"
            }
          },
          {
            "source_index": 4,
            "source_sentence": "But within minutes of running the same logic in this new space, the chaos stopped",
            "best_match": {
              "index": 5,
              "lexical": 0.13393489030431704,
              "semantic": 0.3839417099952698,
              "combined": 0.2589383001497934,
              "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
            }
          },
          {
            "source_index": 5,
            "source_sentence": "The pathing nightmares, missing file errors, and mid-run collapses that had become routine were gone",
            "best_match": {
              "index": 14,
              "lexical": 0.12118921642731166,
              "semantic": 0.46595895290374756,
              "combined": 0.2935740846655296,
              "target_sentence": "What would've been multiple files and undoubtedly exponential failures with my previous approach"
            }
          },
          {
            "source_index": 6,
            "source_sentence": "For the first time, the tool that was supposed to track AI’s role in my writing actually ran from start to finish, without my intervention—and without lying to me about what it had done",
            "best_match": {
              "index": 4,
              "lexical": 0.10299324164174119,
              "semantic": 0.5580788850784302,
              "combined": 0.3305360633600857,
              "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
            }
          },
          {
            "source_index": 7,
            "source_sentence": "---\n\n## Grounding Context\n\nThe point of this entire project was to create a transparent, repeatable way to measure human and AI contributions in my published work",
            "best_match": {
              "index": 48,
              "lexical": 0.13327552726088931,
              "semantic": 0.5141860842704773,
              "combined": 0.3237308057656833,
              "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
            }
          },
          {
            "source_index": 8,
            "source_sentence": "That meant tracking lexical and semantic changes across every stage—draft, refined, edited, final—and presenting those numbers as evidence in the footer of each article",
            "best_match": {
              "index": 45,
              "lexical": 0.1501208198465696,
              "semantic": 0.4597316384315491,
              "combined": 0.3049262291390593,
              "target_sentence": "Every sentence from every version of the article with the relevant data"
            }
          },
          {
            "source_index": 9,
            "source_sentence": "The problem: reproducibility only exists if the environment is stable",
            "best_match": {
              "index": 88,
              "lexical": 0.16095279471504234,
              "semantic": 0.5950171947479248,
              "combined": 0.37798499473148356,
              "target_sentence": "Reproducibility isn't about perfection"
            }
          },
          {
            "source_index": 10,
            "source_sentence": "Every time my setup changed—whether it was switching between AI chat sessions, running scripts locally, or patching broken code—the chain of trust broke",
            "best_match": {
              "index": 64,
              "lexical": 0.11334552855247836,
              "semantic": 0.45000600814819336,
              "combined": 0.28167576835033586,
              "target_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI"
            }
          },
          {
            "source_index": 11,
            "source_sentence": "Environment instability meant losing files between steps or generating metrics that couldn’t be replicated later",
            "best_match": {
              "index": 41,
              "lexical": 0.13520188645097922,
              "semantic": 0.4480517506599426,
              "combined": 0.2916268185554609,
              "target_sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines"
            }
          },
          {
            "source_index": 12,
            "source_sentence": "Toolchain sprawl—juggling JSON, XML, GitHub-hosted scripts, and multiple AI models—multiplied the failure points",
            "best_match": {
              "index": 64,
              "lexical": 0.10865521080828366,
              "semantic": 0.4152637720108032,
              "combined": 0.26195949140954344,
              "target_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI"
            }
          },
          {
            "source_index": 13,
            "source_sentence": "False stability was even worse: the AI’s tendency to declare success without verifying outputs produced a dangerous illusion of accuracy",
            "best_match": {
              "index": 1,
              "lexical": 0.15835475589248432,
              "semantic": 0.5282467603683472,
              "combined": 0.3433007581304157,
              "target_sentence": "It was letting the AI specify the right environment to actually execute what it promised"
            }
          },
          {
            "source_index": 14,
            "source_sentence": "Without that, my “transparency” metrics risked becoming just another layer of fiction",
            "best_match": {
              "index": 52,
              "lexical": 0.09938508989890997,
              "semantic": 0.5056315660476685,
              "combined": 0.3025083279732892,
              "target_sentence": "\"Now I need visuals.\"\n\nComplete, reliable transparency"
            }
          },
          {
            "source_index": 15,
            "source_sentence": "---\n\n## The Core Event / Experiment\n\nOn June 14, I loaded all four versions of my “markup-languages” article—draft, refined, edited, final—into the Colab notebook Claude 4 had built for me",
            "best_match": {
              "index": 2,
              "lexical": 0.18080563056253798,
              "semantic": 0.5972971320152283,
              "combined": 0.3890513812888831,
              "target_sentence": "Testing on the markup-languages article revealed the truth"
            }
          },
          {
            "source_index": 16,
            "source_sentence": "The workflow was structured into deliberate, checkpointed stages so I could verify progress at each step:\nData ingestion & validation – Colab mounted my Google Drive without a single path conflict",
            "best_match": {
              "index": 23,
              "lexical": 0.14865421736395776,
              "semantic": 0.5088725686073303,
              "combined": 0.32876339298564405,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 17,
            "source_sentence": "It found all four versions, confirmed the sequence, and reported basic counts: draft (863 words), refined (1,128), edited (1,066), final (892)",
            "best_match": {
              "index": 3,
              "lexical": 0.09503226211823491,
              "semantic": 0.48152637481689453,
              "combined": 0.2882793184675647,
              "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
            }
          },
          {
            "source_index": 18,
            "source_sentence": "Preprocessing – Markdown formatting was stripped cleanly while preserving sentence and paragraph structure",
            "best_match": {
              "index": 2,
              "lexical": 0.08943089430894309,
              "semantic": 0.48019540309906006,
              "combined": 0.2848131487040016,
              "target_sentence": "Testing on the markup-languages article revealed the truth"
            }
          },
          {
            "source_index": 19,
            "source_sentence": "Similarity analysis – Using SentenceTransformers for semantic similarity and Jaccard/edit distance for lexical changes, the notebook compared each stage in sequence, plus a direct draft→final analysis",
            "best_match": {
              "index": 3,
              "lexical": 0.12489850326602299,
              "semantic": 0.5567047595977783,
              "combined": 0.3408016314319007,
              "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
            }
          },
          {
            "source_index": 20,
            "source_sentence": "Metrics generation – In a single uninterrupted pass, Colab produced clean JSON and CSV outputs for both human-readable review and AI-friendly archival",
            "best_match": {
              "index": 48,
              "lexical": 0.12400988181607443,
              "semantic": 0.36154305934906006,
              "combined": 0.24277647058256724,
              "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
            }
          },
          {
            "source_index": 21,
            "source_sentence": "These outputs were not just complete—they were reproducible and verifiable, because the checkpoints and Drive storage locked in exactly what had been processed at each step",
            "best_match": {
              "index": 23,
              "lexical": 0.16090035194841731,
              "semantic": 0.6102902293205261,
              "combined": 0.38559529063447173,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 22,
            "source_sentence": "For the first time, the system produced valid attribution maps, similarity scores, and modification breakdowns without intervention, error messages, or invisible data loss",
            "best_match": {
              "index": 5,
              "lexical": 0.24002878191512608,
              "semantic": 0.346807599067688,
              "combined": 0.29341819049140705,
              "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
            }
          },
          {
            "source_index": 23,
            "source_sentence": "The semantic similarity score for draft→final—43.1%—was a number I could trust, not because it “looked right,” but because I knew every step that produced it had executed cleanly",
            "best_match": {
              "index": 3,
              "lexical": 0.181480341925398,
              "semantic": 0.7109297513961792,
              "combined": 0.4462050466607886,
              "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
            }
          },
          {
            "source_index": 24,
            "source_sentence": "---\n\n## The Breakdown / Complication\n\nThis smooth run in Colab only looked effortless because of the wreckage it followed",
            "best_match": {
              "index": 67,
              "lexical": 0.12601421605707988,
              "semantic": 0.537155270576477,
              "combined": 0.33158474331677845,
              "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
            }
          },
          {
            "source_index": 25,
            "source_sentence": "In the months before, every environment I tried had found a new way to fail:\nChat-based execution was fragile",
            "best_match": {
              "index": 1,
              "lexical": 0.1966660966691384,
              "semantic": 0.418143630027771,
              "combined": 0.3074048633484547,
              "target_sentence": "It was letting the AI specify the right environment to actually execute what it promised"
            }
          },
          {
            "source_index": 26,
            "source_sentence": "Files vanished between steps, context evaporated across sessions, and any multi-stage process risked collapsing before it finished",
            "best_match": {
              "index": 14,
              "lexical": 0.11279474006396605,
              "semantic": 0.49328750371932983,
              "combined": 0.30304112189164795,
              "target_sentence": "What would've been multiple files and undoubtedly exponential failures with my previous approach"
            }
          },
          {
            "source_index": 27,
            "source_sentence": "Fragmentation between prompts meant the workflow was forced into a rigid, linear structure that couldn’t survive interruptions",
            "best_match": {
              "index": 23,
              "lexical": 0.15713555791376801,
              "semantic": 0.3494720458984375,
              "combined": 0.25330380190610274,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 28,
            "source_sentence": "Local Python runs suffered from silent data loss—rows dropped without error messages—and “phantom” file references that pointed to nothing",
            "best_match": {
              "index": 7,
              "lexical": 0.1317719041778951,
              "semantic": 0.4292752146720886,
              "combined": 0.28052355942499185,
              "target_sentence": "Python scripts that produced empty CSVs"
            }
          },
          {
            "source_index": 29,
            "source_sentence": "Version drift was constant",
            "best_match": {
              "index": 92,
              "lexical": 0.27839191444264205,
              "semantic": 0.3717861771583557,
              "combined": 0.3250890458004989,
              "target_sentence": "It's version 1.3"
            }
          },
          {
            "source_index": 30,
            "source_sentence": "A renamed file could erase core functions, with the AI confidently reintroducing them as imports from modules that didn’t exist",
            "best_match": {
              "index": 1,
              "lexical": 0.14867403226375428,
              "semantic": 0.43522393703460693,
              "combined": 0.2919489846491806,
              "target_sentence": "It was letting the AI specify the right environment to actually execute what it promised"
            }
          },
          {
            "source_index": 31,
            "source_sentence": "Misleading confirmations were a recurring trap",
            "best_match": {
              "index": 85,
              "lexical": 0.10526315789473684,
              "semantic": 0.4031800627708435,
              "combined": 0.25422161033279017,
              "target_sentence": "Consistency enables confidence"
            }
          },
          {
            "source_index": 32,
            "source_sentence": "The AI would report “analysis complete” even when no outputs had been saved or the links it provided returned 404 errors",
            "best_match": {
              "index": 32,
              "lexical": 0.12546721032959565,
              "semantic": 0.4256290793418884,
              "combined": 0.275548144835742,
              "target_sentence": "I don't know that I would've picked up on run_complete_analysis then but I see it plain as day now"
            }
          },
          {
            "source_index": 33,
            "source_sentence": "Pathing chaos created double-nested folders, hard-coded directories, and brittle assumptions that broke the moment my file structure changed",
            "best_match": {
              "index": 14,
              "lexical": 0.11903370348723945,
              "semantic": 0.5255070924758911,
              "combined": 0.32227039798156526,
              "target_sentence": "What would've been multiple files and undoubtedly exponential failures with my previous approach"
            }
          },
          {
            "source_index": 34,
            "source_sentence": "Each fix required hours of rework and re-verification",
            "best_match": {
              "index": 23,
              "lexical": 0.14615206281533985,
              "semantic": 0.5396570563316345,
              "combined": 0.3429045595734872,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 35,
            "source_sentence": "The bigger risk wasn’t just wasted time—it was publishing metrics built on unstable runs, where I couldn’t be certain whether a number reflected the data or the tool’s hidden flaws",
            "best_match": {
              "index": 39,
              "lexical": 0.14973096447133297,
              "semantic": 0.3301377296447754,
              "combined": 0.23993434705805416,
              "target_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started, I'd requested data for visualizations and a subset of that data for charts I could add at the end of the articles"
            }
          },
          {
            "source_index": 36,
            "source_sentence": "By the time Colab entered the picture, I wasn’t just looking for speed; I was looking for something I could finally trust",
            "best_match": {
              "index": 11,
              "lexical": 0.113021639470344,
              "semantic": 0.48921340703964233,
              "combined": 0.3011175232549932,
              "target_sentence": "> Then Claude asked, \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed"
            }
          },
          {
            "source_index": 37,
            "source_sentence": "---\n\n## The Breakthrough\n\nColab didn’t just run the code—it removed the fragility that had been undermining the entire project",
            "best_match": {
              "index": 67,
              "lexical": 0.12811822649037613,
              "semantic": 0.6429804563522339,
              "combined": 0.38554934142130504,
              "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
            }
          },
          {
            "source_index": 38,
            "source_sentence": "It also overcame the fragmentation and rigid linearity of chat-based execution, allowing the process to run as one continuous, coherent workflow without being chopped into unstable prompt sessions",
            "best_match": {
              "index": 23,
              "lexical": 0.11442946563134905,
              "semantic": 0.3530290424823761,
              "combined": 0.23372925405686257,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 39,
            "source_sentence": "Every stage executed in sequence without interruption:\nDrive integration mounted cleanly on the first try, with no double-folder loops or hard-coded paths to untangle",
            "best_match": {
              "index": 23,
              "lexical": 0.1258617925284592,
              "semantic": 0.2978772819042206,
              "combined": 0.2118695372163399,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 40,
            "source_sentence": "Library loading handled dependencies without the compatibility errors I’d wrestled with in local Python",
            "best_match": {
              "index": 69,
              "lexical": 0.14295255552057964,
              "semantic": 0.40646758675575256,
              "combined": 0.2747100711381661,
              "target_sentence": "Using ill-suited technologies meant fighting installation issues, missing dependencies, and cryptic errors"
            }
          },
          {
            "source_index": 41,
            "source_sentence": "Processing checkpoints saved in real time to Drive, giving me verifiable snapshots between stages—critical for ensuring any future run could be matched exactly to past outputs",
            "best_match": {
              "index": 23,
              "lexical": 0.1310981412105828,
              "semantic": 0.5970276594161987,
              "combined": 0.3640629003133908,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 42,
            "source_sentence": "Final outputs—attribution maps, similarity scores, modification percentages—were generated exactly as requested, in both human-readable and archival formats",
            "best_match": {
              "index": 3,
              "lexical": 0.10523544999999422,
              "semantic": 0.50541090965271,
              "combined": 0.3053231798263521,
              "target_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
            }
          },
          {
            "source_index": 43,
            "source_sentence": "---\n\n## Pattern or Principle\n\nThe success in Colab underscored something I’d been circling for months: infrastructure reliability isn’t a convenience—it’s a prerequisite for ethical measurement",
            "best_match": {
              "index": 68,
              "lexical": 0.10905386431354837,
              "semantic": 0.5284626483917236,
              "combined": 0.318758256352636,
              "target_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure"
            }
          },
          {
            "source_index": 44,
            "source_sentence": "If the environment shifts under you, the same code can produce different results for reasons that have nothing to do with the data",
            "best_match": {
              "index": 5,
              "lexical": 0.1826233777803843,
              "semantic": 0.3254292607307434,
              "combined": 0.25402631925556385,
              "target_sentence": "For the first time, the system didn't collapse under the weight of real data"
            }
          },
          {
            "source_index": 45,
            "source_sentence": "In my case, the goal was to measure how much of a finished article was human-authored versus AI-assisted",
            "best_match": {
              "index": 4,
              "lexical": 0.12822587628798435,
              "semantic": 0.5632262825965881,
              "combined": 0.3457260794422862,
              "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
            }
          },
          {
            "source_index": 46,
            "source_sentence": "That’s a credibility claim",
            "best_match": {
              "index": 86,
              "lexical": 0.08032128514056225,
              "semantic": 0.41087502241134644,
              "combined": 0.24559815377595434,
              "target_sentence": "Results that vary aren't wrong, but they're hard to trust"
            }
          },
          {
            "source_index": 47,
            "source_sentence": "If my tooling can’t run in a stable, reproducible space, any number I publish risks being less about editorial truth and more about whatever quirks the environment introduced that day",
            "best_match": {
              "index": 68,
              "lexical": 0.09956791875611065,
              "semantic": 0.3336038291454315,
              "combined": 0.21658587395077109,
              "target_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure"
            }
          },
          {
            "source_index": 48,
            "source_sentence": "Colab’s stability didn’t just solve a technical problem—it reframed my evaluation criteria for every AI-assisted workflow",
            "best_match": {
              "index": 15,
              "lexical": 0.10897962428132653,
              "semantic": 0.4661378264427185,
              "combined": 0.28755872536202254,
              "target_sentence": "By now, I had learned to request complex or long items in pieces, effectively making the AI work in steps rather than spitting out a not-so-comprehensive artifact"
            }
          },
          {
            "source_index": 49,
            "source_sentence": "Capability matters, but without controlled execution conditions, even the best-designed algorithms can become ethical liabilities",
            "best_match": {
              "index": 1,
              "lexical": 0.09836718438868976,
              "semantic": 0.46858158707618713,
              "combined": 0.28347438573243844,
              "target_sentence": "It was letting the AI specify the right environment to actually execute what it promised"
            }
          },
          {
            "source_index": 50,
            "source_sentence": "This project proved that measurement integrity lives or dies in the infrastructure that supports it",
            "best_match": {
              "index": 68,
              "lexical": 0.16183041158078512,
              "semantic": 0.5394561886787415,
              "combined": 0.3506433001297633,
              "target_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure"
            }
          },
          {
            "source_index": 51,
            "source_sentence": "---\n\n## What This Means for Your Workflow\n\nThe Colab shift forced me to think about execution environments as part of the tool itself—not an afterthought",
            "best_match": {
              "index": 67,
              "lexical": 0.15313683111010012,
              "semantic": 0.5671565532684326,
              "combined": 0.36014669218926637,
              "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
            }
          },
          {
            "source_index": 52,
            "source_sentence": "If you want reproducible, defensible results from AI-assisted analysis, treat stability as a design requirement from day one",
            "best_match": {
              "index": 48,
              "lexical": 0.09820137392077723,
              "semantic": 0.41251519322395325,
              "combined": 0.25535828357236523,
              "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
            }
          },
          {
            "source_index": 53,
            "source_sentence": "Document environment requirements – Record versions, library dependencies, storage paths, and integration steps so the exact setup can be rebuilt later",
            "best_match": {
              "index": 69,
              "lexical": 0.1397110177024464,
              "semantic": 0.49055349826812744,
              "combined": 0.31513225798528693,
              "target_sentence": "Using ill-suited technologies meant fighting installation issues, missing dependencies, and cryptic errors"
            }
          },
          {
            "source_index": 54,
            "source_sentence": "Budget for infrastructure – Even “free” options have limits; know what it would cost to scale or preserve your setup",
            "best_match": {
              "index": 70,
              "lexical": 0.19093014823826582,
              "semantic": 0.44005417823791504,
              "combined": 0.31549216323809043,
              "target_sentence": "Moving to purpose-built infrastructure removed obstacles I didn't know existed"
            }
          },
          {
            "source_index": 55,
            "source_sentence": "Treat stability as an ethical requirement – When your output will be cited as evidence—whether for AI transparency or any other metric—environmental drift can become a form of silent falsification",
            "best_match": {
              "index": 1,
              "lexical": 0.12910447565761893,
              "semantic": 0.4730357825756073,
              "combined": 0.3010701291166131,
              "target_sentence": "It was letting the AI specify the right environment to actually execute what it promised"
            }
          },
          {
            "source_index": 56,
            "source_sentence": "This shift changed how I assess every AI tool I use",
            "best_match": {
              "index": 4,
              "lexical": 0.09572900868919514,
              "semantic": 0.49414336681365967,
              "combined": 0.2949361877514274,
              "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
            }
          },
          {
            "source_index": 57,
            "source_sentence": "I now weigh its execution stability as heavily as its functional capability, because one without the other isn’t reliable enough to publish",
            "best_match": {
              "index": 65,
              "lexical": 0.12301587301587301,
              "semantic": 0.35505256056785583,
              "combined": 0.23903421679186443,
              "target_sentence": "Oversight, verification, and quality assurance aren’t obstacles to efficiency"
            }
          },
          {
            "source_index": 58,
            "source_sentence": "---\n\n## Closing Arc\n\nIn the end, Colab didn’t make the analysis smarter—it made it honest",
            "best_match": {
              "index": 67,
              "lexical": 0.1528248049953284,
              "semantic": 0.5511572360992432,
              "combined": 0.3519910205472858,
              "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
            }
          },
          {
            "source_index": 59,
            "source_sentence": "By giving the process a consistent, transparent footing, it turned months of chaotic iteration into a workflow I could trust enough to publish",
            "best_match": {
              "index": 23,
              "lexical": 0.13451826319009094,
              "semantic": 0.43042075634002686,
              "combined": 0.2824695097650589,
              "target_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
            }
          },
          {
            "source_index": 60,
            "source_sentence": "The last mile in AI-assisted measurement is always human",
            "best_match": {
              "index": 4,
              "lexical": 0.1899300442669133,
              "semantic": 0.43398088216781616,
              "combined": 0.3119554632173647,
              "target_sentence": "The AI accelerated expansion, but human editing shaped the actual content"
            }
          },
          {
            "source_index": 61,
            "source_sentence": "It’s in our oversight, our interpretation of the numbers, and our willingness to challenge results that don’t add up",
            "best_match": {
              "index": 48,
              "lexical": 0.17321594557415732,
              "semantic": 0.4588775932788849,
              "combined": 0.3160467694265211,
              "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
            }
          },
          {
            "source_index": 62,
            "source_sentence": "But for that human judgment to mean anything, the path getting to those numbers has to be solid",
            "best_match": {
              "index": 48,
              "lexical": 0.18455798134826126,
              "semantic": 0.41757625341415405,
              "combined": 0.30106711738120767,
              "target_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future"
            }
          },
          {
            "source_index": 63,
            "source_sentence": "Colab gave me that solid ground",
            "best_match": {
              "index": 67,
              "lexical": 0.1639704944372019,
              "semantic": 0.4589703679084778,
              "combined": 0.31147043117283985,
              "target_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility"
            }
          }
        ]
      },
      "paragraph_level": {
        "lexical": {
          "jaccard_similarity": 0.1381294964028777,
          "edit_similarity": 0.0196319018404908,
          "tfidf_similarity": 0.23997407142901805,
          "lexical_average": 0.13257848989079551
        },
        "semantic": {
          "semantic_similarity": 0.5429775714874268,
          "embedding_dim": 384
        },
        "combined": 0.33777803068911116
      }
    },
    "analysis_timestamp": "2025-11-01T02:33:10.993491",
    "versions_analyzed": [
      "draft",
      "refined",
      "edited",
      "final"
    ]
  },
  "attribution_analysis": {
    "sentence_attributions": [
      {
        "final_index": 0,
        "final_sentence": "After learning to collaborate rather than command, I discovered the missing piece wasn't better prompts or smarter models",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.2505647287918971,
          "refined": 0.21521861922173274,
          "draft": 0.21311849443351522
        },
        "modification_path": []
      },
      {
        "final_index": 1,
        "final_sentence": "It was letting the AI specify the right environment to actually execute what it promised",
        "origin_version": "edited",
        "origin_index": 49,
        "similarity_scores": {
          "edited": 0.36528647487813776,
          "refined": 0.34830774664878844,
          "draft": 0.3141233801841736
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.36528647487813776,
            "sentence": "Expecting AI to deliver what I couldn't really define because I heard what I wanted"
          },
          {
            "version": "refined",
            "similarity": 0.34830774664878844,
            "sentence": "They were the mechanisms that made AI assistance trustworthy"
          },
          {
            "version": "draft",
            "similarity": 0.3141233801841736,
            "sentence": "False stability was even worse: the AI’s tendency to declare success without verifying outputs produced a dangerous illusion of accuracy"
          }
        ]
      },
      {
        "final_index": 2,
        "final_sentence": "Testing on the markup-languages article revealed the truth",
        "origin_version": "edited",
        "origin_index": 1,
        "similarity_scores": {
          "edited": 0.47978055477142334,
          "refined": 0.4854014582104153,
          "draft": 0.3272199945790427
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.47978055477142334,
            "sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
          },
          {
            "version": "refined",
            "similarity": 0.4854014582104153,
            "sentence": "## Testing on Markup Languages\n\nThe test subject was an article about markup languages in AI prompting"
          },
          {
            "version": "draft",
            "similarity": 0.3272199945790427,
            "sentence": "---\n\n## The Core Event / Experiment\n\nOn June 14, I loaded all four versions of my “markup-languages” article—draft, refined, edited, final—into the Colab notebook Claude 4 had built for me"
          }
        ]
      },
      {
        "final_index": 3,
        "final_sentence": "Only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact",
        "origin_version": "edited",
        "origin_index": 1,
        "similarity_scores": {
          "edited": 0.7658531302991121,
          "refined": 0.7658531302991121,
          "draft": 0.3679648756980896
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.7658531302991121,
            "sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
          },
          {
            "version": "refined",
            "similarity": 0.7658531302991121,
            "sentence": "Testing on the markup-languages article revealed the truth: only 43% similarity remained from draft to final, with just 2.4% of original sentences surviving intact"
          },
          {
            "version": "draft",
            "similarity": 0.3679648756980896,
            "sentence": "The semantic similarity score for draft→final—43.1%—was a number I could trust, not because it “looked right,” but because I knew every step that produced it had executed cleanly"
          }
        ]
      },
      {
        "final_index": 4,
        "final_sentence": "The AI accelerated expansion, but human editing shaped the actual content",
        "origin_version": "edited",
        "origin_index": 2,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 1.0000000596046448,
          "draft": 0.3008439105290633
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "The AI accelerated expansion, but human editing shaped the actual content"
          },
          {
            "version": "refined",
            "similarity": 1.0000000596046448,
            "sentence": "The AI accelerated expansion, but human editing shaped the actual content"
          },
          {
            "version": "draft",
            "similarity": 0.3008439105290633,
            "sentence": "In my case, the goal was to measure how much of a finished article was human-authored versus AI-assisted"
          }
        ]
      },
      {
        "final_index": 5,
        "final_sentence": "For the first time, the system didn't collapse under the weight of real data",
        "origin_version": "edited",
        "origin_index": 3,
        "similarity_scores": {
          "edited": 0.9999999701976776,
          "refined": 0.9999999701976776,
          "draft": 0.28054665667670114
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9999999701976776,
            "sentence": "For the first time, the system didn't collapse under the weight of real data"
          },
          {
            "version": "refined",
            "similarity": 0.9999999701976776,
            "sentence": "For the first time, the system didn't collapse under the weight of real data"
          }
        ]
      },
      {
        "final_index": 6,
        "final_sentence": "## Python's Laboratory\n\nI'd already paid the tuition",
        "origin_version": "edited",
        "origin_index": 4,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.22113244661263057,
          "draft": 0.19965391712529318
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "## Python's Laboratory\n\nI'd already paid the tuition"
          }
        ]
      },
      {
        "final_index": 7,
        "final_sentence": "Python scripts that produced empty CSVs",
        "origin_version": "edited",
        "origin_index": 5,
        "similarity_scores": {
          "edited": 0.9999999403953552,
          "refined": 0.32917726390502033,
          "draft": 0.2581158682056095
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9999999403953552,
            "sentence": "Python scripts that produced empty CSVs"
          },
          {
            "version": "refined",
            "similarity": 0.32917726390502033,
            "sentence": "But compared to empty CSVs and phantom functions, a duplicate folder was nothing"
          }
        ]
      },
      {
        "final_index": 8,
        "final_sentence": "HTML interfaces that couldn't actually analyze anything",
        "origin_version": "edited",
        "origin_index": 6,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.26827308866712785,
          "draft": 0.1547326147556305
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "HTML interfaces that couldn't actually analyze anything"
          }
        ]
      },
      {
        "final_index": 9,
        "final_sentence": "Semantic similarity scores that changed every time I blinked",
        "origin_version": "edited",
        "origin_index": 7,
        "similarity_scores": {
          "edited": 1.0000001192092896,
          "refined": 0.3070809576246474,
          "draft": 0.3589936926447112
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000001192092896,
            "sentence": "Semantic similarity scores that changed every time I blinked"
          },
          {
            "version": "refined",
            "similarity": 0.3070809576246474,
            "sentence": "\"I'll use TF-IDF and cosine similarity as our primary semantic measure"
          },
          {
            "version": "draft",
            "similarity": 0.3589936926447112,
            "sentence": "The semantic similarity score for draft→final—43.1%—was a number I could trust, not because it “looked right,” but because I knew every step that produced it had executed cleanly"
          }
        ]
      },
      {
        "final_index": 10,
        "final_sentence": "Each failure had taught me something, but none had produced what I actually needed",
        "origin_version": "edited",
        "origin_index": 8,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.24974863345806414,
          "draft": 0.2269582476686029
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "Each failure had taught me something, but none had produced what I actually needed"
          }
        ]
      },
      {
        "final_index": 11,
        "final_sentence": "> Then Claude asked, \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed",
        "origin_version": "edited",
        "origin_index": 9,
        "similarity_scores": {
          "edited": 0.9486656308174133,
          "refined": 0.2717426640016061,
          "draft": 0.4067985748543459
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9486656308174133,
            "sentence": "> Then Claude asked  \"Have you considered running this in Google Colab?\"\n\nI hadn't considered it because I didn't know it existed"
          },
          {
            "version": "draft",
            "similarity": 0.4067985748543459,
            "sentence": "So when Claude 4 suggested shifting the entire workflow into Google Colab, I approached it like my last shot"
          }
        ]
      },
      {
        "final_index": 12,
        "final_sentence": "Twenty minutes later, I was staring at what looked like Google Docs had a baby with a Jupyter Notebook",
        "origin_version": "edited",
        "origin_index": 10,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.1931404625215838,
          "draft": 0.209787133065137
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "Twenty minutes later, I was staring at what looked like Google Docs had a baby with a Jupyter Notebook"
          }
        ]
      },
      {
        "final_index": 13,
        "final_sentence": "\\[Image of colab cell with code in it]\n\n### Class In Session\n\nThe notebook let me split scripts into stages",
        "origin_version": "refined",
        "origin_index": 1,
        "similarity_scores": {
          "edited": 0.2414090642157723,
          "refined": 0.3125135323096966,
          "draft": 0.2318493604660034
        },
        "modification_path": [
          {
            "version": "refined",
            "similarity": 0.3125135323096966,
            "sentence": "> TL;DR: Moving to Google Colab transformed scattered scripts into a working pipeline"
          }
        ]
      },
      {
        "final_index": 14,
        "final_sentence": "What would've been multiple files and undoubtedly exponential failures with my previous approach",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.2367169153690338,
          "refined": 0.2367169153690338,
          "draft": 0.2972363048586352
        },
        "modification_path": []
      },
      {
        "final_index": 15,
        "final_sentence": "By now, I had learned to request complex or long items in pieces, effectively making the AI work in steps rather than spitting out a not-so-comprehensive artifact",
        "origin_version": "edited",
        "origin_index": 11,
        "similarity_scores": {
          "edited": 0.9227769119398934,
          "refined": 0.2562402835706385,
          "draft": 0.26419507031855377
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9227769119398934,
            "sentence": "By now, I had learned to request complex or long items in chunks, effectively making the AI in question work in steps rather than spitting out a not-so-comprehensive artifact"
          }
        ]
      },
      {
        "final_index": 16,
        "final_sentence": "I watched as Claude transformed from code generator to educator",
        "origin_version": "edited",
        "origin_index": 12,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.2719547287984328,
          "draft": 0.2340692353469354
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "I watched as Claude transformed from code generator to educator"
          }
        ]
      },
      {
        "final_index": 17,
        "final_sentence": "It wasn't just solving my problem",
        "origin_version": "edited",
        "origin_index": 13,
        "similarity_scores": {
          "edited": 0.5878436382000263,
          "refined": 0.24059862560696071,
          "draft": 0.17369345873594283
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.5878436382000263,
            "sentence": "It wasn't just solving my problem—it was ensuring I understood the solution"
          }
        ]
      },
      {
        "final_index": 18,
        "final_sentence": "It was ensuring I understood the solution",
        "origin_version": "edited",
        "origin_index": 13,
        "similarity_scores": {
          "edited": 0.7344402472178142,
          "refined": 0.28242618441581724,
          "draft": 0.2475995604808514
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.7344402472178142,
            "sentence": "It wasn't just solving my problem—it was ensuring I understood the solution"
          }
        ]
      },
      {
        "final_index": 19,
        "final_sentence": "Each function included not just what it did, but why it mattered",
        "origin_version": "edited",
        "origin_index": 14,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.28868335485458374,
          "draft": 0.2396200616513529
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "Each function included not just what it did, but why it mattered"
          }
        ]
      },
      {
        "final_index": 20,
        "final_sentence": "After months of black-box solutions, I had a patient tutor explaining every step",
        "origin_version": "edited",
        "origin_index": 15,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.264637324370836,
          "draft": 0.22431654786622082
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "After months of black-box solutions, I had a patient tutor explaining every step"
          }
        ]
      },
      {
        "final_index": 21,
        "final_sentence": "This was acknowledging the actual complexity of the problem and helping the dope that showed up with a silly little script understand the purpose of the code",
        "origin_version": "edited",
        "origin_index": 16,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.23826146282647787,
          "draft": 0.26747626491955345
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "This was acknowledging the actual complexity of the problem and helping the dope that showed up with a silly little script understand the purpose of the code"
          }
        ]
      },
      {
        "final_index": 22,
        "final_sentence": "### And Then, Secret CELL 11\n\nUp to this point every cell ran for less than a minute",
        "origin_version": "edited",
        "origin_index": 17,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.2007786492506663,
          "draft": 0.18830911900315966
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "### And Then, Secret CELL 11\n\nUp to this point every cell ran for less than a minute"
          }
        ]
      },
      {
        "final_index": 23,
        "final_sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well",
        "origin_version": "edited",
        "origin_index": 18,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.36866672902271663,
          "draft": 0.35514511466026305
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "Each followed by a brief confirmation upon completion, checkpoints in the process, tidbits for human verification that all was well"
          },
          {
            "version": "refined",
            "similarity": 0.36866672902271663,
            "sentence": "Most importantly, checkpoints could be inspected and verified before proceeding"
          },
          {
            "version": "draft",
            "similarity": 0.35514511466026305,
            "sentence": "These outputs were not just complete—they were reproducible and verifiable, because the checkpoints and Drive storage locked in exactly what had been processed at each step"
          }
        ]
      },
      {
        "final_index": 24,
        "final_sentence": "`plaintext\n#CELL 10: QUICK EXECUTION FOR EXISTING DATA\n`\n\nPrior cells had been monolithic in comparison to what I'd been punished with time and time again",
        "origin_version": "edited",
        "origin_index": 19,
        "similarity_scores": {
          "edited": 0.9584545111656189,
          "refined": 0.25464762355151926,
          "draft": 0.20074197955620593
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9584545111656189,
            "sentence": "`plaintext\n#CELL 10: QUICK EXECUTION FOR EXISTING DATA\n`\n\nPrior cells had been monolithic in comparison to what I had been punished with time and time again"
          }
        ]
      },
      {
        "final_index": 25,
        "final_sentence": "Cell 10 was a fraction by comparison, a meager 34 lines of code",
        "origin_version": "edited",
        "origin_index": 20,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.20930551409721374,
          "draft": 0.16932851903968388
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "Cell 10 was a fraction by comparison, a meager 34 lines of code"
          }
        ]
      },
      {
        "final_index": 26,
        "final_sentence": "Then there was an inconspicuous cell",
        "origin_version": "edited",
        "origin_index": 21,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.22343609399265713,
          "draft": 0.16911767423152924
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "Then there was an inconspicuous cell"
          }
        ]
      },
      {
        "final_index": 27,
        "final_sentence": "A mere 3 lines of code",
        "origin_version": "edited",
        "origin_index": 22,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.2790023581339763,
          "draft": 0.15525970806678135
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "A mere 3 lines of code"
          }
        ]
      },
      {
        "final_index": 28,
        "final_sentence": "> No title in CAPS proclaiming its presence",
        "origin_version": "edited",
        "origin_index": 23,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.15587869515785804,
          "draft": 0.14580929279327393
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "> No title in CAPS proclaiming its presence"
          }
        ]
      },
      {
        "final_index": 29,
        "final_sentence": "No educational explanation",
        "origin_version": "edited",
        "origin_index": 24,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.26096135973930357,
          "draft": 0.1547439992427826
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "No educational explanation"
          }
        ]
      },
      {
        "final_index": 30,
        "final_sentence": "No warning",
        "origin_version": "edited",
        "origin_index": 25,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.21259711682796478,
          "draft": 0.11030779920873188
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "No warning"
          }
        ]
      },
      {
        "final_index": 31,
        "final_sentence": "I still don't know Python, but I know you don't have to be able to read or write it to see the hints at its purpose",
        "origin_version": "edited",
        "origin_index": 26,
        "similarity_scores": {
          "edited": 0.874020639968955,
          "refined": 0.1773693767087213,
          "draft": 0.26898153832084254
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.874020639968955,
            "sentence": "I still don't know Python, but I know you don't have to be able to read or write it to miss hints at it's purpose"
          }
        ]
      },
      {
        "final_index": 32,
        "final_sentence": "I don't know that I would've picked up on run_complete_analysis then but I see it plain as day now",
        "origin_version": "edited",
        "origin_index": 27,
        "similarity_scores": {
          "edited": 0.48666697818981974,
          "refined": 0.2161730220823577,
          "draft": 0.2267034285598331
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.48666697818981974,
            "sentence": "I don't know that I would have picked up on it then but I see it plain as day now"
          }
        ]
      },
      {
        "final_index": 33,
        "final_sentence": "`plaintext\ncombined_results, footer_metrics = run_complete_analysis_from_existing(\n    article_versions, preprocessor\n)\n`\n\nThe cell ran past a minute, the spinner kept spinning, and nothing happened",
        "origin_version": "edited",
        "origin_index": 28,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.20361513727241093,
          "draft": 0.19088463187217714
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "`plaintext\ncombined_results, footer_metrics = run_complete_analysis_from_existing(\n    article_versions, preprocessor\n)\n`\n\nThe cell ran past a minute, the spinner kept spinning, and nothing happened"
          }
        ]
      },
      {
        "final_index": 34,
        "final_sentence": "> I'd paid my taxes in full, and the Fairy finally delivered...an hour and a half later",
        "origin_version": "edited",
        "origin_index": 29,
        "similarity_scores": {
          "edited": 0.6217754645781084,
          "refined": 0.2819705477048611,
          "draft": 0.15870751653398785
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.6217754645781084,
            "sentence": "> I had paid my taxes in full, and this is when the Fairy delivered"
          }
        ]
      },
      {
        "final_index": 35,
        "final_sentence": "When the results appeared the moment was anticlimactic to say the least",
        "origin_version": "edited",
        "origin_index": 31,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.22637905638951522,
          "draft": 0.22655958268377516
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "When the results appeared the moment was anticlimactic to say the least"
          }
        ]
      },
      {
        "final_index": 36,
        "final_sentence": "The question had been answered in a concise and meaningful way",
        "origin_version": "edited",
        "origin_index": 32,
        "similarity_scores": {
          "edited": 0.9999999105930328,
          "refined": 0.2793268728256226,
          "draft": 0.21134310722351074
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9999999105930328,
            "sentence": "The question had been answered in a concise and meaningful way"
          }
        ]
      },
      {
        "final_index": 37,
        "final_sentence": "Results that I failed to copy from the notebook",
        "origin_version": "edited",
        "origin_index": 33,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.2581856093908611,
          "draft": 0.20466254012925283
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "Results that I failed to copy from the notebook"
          }
        ]
      },
      {
        "final_index": 38,
        "final_sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following",
        "origin_version": "edited",
        "origin_index": 34,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.31393311525646006,
          "draft": 0.23627629830981745
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "For the sake of completeness, I used The Count That Couldn't to provide the following"
          },
          {
            "version": "refined",
            "similarity": 0.31393311525646006,
            "sentence": "Each was just for counting content accurately"
          }
        ]
      },
      {
        "final_index": 39,
        "final_sentence": "## Fourteen Decimals of Overkill\n\nWhen I started, I'd requested data for visualizations and a subset of that data for charts I could add at the end of the articles",
        "origin_version": "edited",
        "origin_index": 35,
        "similarity_scores": {
          "edited": 0.8034202655156453,
          "refined": 0.312325862772537,
          "draft": 0.23719188239839342
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8034202655156453,
            "sentence": "## Fourteen Decimals of Overkill\n\nWhen I started I had requested data to be used for visualizations, and a subset of the data for visualizations I could add at the end of the articles"
          },
          {
            "version": "refined",
            "similarity": 0.312325862772537,
            "sentence": "## Visualizations That Actually Worked\n\nThe structured data pipeline enabled visualization capabilities that emerged naturally"
          }
        ]
      },
      {
        "final_index": 40,
        "final_sentence": "The json for the footer looked like the information provided in Colab",
        "origin_version": "edited",
        "origin_index": 36,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.27735030982229447,
          "draft": 0.2845470905303955
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "The json for the footer looked like the information provided in Colab"
          }
        ]
      },
      {
        "final_index": 41,
        "final_sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines",
        "origin_version": "edited",
        "origin_index": 37,
        "similarity_scores": {
          "edited": 0.9999999701976776,
          "refined": 0.3350290894508362,
          "draft": 0.3287953734397888
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9999999701976776,
            "sentence": "Checkpoint data from steps 1 and 2, slightly more satisfying at 86 lines"
          },
          {
            "version": "refined",
            "similarity": 0.3350290894508362,
            "sentence": "Seven distinct stages, each with its own checkpoint"
          },
          {
            "version": "draft",
            "similarity": 0.3287953734397888,
            "sentence": "Processing checkpoints saved in real time to Drive, giving me verifiable snapshots between stages—critical for ensuring any future run could be matched exactly to past outputs"
          }
        ]
      },
      {
        "final_index": 42,
        "final_sentence": "> Spoiler: it turns out the article was about using Mermaid AI, not markup",
        "origin_version": "edited",
        "origin_index": 38,
        "similarity_scores": {
          "edited": 0.9327696522076925,
          "refined": 0.3756776551405589,
          "draft": 0.2488136546952384
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9327696522076925,
            "sentence": "> Spoiler, it turns out the article was about using Mermaid AI, not markup"
          },
          {
            "version": "refined",
            "similarity": 0.3756776551405589,
            "sentence": "## Testing on Markup Languages\n\nThe test subject was an article about markup languages in AI prompting"
          }
        ]
      },
      {
        "final_index": 43,
        "final_sentence": "Then there was the complete dataset",
        "origin_version": "edited",
        "origin_index": 39,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.36831803619861603,
          "draft": 0.23660819797680296
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "Then there was the complete dataset"
          },
          {
            "version": "refined",
            "similarity": 0.36831803619861603,
            "sentence": "The semantic analysis was there"
          }
        ]
      },
      {
        "final_index": 44,
        "final_sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable",
        "origin_version": "edited",
        "origin_index": 40,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.25978851318359375,
          "draft": 0.21630528569221497
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "An overwhelming 3647 lines documenting every calculation traceable, every metric visible, every error identifiable"
          }
        ]
      },
      {
        "final_index": 45,
        "final_sentence": "Every sentence from every version of the article with the relevant data",
        "origin_version": "edited",
        "origin_index": 41,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.31583170514357717,
          "draft": 0.2965324858824412
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "Every sentence from every version of the article with the relevant data"
          },
          {
            "version": "refined",
            "similarity": 0.31583170514357717,
            "sentence": "Only one sentence from the original 47 remained recognizably similar in the final version"
          }
        ]
      },
      {
        "final_index": 46,
        "final_sentence": "A summary of the data, the actual data, an index of the data, and more",
        "origin_version": "edited",
        "origin_index": 42,
        "similarity_scores": {
          "edited": 0.8692525029182434,
          "refined": 0.290308449949537,
          "draft": 0.21858912706375122
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8692525029182434,
            "sentence": "A summary of the data, the actual data, an index of the data, and so on"
          }
        ]
      },
      {
        "final_index": 47,
        "final_sentence": "Fourteen decimals on every datapoint",
        "origin_version": "edited",
        "origin_index": 43,
        "similarity_scores": {
          "edited": 0.5206122669306669,
          "refined": 0.44583767652511597,
          "draft": 0.21680648624897003
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.5206122669306669,
            "sentence": "Fourteen decimals on every datapoint; everything necessary for it to be AI-friendly so I can use the numbers again in the future"
          },
          {
            "version": "refined",
            "similarity": 0.44583767652511597,
            "sentence": "Fourteen decimals on almost everything, far more precision than necessary, but it was there"
          }
        ]
      },
      {
        "final_index": 48,
        "final_sentence": "Everything necessary for it to be AI-readable so I can use the numbers again in the future",
        "origin_version": "edited",
        "origin_index": 43,
        "similarity_scores": {
          "edited": 0.6457224759188565,
          "refined": 0.3810050402368818,
          "draft": 0.3013807192996696
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.6457224759188565,
            "sentence": "Fourteen decimals on every datapoint; everything necessary for it to be AI-friendly so I can use the numbers again in the future"
          },
          {
            "version": "refined",
            "similarity": 0.3810050402368818,
            "sentence": "It needed to be AI-friendly, structured data I could feed into future analysis without re-running the entire pipeline"
          },
          {
            "version": "draft",
            "similarity": 0.3013807192996696,
            "sentence": "But for that human judgment to mean anything, the path getting to those numbers has to be solid"
          }
        ]
      },
      {
        "final_index": 49,
        "final_sentence": "I ran the same article through three more times and got consistent results",
        "origin_version": "edited",
        "origin_index": 44,
        "similarity_scores": {
          "edited": 0.887494170665741,
          "refined": 0.30703258514404297,
          "draft": 0.23992683206285748
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.887494170665741,
            "sentence": "I ran the same article through three more times and the results have been consistent"
          },
          {
            "version": "refined",
            "similarity": 0.30703258514404297,
            "sentence": "Multiple articles could be analyzed using identical methodology"
          }
        ]
      },
      {
        "final_index": 50,
        "final_sentence": "All fourteen decimal points, every time",
        "origin_version": "edited",
        "origin_index": 45,
        "similarity_scores": {
          "edited": 0.6663167604378292,
          "refined": 0.3840386679297999,
          "draft": 0.16760218143463135
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.6663167604378292,
            "sentence": "All fourteen decimal points"
          },
          {
            "version": "refined",
            "similarity": 0.3840386679297999,
            "sentence": "Fourteen decimals on almost everything, far more precision than necessary, but it was there"
          }
        ]
      },
      {
        "final_index": 51,
        "final_sentence": "> \"I think I love you right now,\" I typed",
        "origin_version": "edited",
        "origin_index": 46,
        "similarity_scores": {
          "edited": 0.5399444103240967,
          "refined": 0.17633897241424112,
          "draft": 0.0999331921339035
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.5399444103240967,
            "sentence": "> \"I think I love you right now,\" I typed, \"Now I need visuals.\"\n\nComplete, reliable, transparency"
          }
        ]
      },
      {
        "final_index": 52,
        "final_sentence": "\"Now I need visuals.\"\n\nComplete, reliable transparency",
        "origin_version": "edited",
        "origin_index": 46,
        "similarity_scores": {
          "edited": 0.5577770173549652,
          "refined": 0.322285532951355,
          "draft": 0.25281578302383423
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.5577770173549652,
            "sentence": "> \"I think I love you right now,\" I typed, \"Now I need visuals.\"\n\nComplete, reliable, transparency"
          },
          {
            "version": "refined",
            "similarity": 0.322285532951355,
            "sentence": "Building infrastructure that makes showing your work repeatable is transparency"
          }
        ]
      },
      {
        "final_index": 53,
        "final_sentence": "## The Fairy Tale Tax\n\nI came up with a Python script that worked",
        "origin_version": "edited",
        "origin_index": 47,
        "similarity_scores": {
          "edited": 0.6901651400586832,
          "refined": 0.4091617226600647,
          "draft": 0.1589995300769806
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.6901651400586832,
            "sentence": "## The Fairy Tale Tax\n\nI came with a Python script that worked, it had a \"statistically acceptable level of variance\", but it worked"
          },
          {
            "version": "refined",
            "similarity": 0.4091617226600647,
            "sentence": "## The Fairy Tale Tax\n\nI'd expected the pipeline to just work once it was properly designed"
          }
        ]
      },
      {
        "final_index": 54,
        "final_sentence": "It had a “statistically acceptable level of variance,” but it worked",
        "origin_version": "edited",
        "origin_index": 47,
        "similarity_scores": {
          "edited": 0.4558043877283732,
          "refined": 0.24285157450607844,
          "draft": 0.2188193282565555
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.4558043877283732,
            "sentence": "## The Fairy Tale Tax\n\nI came with a Python script that worked, it had a \"statistically acceptable level of variance\", but it worked"
          }
        ]
      },
      {
        "final_index": 55,
        "final_sentence": "I paid the Fairy Tale Tax several times:\nBlindly following an AI producing code I couldn’t read that failed time and time again",
        "origin_version": "edited",
        "origin_index": 48,
        "similarity_scores": {
          "edited": 0.9544094665483995,
          "refined": 0.42595096880739386,
          "draft": 0.2614063521226247
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9544094665483995,
            "sentence": "I paid the Fairy Tale Tax several times:\nBlindly following an AI producing code I couldn't read that failed time and time again"
          },
          {
            "version": "refined",
            "similarity": 0.42595096880739386,
            "sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
          }
        ]
      },
      {
        "final_index": 56,
        "final_sentence": "Expecting AI to deliver what I couldn’t really define because I heard what I wanted",
        "origin_version": "edited",
        "origin_index": 49,
        "similarity_scores": {
          "edited": 0.9225478722498968,
          "refined": 0.29937041842419165,
          "draft": 0.25807242248302853
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9225478722498968,
            "sentence": "Expecting AI to deliver what I couldn't really define because I heard what I wanted"
          }
        ]
      },
      {
        "final_index": 57,
        "final_sentence": "Repeated frustration that resulted in me giving up more than once",
        "origin_version": "edited",
        "origin_index": 50,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.17189690470695496,
          "draft": 0.19502115646998086
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "Repeated frustration that resulted in me giving up more than once"
          }
        ]
      },
      {
        "final_index": 58,
        "final_sentence": "And then some",
        "origin_version": "edited",
        "origin_index": 51,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 0.2208988858120782,
          "draft": 0.12454545497894287
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "And then some"
          }
        ]
      },
      {
        "final_index": 59,
        "final_sentence": "This time the tax wasn’t about believing in magic or thinking it would simply work out because I was using AI",
        "origin_version": "edited",
        "origin_index": 52,
        "similarity_scores": {
          "edited": 0.8524617354075115,
          "refined": 0.4055906611940135,
          "draft": 0.23857555124494764
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8524617354075115,
            "sentence": "This time the tax wasn't about believing in magic, that it would simply work out because I was using AI"
          },
          {
            "version": "refined",
            "similarity": 0.4055906611940135,
            "sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
          }
        ]
      },
      {
        "final_index": 60,
        "final_sentence": "It was about learning that having a vast amount of information at your fingertips might qualify as intelligent, but it doesn’t make you smart",
        "origin_version": "edited",
        "origin_index": 53,
        "similarity_scores": {
          "edited": 0.9187062811851501,
          "refined": 0.24397120036576925,
          "draft": 0.22733717592986855
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9187062811851501,
            "sentence": "It was about learning that having a vast amount of information at your fingertips might qualify as intelligent but it doesn't make you smart"
          }
        ]
      },
      {
        "final_index": 61,
        "final_sentence": "Understanding how to use that vast amount of knowledge does",
        "origin_version": "edited",
        "origin_index": 54,
        "similarity_scores": {
          "edited": 0.8763035264882175,
          "refined": 0.23709693253040315,
          "draft": 0.2534477412700653
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8763035264882175,
            "sentence": "Understanding how to into that vast amount of knowledge does"
          }
        ]
      },
      {
        "final_index": 62,
        "final_sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after",
        "origin_version": "edited",
        "origin_index": 55,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 1.0,
          "draft": 0.23998438853483933
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
          },
          {
            "version": "refined",
            "similarity": 1.0,
            "sentence": "> The only real tax when working with AI is the “Fairy Tale Tax.” It’s the belief that AI will take care of everything so you can live happily ever after"
          }
        ]
      },
      {
        "final_index": 63,
        "final_sentence": "The “AI Tax” evolved but didn’t disappear",
        "origin_version": "edited",
        "origin_index": 56,
        "similarity_scores": {
          "edited": 0.697928500175476,
          "refined": 0.697928500175476,
          "draft": 0.2408323222398758
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.697928500175476,
            "sentence": "The \"AI Tax\" evolved but didn't disappear"
          },
          {
            "version": "refined",
            "similarity": 0.697928500175476,
            "sentence": "The \"AI Tax\" evolved but didn't disappear"
          }
        ]
      },
      {
        "final_index": 64,
        "final_sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI",
        "origin_version": "edited",
        "origin_index": 57,
        "similarity_scores": {
          "edited": 0.8950083795047942,
          "refined": 0.9999999701976776,
          "draft": 0.2951340990908006
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8950083795047942,
            "sentence": "Instead of compound interest on failed systems, it's become the systematic cost of maintaining reliable collaboration between humans and AI"
          },
          {
            "version": "refined",
            "similarity": 0.9999999701976776,
            "sentence": "Instead of compound interest on failed systems, it became the systematic cost of maintaining reliable collaboration between humans and AI"
          }
        ]
      },
      {
        "final_index": 65,
        "final_sentence": "Oversight, verification, and quality assurance aren’t obstacles to efficiency",
        "origin_version": "edited",
        "origin_index": 58,
        "similarity_scores": {
          "edited": 0.8977166652679444,
          "refined": 0.7279482667262738,
          "draft": 0.2585039294284323
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.8977166652679444,
            "sentence": "Oversight, verification, and quality assurance aren't obstacles to efficiency"
          },
          {
            "version": "refined",
            "similarity": 0.7279482667262738,
            "sentence": "Even in success, oversight, verification, and quality assurance weren't obstacles to efficiency"
          }
        ]
      },
      {
        "final_index": 66,
        "final_sentence": "They’re what makes AI assistance trustworthy",
        "origin_version": "edited",
        "origin_index": 59,
        "similarity_scores": {
          "edited": 0.6033794988285411,
          "refined": 0.541692465543747,
          "draft": 0.24021515448888142
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.6033794988285411,
            "sentence": "They're the mechanisms that make AI assistance trustworthy"
          },
          {
            "version": "refined",
            "similarity": 0.541692465543747,
            "sentence": "They were the mechanisms that made AI assistance trustworthy"
          }
        ]
      },
      {
        "final_index": 67,
        "final_sentence": "## Why Colab Changed Everything\n\nEnvironment determines possibility",
        "origin_version": "edited",
        "origin_index": 60,
        "similarity_scores": {
          "edited": 0.42880799895838684,
          "refined": 0.42880799895838684,
          "draft": 0.36496848904568213
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.42880799895838684,
            "sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis"
          },
          {
            "version": "refined",
            "similarity": 0.42880799895838684,
            "sentence": "## Why Colab Changed Everything\n\nContext persistence across cells meant variables and functions didn't vanish mid-analysis"
          },
          {
            "version": "draft",
            "similarity": 0.36496848904568213,
            "sentence": "---\n\n## The Breakthrough\n\nColab didn’t just run the code—it removed the fragility that had been undermining the entire project"
          }
        ]
      },
      {
        "final_index": 68,
        "final_sentence": "The right infrastructure doesn't guarantee success, but the wrong one guarantees failure",
        "origin_version": "edited",
        "origin_index": 77,
        "similarity_scores": {
          "edited": 0.390871558870588,
          "refined": 0.390871558870588,
          "draft": 0.3132063552089359
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.390871558870588,
            "sentence": "Infrastructure enables rather than guarantees"
          },
          {
            "version": "refined",
            "similarity": 0.390871558870588,
            "sentence": "Infrastructure enables rather than guarantees"
          },
          {
            "version": "draft",
            "similarity": 0.3132063552089359,
            "sentence": "This project proved that measurement integrity lives or dies in the infrastructure that supports it"
          }
        ]
      },
      {
        "final_index": 69,
        "final_sentence": "Using ill-suited technologies meant fighting installation issues, missing dependencies, and cryptic errors",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.20508346378803252,
          "refined": 0.21874502466784584,
          "draft": 0.2775348136501927
        },
        "modification_path": []
      },
      {
        "final_index": 70,
        "final_sentence": "Moving to purpose-built infrastructure removed obstacles I didn't know existed",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.254497092021139,
          "refined": 0.254497092021139,
          "draft": 0.2755826446745131
        },
        "modification_path": []
      },
      {
        "final_index": 71,
        "final_sentence": "Sometimes the solution isn't better code",
        "origin_version": "edited",
        "origin_index": 13,
        "similarity_scores": {
          "edited": 0.31309449672698975,
          "refined": 0.21497698326905568,
          "draft": 0.22235599994659425
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.31309449672698975,
            "sentence": "It wasn't just solving my problem—it was ensuring I understood the solution"
          }
        ]
      },
      {
        "final_index": 72,
        "final_sentence": "It's better context",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.1762586086988449,
          "refined": 0.21850580402782985,
          "draft": 0.11771336304289953
        },
        "modification_path": []
      },
      {
        "final_index": 73,
        "final_sentence": "Segmentation prevents cascade failure",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.21783887062753948,
          "refined": 0.22013063728809357,
          "draft": 0.15693646669387817
        },
        "modification_path": []
      },
      {
        "final_index": 74,
        "final_sentence": "Monolithic scripts fail monolithically",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.15927319559786055,
          "refined": 0.24735289812088013,
          "draft": 0.19394274055957794
        },
        "modification_path": []
      },
      {
        "final_index": 75,
        "final_sentence": "When several hundred lines break, everything breaks",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.24028968314329782,
          "refined": 0.2572835706747495,
          "draft": 0.1872890293598175
        },
        "modification_path": []
      },
      {
        "final_index": 76,
        "final_sentence": "Split into cells, failure becomes diagnostic rather than catastrophic",
        "origin_version": "edited",
        "origin_index": 72,
        "similarity_scores": {
          "edited": 0.31243635416030885,
          "refined": 0.31243635416030885,
          "draft": 0.18538290679454802
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.31243635416030885,
            "sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
          },
          {
            "version": "refined",
            "similarity": 0.31243635416030885,
            "sentence": "When something broke, the failure was isolated and fixable rather than poisoning the entire system"
          }
        ]
      },
      {
        "final_index": 77,
        "final_sentence": "Each checkpoint isolates problems before they compound",
        "origin_version": "edited",
        "origin_index": 71,
        "similarity_scores": {
          "edited": 0.3740638540341304,
          "refined": 0.4909908840289483,
          "draft": 0.29539525508880615
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.3740638540341304,
            "sentence": "Seven distinct stages, each with its own checkpoint"
          },
          {
            "version": "refined",
            "similarity": 0.4909908840289483,
            "sentence": "The checkpoints designed to catch problems before they cascaded"
          }
        ]
      },
      {
        "final_index": 78,
        "final_sentence": "What looked like organization turned out to be risk management",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.15875500440597534,
          "refined": 0.18594928298677715,
          "draft": 0.20784537659751046
        },
        "modification_path": []
      },
      {
        "final_index": 79,
        "final_sentence": "Patience requires visibility",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.1881987452507019,
          "refined": 0.1881987452507019,
          "draft": 0.17160135507583618
        },
        "modification_path": []
      },
      {
        "final_index": 80,
        "final_sentence": "Waiting becomes tolerable when you can see progress",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.1926325559616089,
          "refined": 0.1926325559616089,
          "draft": 0.18319815397262573
        },
        "modification_path": []
      },
      {
        "final_index": 81,
        "final_sentence": "Black boxes breed anxiety while progress messages build trust",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.27699771388010547,
          "refined": 0.27699771388010547,
          "draft": 0.22818498361495232
        },
        "modification_path": []
      },
      {
        "final_index": 82,
        "final_sentence": "The difference between \"frozen\" and \"processing\" isn't technical",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.20293465431998758,
          "refined": 0.20293465431998758,
          "draft": 0.20461566359908492
        },
        "modification_path": []
      },
      {
        "final_index": 83,
        "final_sentence": "It's psychological",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.17315468192100525,
          "refined": 0.14475175738334656,
          "draft": 0.15037940442562103
        },
        "modification_path": []
      },
      {
        "final_index": 84,
        "final_sentence": "Even a spinning icon that whispers occasionally beats silent uncertainty",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.17071083353625405,
          "refined": 0.1665125804788926,
          "draft": 0.20303240631307873
        },
        "modification_path": []
      },
      {
        "final_index": 85,
        "final_sentence": "Consistency enables confidence",
        "origin_version": "new_in_final",
        "origin_index": null,
        "similarity_scores": {
          "edited": 0.2765742582934243,
          "refined": 0.2765742582934243,
          "draft": 0.26066145300865173
        },
        "modification_path": []
      },
      {
        "final_index": 86,
        "final_sentence": "Results that vary aren't wrong, but they're hard to trust",
        "origin_version": "edited",
        "origin_index": 82,
        "similarity_scores": {
          "edited": 0.3115345637003581,
          "refined": 0.3115345637003581,
          "draft": 0.2605702877044678
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.3115345637003581,
            "sentence": "Reproducibility builds trust"
          },
          {
            "version": "refined",
            "similarity": 0.3115345637003581,
            "sentence": "Reproducibility builds trust"
          }
        ]
      },
      {
        "final_index": 87,
        "final_sentence": "Fourteen decimal places of overkill beats two decimal places of uncertainty",
        "origin_version": "edited",
        "origin_index": 45,
        "similarity_scores": {
          "edited": 0.3931752800941467,
          "refined": 0.3728929772263482,
          "draft": 0.22153021891911825
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.3931752800941467,
            "sentence": "All fourteen decimal points"
          },
          {
            "version": "refined",
            "similarity": 0.3728929772263482,
            "sentence": "Fourteen decimals on almost everything, far more precision than necessary, but it was there"
          }
        ]
      },
      {
        "final_index": 88,
        "final_sentence": "Reproducibility isn't about perfection",
        "origin_version": "edited",
        "origin_index": 82,
        "similarity_scores": {
          "edited": 0.4234529336293538,
          "refined": 0.4234529336293538,
          "draft": 0.3391752640406291
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.4234529336293538,
            "sentence": "Reproducibility builds trust"
          },
          {
            "version": "refined",
            "similarity": 0.4234529336293538,
            "sentence": "Reproducibility builds trust"
          },
          {
            "version": "draft",
            "similarity": 0.3391752640406291,
            "sentence": "The problem: reproducibility only exists if the environment is stable"
          }
        ]
      },
      {
        "final_index": 89,
        "final_sentence": "It's about knowing your measurements measure the same thing and provide reliable results",
        "origin_version": "edited",
        "origin_index": 75,
        "similarity_scores": {
          "edited": 0.32951198076760324,
          "refined": 0.3349881553649902,
          "draft": 0.24801411065790388
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.32951198076760324,
            "sentence": "The system could measure similarity and track attribution, but interpreting those measurements demanded contextual understanding that algorithms couldn't provide"
          },
          {
            "version": "refined",
            "similarity": 0.3349881553649902,
            "sentence": "For the first time, I had proof of what I'd suspected but couldn't measure"
          }
        ]
      },
      {
        "final_index": 90,
        "final_sentence": "I finally have what I originally asked for",
        "origin_version": "edited",
        "origin_index": 88,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.19736498792966206,
          "draft": 0.20034000703266688
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "I finally have what I originally asked for"
          }
        ]
      },
      {
        "final_index": 91,
        "final_sentence": "It has cells to measure trends over time and produces visualizations so you don't have to read a fourteen decimal dataset to make sense of it",
        "origin_version": "edited",
        "origin_index": 89,
        "similarity_scores": {
          "edited": 0.9358416199684143,
          "refined": 0.2273774610625373,
          "draft": 0.1947505417707804
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 0.9358416199684143,
            "sentence": "It has cells to measure trends over time, it produces visualizations so you don't have to read a fourteen decimal dataset to make sense of it"
          }
        ]
      },
      {
        "final_index": 92,
        "final_sentence": "It's version 1.3",
        "origin_version": "edited",
        "origin_index": 90,
        "similarity_scores": {
          "edited": 1.0,
          "refined": 0.19761973917484282,
          "draft": 0.26922642191251117
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0,
            "sentence": "It's version 1.3"
          }
        ]
      },
      {
        "final_index": 93,
        "final_sentence": "That's where the final article begins.",
        "origin_version": "edited",
        "origin_index": 91,
        "similarity_scores": {
          "edited": 1.0000000596046448,
          "refined": 1.0000000596046448,
          "draft": 0.23484628186339424
        },
        "modification_path": [
          {
            "version": "edited",
            "similarity": 1.0000000596046448,
            "sentence": "That's where the final article begins."
          },
          {
            "version": "refined",
            "similarity": 1.0000000596046448,
            "sentence": "That's where the final article begins."
          }
        ]
      }
    ],
    "statistics": {
      "total_sentences": 94,
      "origin_distribution": {
        "new_in_final": {
          "count": 16,
          "percentage": 17.02127659574468
        },
        "edited": {
          "count": 77,
          "percentage": 81.91489361702128
        },
        "refined": {
          "count": 1,
          "percentage": 1.0638297872340425
        }
      },
      "modification_distribution": {
        "high_similarity": {
          "count": 52,
          "percentage": 55.319148936170215
        },
        "medium_similarity": {
          "count": 12,
          "percentage": 12.76595744680851
        },
        "low_similarity": {
          "count": 14,
          "percentage": 14.893617021276595
        },
        "new_content": {
          "count": 16,
          "percentage": 17.02127659574468
        }
      }
    },
    "analysis_timestamp": "2025-11-01T02:49:52.276369",
    "similarity_threshold": 0.3
  }
}