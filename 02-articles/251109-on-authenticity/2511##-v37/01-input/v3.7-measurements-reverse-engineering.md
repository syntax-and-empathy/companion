# v3.7 Detection Measurements - Reverse Engineering Guide

## Purpose
Document EXACTLY how v3.7 measures each feature, so humanizer transformations can target the precise measurements.

---

## 1. BURSTINESS (Module 2 - NLTK)

### v3.7 Measurement:
```python
def _cv(vals):  # vals = list of tokens_per_sentence
    mu = statistics.mean(vals)
    if mu == 0 or len(vals) < 2: return nan
    return statistics.pstdev(vals) / mu  # population std dev / mean
```

**Formula:** `CV = std(tokens_per_sentence) / mean(tokens_per_sentence)`

**Detection Thresholds:**
- AI text: CV < 0.4 (very uniform sentence lengths)
- Human text: CV 0.5-0.6 (moderate variation)

### What Humanizer Must Do:
- Create sentence length DISTRIBUTION with CV â‰ˆ 0.55
- Example: Mix of 5-word, 15-word, 25-word sentences
- **Current problem:** Only splits long sentences, doesn't create distribution

---

## 2. SUBORDINATION (Module 3 - spaCy)

### v3.7 Measurement:
```python
# Count tokens with these dependency labels:
SUBORD_SET = {"mark","advcl","ccomp","xcomp","acl","relcl","csubj","csubjpass","csubj:pass"}

# Per sentence:
subord_count = 0
for token in sentence_tokens:
    dep = token.dep_.lower()
    if dep == "acl":
        # Only count as subord if it's a relative clause
        if "Relcl=Yes" in str(token.morph).lower():
            subord_count += 1
    if dep in SUBORD_SET:
        subord_count += 1

# Doc level:
subord_rate = total_subord_tokens / total_doc_tokens
```

**Detection Thresholds:**
- AI text: Low subordination rate, coord/subord ratio ~ 2.0 (more coordination)
- Human text: Balanced, coord/subord ratio ~ 1.0

### What Humanizer Must Do:
- Create structures that spaCy parses with subordination labels
- **Current problem:** Just prepending "While", "As" - doesn't create proper dependencies
- **Need:** Actual clause restructuring that creates `mark`, `advcl`, `ccomp` dependencies

**Example transformation:**
```
WRONG: "As the solution isn't..." (broken grammar, no mark/advcl)
RIGHT: "Because X happened, Y resulted" (creates mark + advcl dependencies)
```

---

## 3. COORDINATION (Module 3 - spaCy)

### v3.7 Measurement:
```python
COORD_SET = {"cc","conj","parataxis"}

coord_count = sum(1 for token in tokens if token.dep_.lower() in COORD_SET)
coord_rate = coord_count / total_tokens
```

**Detection Thresholds:**
- AI text: Higher coordination (lists, "and" chains)
- Human text: Lower coordination, more subordination

### What Humanizer Must Do:
- **DECREASE** coordination by converting "X and Y" to "Because X, Y"
- Must create structures spaCy doesn't label as `cc` or `conj`

---

## 4. PARSE DEPTH (Module 3 - spaCy)

### v3.7 Measurement:
```python
# For each token in sentence:
def get_depth(token):
    depth = 0
    current = token
    root = sentence.root
    while current != root and depth <= 80:
        current = current.head
        depth += 1
    return depth

# Sentence depth = max depth of any token
sentence_depth = max(get_depth(t) for t in sentence_tokens)

# Doc stats:
mean_depth = mean(sentence_depths)
```

**Detection Thresholds:**
- AI text: depth 4-5 (shallow trees)
- Human text: depth 6-8 (deeper nesting)

### What Humanizer Must Do:
- Add nested structures that increase dependency distance
- **Current problem:** Randomly combining sentences doesn't necessarily increase depth
- **Need:** Add relative clauses, embedded clauses that create deeper trees

**Example:**
```
SHALLOW: "The system works well."  (depth ~3)
DEEPER: "The system, which processes data efficiently, works well." (depth ~5-6)
```

---

## 5. ZIPF FREQUENCY (Module 1 - wordfreq)

### v3.7 Measurement:
```python
from wordfreq import zipf_frequency

# For each token:
zipf = zipf_frequency(token.lower(), 'en', wordlist='best')

# Doc stats:
zipf_mean = mean(all_token_zipf_scores)
```

**Detection Thresholds:**
- AI text: zipf_mean > 6.2 (very common words)
- Human text: zipf_mean 5.0-5.5 (mix of common and rarer words)

### What Humanizer Must Do:
- Replace high-frequency words (Zipf > 6.0) with synonyms (Zipf 4.5-5.5)
- **Current problem:** Not checking if synonym fits semantically/grammatically
- **Need:** Validate replacement with sentence-transformers similarity

---

## KEY INSIGHTS

1. **All measurements use spaCy's parsing** - We must create structures spaCy recognizes, not just add words
2. **Rates are per-token** - Counts divided by total tokens
3. **Dependencies matter** - Just adding conjunctions doesn't work if they don't create the right dependency labels
4. **Validate with v3.7** - After each transformation, run through v3.7's measurement functions to verify

---

## NEXT STEPS FOR HUMANIZER

1. **Disable current broken transformations**
2. **Rewrite subordination:** Actually restructure clauses to create `mark`/`advcl` dependencies
3. **Rewrite burstiness:** Create sentence length distributions, not just split
4. **Rewrite parse depth:** Add nested clauses that increase dependency distance
5. **Rewrite Zipf:** Validate semantic similarity of each replacement
6. **Test against v3.7:** Run humanized text through v3.7 to verify metrics move correctly
