{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtrekell/soylent-army/blob/main/colab/ai_vs_human_v1.4c.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf9243b",
      "metadata": {
        "id": "5bf9243b"
      },
      "source": [
        "# ai_vs_human_v1.4c.3 — Analyzer\n",
        "\n",
        "Updated per your specifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7479ce0d",
      "metadata": {
        "id": "7479ce0d"
      },
      "outputs": [],
      "source": [
        "# CELL 1: This cell installs the necessary Python libraries for the project using pip.\n",
        "# %%capture --no-display: This is a cell magic that captures the standard output and standard error of the cell and prevents it from being displayed. This is used here to hide the detailed output of the pip install command, while still allowing progress bars (if any are shown by the installed packages) to be displayed.\n",
        "# %pip install -q: This is a line magic that runs the pip install command. The -q flag stands for \"quiet\", which reduces the verbosity of the output.\n",
        "# The rest of the line lists the specific libraries and their versions to be installed.\n",
        "\n",
        "# In summary, this cell ensures that all required libraries are installed with minimal output shown, except for potential progress bars during the installation process.\n",
        "\n",
        "%%capture --no-display\n",
        "%pip install -q \"markdown-it-py[linkify]==3.0.0\" \"linkify-it-py==2.0.3\" \\\n",
        "                \"sentence-transformers==3.0.1\" \"scikit-learn>=1.6.1\" \\\n",
        "                \"beautifulsoup4==4.12.3\" \"lxml==5.2.2\" \\\n",
        "                \"rapidfuzz==3.9.6\" \"pandas==2.2.2\" \"numpy>=2.0.0,<2.3.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "26c60479",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c60479",
        "outputId": "31617f3b-3cf7-4c8c-c032-9024c5546488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ai_vs_human_v1.4c.3 configuration loaded.\n"
          ]
        }
      ],
      "source": [
        "# CELL 2: This cell imports several Python libraries and defines helper functions for processing and analyzing text data, along with a configuration class.\n",
        "\n",
        "# Imports: It imports necessary libraries like pathlib, os, re, json, glob, time, numpy, pandas, BeautifulSoup (for parsing HTML), MarkdownIt (for parsing Markdown), SentenceTransformer (for creating sentence embeddings), TfidfVectorizer and cosine_similarity from sklearn (for TF-IDF analysis and similarity), and Levenshtein from rapidfuzz (for calculating edit distance). It also imports tqdm.autonotebook.tqdm for progress bars and suppresses a related warning.\n",
        "# MarkdownIt and md_to_text: Initializes a Markdown parser and defines a function md_to_text to convert Markdown strings to plain text using BeautifulSoup.\n",
        "# split_sentences: Defines a function to split a given text into a list of sentences based on punctuation and spacing.\n",
        "# tokenize: Defines a function to tokenize text by converting it to lowercase, removing non-alphanumeric characters, and splitting it into words.\n",
        "# jaccard: Defines a function to calculate the Jaccard similarity between two sets of tokens.\n",
        "# modification_label_for: Defines a function to categorize the degree of modification (\"unchanged\", \"minor\", or \"major\") based on a similarity score and defined thresholds.\n",
        "# Config class: Defines a class to hold configuration parameters such as data and output directories, the name of the sentence transformer model, parameters for candidate selection and similarity weighting, thresholds for modification labels, and file patterns for different document versions.\n",
        "# Constants: Defines constants for the order of document versions (VERSION_ORDER), display names for versions (DISPLAY_NAME), and labels for modifications (MOD_LABELS).\n",
        "\n",
        "# In essence, this cell sets up the tools and configurations needed for the subsequent steps of loading, processing, and comparing different versions of text documents.\n",
        "\n",
        "from pathlib import Path\n",
        "import os, re, json, glob, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from markdown_it import MarkdownIt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rapidfuzz.distance import Levenshtein\n",
        "\n",
        "# Let tqdm use notebook mode (keeps progress bars visible in Colab/Jupyter).\n",
        "# Suppress the \"ExperimentalWarning\" so you don't see the noisy message.\n",
        "import warnings\n",
        "from tqdm.autonotebook import tqdm\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
        "\n",
        "md = MarkdownIt(\"commonmark\", {})\n",
        "def md_to_text(md_str: str) -> str:\n",
        "    html = md.render(md_str or \"\")\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    text = soup.get_text(\" \")\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "def split_sentences(text: str) -> list:\n",
        "    if not text:\n",
        "        return []\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    parts = re.split(r\"(?<=[.!?])\\s+(?=[\\(\\\"\\'A-Z0-9])\", text)\n",
        "    return [p.strip() for p in parts if p and not p.isspace()]\n",
        "\n",
        "def tokenize(text: str) -> list:\n",
        "    if not text:\n",
        "        return []\n",
        "    text = text.lower()\n",
        "    # Replace non-alphanumeric characters with spaces\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text.split()\n",
        "\n",
        "def jaccard(tokens_a, tokens_b) -> float:\n",
        "    if not tokens_a and not tokens_b:\n",
        "        return 1.0\n",
        "    A, B = set(tokens_a), set(tokens_b)\n",
        "    if not A and not B:\n",
        "        return 1.0\n",
        "    if not A or not B:\n",
        "        return 0.0\n",
        "    return len(A & B) / float(len(A | B))\n",
        "\n",
        "def modification_label_for(sim: float, th_unchanged=0.9, th_minor=0.7) -> str:\n",
        "    if sim >= th_unchanged:\n",
        "        return \"unchanged\"\n",
        "    if sim >= th_minor:\n",
        "        return \"minor\"\n",
        "    return \"major\"\n",
        "\n",
        "class Config:\n",
        "    data_dir = \"./data\"\n",
        "    out_dir = \"./output\"\n",
        "    model_name = \"all-MiniLM-L6-v2\"\n",
        "    topk_candidates = 10\n",
        "    weight_semantic = 0.6\n",
        "    weight_tfidf = 0.4\n",
        "    unchanged_threshold = 0.90\n",
        "    minor_change_threshold = 0.70\n",
        "    patterns = {\"draft\":\"draft*.md\",\"refined\":\"refined*.md\",\"edited\":\"edited*.md\",\"final\":\"final*.md\"}\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "VERSION_ORDER = [\"draft\", \"refined\", \"edited\", \"final\"]\n",
        "DISPLAY_NAME  = {\"draft\":\"Draft\",\"refined\":\"Refined\",\"edited\":\"Edited\",\"final\":\"Final\"}\n",
        "MOD_LABELS    = [\"unchanged\",\"minor\",\"major\"]\n",
        "\n",
        "print(\"ai_vs_human_v1.4c.3 configuration loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d9f2ec4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9f2ec4e",
        "outputId": "8a37e13a-96d7-42c9-a521-f2e2e9e0e05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discovered 1 article location(s).\n",
            " - data\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: This cell contains functions for loading and discovering article data, and then uses them to find and list the available article locations.\n",
        "\n",
        "# read_first_match(folder: Path, pattern: str): This function takes a folder path and a file pattern as input. It searches the folder for files matching the pattern, sorts them, and reads the content of the first matching file. If no files are found, it returns None.\n",
        "# load_versions(article_folder: Path): This function takes an article folder path and uses the read_first_match function to load the content of different versions (draft, refined, edited, final) of an article based on predefined file patterns in the cfg.patterns dictionary. It returns a dictionary where keys are version names and values are the loaded content (or None if no file was found for a version).\n",
        "# to_sentences(md_content: str) -> list: This function takes Markdown content as input, converts it to plain text using md_to_text (defined in a previous cell), and then splits the text into a list of sentences using split_sentences (also defined previously).\n",
        "# discover_articles(data_dir: str): This function takes a data directory path, ensures the directory exists, and then finds all subdirectories within it. These subdirectories are considered as individual \"article locations\". If no subdirectories are found, it returns a list containing the data directory itself.\n",
        "# articles = discover_articles(cfg.data_dir): This line calls the discover_articles function with the data directory specified in the configuration (cfg.data_dir) to find all article locations.\n",
        "# The subsequent print statements display the number of discovered article locations and list each one.\n",
        "\n",
        "# In summary, this cell sets up the functions to handle the loading of different article versions and then identifies where these articles are located within the specified data directory.\n",
        "\n",
        "def read_first_match(folder: Path, pattern: str):\n",
        "    files = sorted(folder.glob(pattern))\n",
        "    if not files:\n",
        "        return None\n",
        "    return files[0].read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "def load_versions(article_folder: Path):\n",
        "    data = {}\n",
        "    for v in VERSION_ORDER:\n",
        "        pattern = cfg.patterns.get(v)\n",
        "        if not pattern:\n",
        "            data[v] = None\n",
        "            continue\n",
        "        content = read_first_match(article_folder, pattern)\n",
        "        data[v] = content\n",
        "    return data\n",
        "\n",
        "def to_sentences(md_content: str) -> list:\n",
        "    return split_sentences(md_to_text(md_content or \"\"))\n",
        "\n",
        "def discover_articles(data_dir: str):\n",
        "    base = Path(data_dir)\n",
        "    if not base.exists():\n",
        "        base.mkdir(parents=True, exist_ok=True)  # ensure the folder exists\n",
        "    folders = [p for p in base.iterdir() if p.is_dir()]\n",
        "    if not folders:\n",
        "        return [base]\n",
        "    return folders\n",
        "\n",
        "articles = discover_articles(cfg.data_dir)\n",
        "print(f\"Discovered {len(articles)} article location(s).\")\n",
        "for a in articles:\n",
        "    print(' -', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "94d8d28e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94d8d28e",
        "outputId": "0c8dbc7d-d4ed-4efa-c69e-8777bc40be12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embedding model: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# CELL 4:This code cell loads a pre-trained sentence transformer model and initializes a TF-IDF vectorizer, which are both used for calculating text similarity later in the notebook.\n",
        "\n",
        "# print(\"Loading embedding model:\", cfg.model_name): This line prints a message indicating which sentence embedding model is being loaded, using the model name specified in the cfg (Config) object.\n",
        "# st_model = SentenceTransformer(cfg.model_name): This line initializes a SentenceTransformer model with the specified model name. This model will be used to convert sentences into numerical vectors (embeddings) that capture their semantic meaning.\n",
        "# def embed_sentences(sentences: list[str]) -> np.ndarray:: This function takes a list of sentences and uses the loaded st_model to generate embeddings for each sentence. It returns a NumPy array of these embeddings. If the input list is empty, it returns an empty array with the expected shape and data type.\n",
        "# tfidf = TfidfVectorizer(min_df=1, ngram_range=(1,2)): This line initializes a TfidfVectorizer. This tool is used to convert a collection of raw documents into a matrix of TF-IDF features. min_df=1 means that terms that appear in less than 1 document will be ignored. ngram_range=(1,2) means that both unigrams (single words) and bigrams (two-word phrases) will be considered as features.\n",
        "\n",
        "# In summary, this cell prepares the necessary models and tools for semantic and TF-IDF based similarity calculations between sentences.\n",
        "\n",
        "print(\"Loading embedding model:\", cfg.model_name)\n",
        "st_model = SentenceTransformer(cfg.model_name)\n",
        "\n",
        "def embed_sentences(sentences: list[str]) -> np.ndarray:\n",
        "    if not sentences:\n",
        "        return np.empty((0, 384), dtype=np.float32)\n",
        "    return np.array(st_model.encode(sentences, show_progress_bar=False), dtype=np.float32)\n",
        "\n",
        "tfidf = TfidfVectorizer(min_df=1, ngram_range=(1,2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "453bee10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "453bee10",
        "outputId": "f3b2f731-918d-4a02-8f6f-88d426094157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer ready.\n"
          ]
        }
      ],
      "source": [
        "## CELL 5: This code cell defines the main analysis function analyze_article which compares sentences from a \"final\" version of an article to earlier versions (draft, refined, edited) to determine how much each final sentence has been modified and attribute it to an origin version.\n",
        "\n",
        "# Load Versions: It first loads the content of the different article versions using the load_versions function. If there's no \"final\" version, it skips the analysis for that article.\n",
        "# Convert to Sentences: It converts the content of each version into a list of sentences using the to_sentences function. It also skips the analysis if the \"final\" version has no sentences.\n",
        "# Prepare Candidates: It creates a combined list of all sentences from the \"draft\", \"refined\", and \"edited\" versions, along with metadata (version and index) for each candidate sentence.\n",
        "# TF-IDF Vectorization: It fits a TfidfVectorizer on all sentences (final and candidates) to generate TF-IDF representations.\n",
        "# Sentence Embedding: It generates sentence embeddings for both the final sentences and the candidate sentences using the loaded SentenceTransformer model.\n",
        "# Iterate and Compare: It iterates through each sentence in the \"final\" version:\n",
        "# Calculates semantic similarity (cosine similarity of embeddings) and TF-IDF similarity between the current final sentence and all candidate sentences.\n",
        "# If there are no candidates, it records the final sentence with None values for origin and similarity metrics.\n",
        "# Calculates a combined similarity score (weighted average of semantic and TF-IDF similarity).\n",
        "# Identifies the top-k candidate sentences with the highest combined similarity.\n",
        "# For the top candidates, it calculates Jaccard similarity (token overlap) and Levenshtein ratio (edit distance).\n",
        "# Calculates a final combined score using a weighted average of the fast combined similarity, Jaccard, and Levenshtein ratio.\n",
        "# Identifies the candidate sentence with the highest final combined score as the \"best\" match.\n",
        "# Records the details of the final sentence and its best matching origin sentence (or None if no suitable candidate was found), including various similarity scores and a \"modification label\" (\"unchanged\", \"minor\", or \"major\") based on the final combined score and defined thresholds.\n",
        "# Generate Output: After processing all final sentences, it creates a pandas DataFrame from the collected data. It also calculates the distribution of origin versions and modification labels.\n",
        "# Save Results: It saves the detailed results to a CSV file and a JSON file in the output directory specified in the configuration. It also saves a separate JSON file with footer metrics like execution time and comparison counts.\n",
        "# Print Diagnostic: Finally, it prints a plain-English diagnostic message summarizing the analysis results, including the number of sentences analyzed, heavy comparisons performed, and an interpretation of the heavy comparison count relative to the top-k setting.\n",
        "\n",
        "# The function returns a dictionary containing the name of the article and the paths to the generated output files.\n",
        "\n",
        "def analyze_article(article_path: Path):\n",
        "    versions = load_versions(article_path)\n",
        "    if not versions.get(\"final\"):\n",
        "        print(f\"[SKIP] No final*.md found in {article_path}.\")\n",
        "        return None\n",
        "\n",
        "    sents = {v: to_sentences(versions.get(v) or \"\") for v in VERSION_ORDER}\n",
        "    final_sents = sents[\"final\"]\n",
        "    if not final_sents:\n",
        "        print(f\"[SKIP] No sentences produced for Final in {article_path}.\")\n",
        "        return None\n",
        "\n",
        "    candidate_versions = [\"draft\", \"refined\", \"edited\"]\n",
        "    candidates, cand_meta = [], []\n",
        "    for v in candidate_versions:\n",
        "        for idx, sent in enumerate(sents.get(v, [])):\n",
        "            candidates.append(sent); cand_meta.append((v, idx))\n",
        "\n",
        "    all_for_tfidf = final_sents + candidates\n",
        "    tfidf_matrix = tfidf.fit_transform(all_for_tfidf)\n",
        "    tfidf_final = tfidf_matrix[:len(final_sents)]\n",
        "    tfidf_cands = tfidf_matrix[len(final_sents):]\n",
        "\n",
        "    emb_final = embed_sentences(final_sents)\n",
        "    emb_cands = embed_sentences(candidates)\n",
        "\n",
        "    rows = []\n",
        "    heavy_calls = 0\n",
        "    t_heavy0 = time.perf_counter()\n",
        "\n",
        "    for f_idx, f_sent in enumerate(final_sents):\n",
        "        sem_sim = cosine_similarity(emb_final[f_idx:f_idx+1], emb_cands).ravel() if emb_cands.shape[0] > 0 else np.array([])\n",
        "        tfidf_sim = cosine_similarity(tfidf_final[f_idx:f_idx+1], tfidf_cands).ravel() if tfidf_cands.shape[0] > 0 else np.array([])\n",
        "        if sem_sim.size == 0 or tfidf_sim.size == 0:\n",
        "            rows.append({\n",
        "                \"final_index\": f_idx,\n",
        "                \"final_sentence\": f_sent,\n",
        "                \"origin_version\": None,\n",
        "                \"origin_index\": None,\n",
        "                \"origin_sentence\": None,\n",
        "                \"semantic_sim\": None,\n",
        "                \"tfidf_sim\": None,\n",
        "                \"jaccard\": None,\n",
        "                \"levenshtein\": None,\n",
        "                \"combined_sim\": 0.0,\n",
        "                \"modification_label\": modification_label_for(0.0, cfg.unchanged_threshold, cfg.minor_change_threshold),\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        combined_fast = cfg.weight_semantic * sem_sim + cfg.weight_tfidf * tfidf_sim\n",
        "        topk = min(cfg.topk_candidates, combined_fast.shape[0])\n",
        "        cand_idx = np.argpartition(-combined_fast, kth=topk-1)[:topk]\n",
        "\n",
        "        f_tokens = tokenize(f_sent)\n",
        "        best_score = -1.0\n",
        "        best = None\n",
        "        for ci in cand_idx:\n",
        "            c_sent = candidates[ci]\n",
        "            c_tokens = tokenize(c_sent)\n",
        "            A = set(f_tokens); B = set(c_tokens)\n",
        "            jac = 0.0 if (not A or not B) else len(A & B)/float(len(A | B))\n",
        "            max_len = max(len(f_sent), len(c_sent)) or 1\n",
        "            lev_dist = Levenshtein.distance(f_sent, c_sent)\n",
        "            lev_ratio = 1.0 - (lev_dist / max_len)\n",
        "            heavy_calls += 1\n",
        "            score = 0.7 * combined_fast[ci] + 0.2 * jac + 0.1 * lev_ratio\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best = (ci, jac, lev_ratio, combined_fast[ci])\n",
        "\n",
        "        if best is None:\n",
        "            rows.append({\n",
        "                \"final_index\": f_idx,\n",
        "                \"final_sentence\": f_sent,\n",
        "                \"origin_version\": None,\n",
        "                \"origin_index\": None,\n",
        "                \"origin_sentence\": None,\n",
        "                \"semantic_sim\": float(np.max(sem_sim)),\n",
        "                \"tfidf_sim\": float(np.max(tfidf_sim)),\n",
        "                \"jaccard\": None,\n",
        "                \"levenshtein\": None,\n",
        "                \"combined_sim\": float(np.max(combined_fast)),\n",
        "                \"modification_label\": modification_label_for(float(np.max(combined_fast)), cfg.unchanged_threshold, cfg.minor_change_threshold),\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        ci, jac, lev_ratio, fast_keep = best\n",
        "        origin_version, origin_index = cand_meta[ci]\n",
        "        origin_sentence = candidates[ci]\n",
        "        final_combined = max(0.0, min(1.0, best_score))\n",
        "        label = modification_label_for(final_combined, cfg.unchanged_threshold, cfg.minor_change_threshold)\n",
        "\n",
        "        rows.append({\n",
        "            \"final_index\": f_idx,\n",
        "            \"final_sentence\": f_sent,\n",
        "            \"origin_version\": origin_version,\n",
        "            \"origin_index\": int(origin_index),\n",
        "            \"origin_sentence\": origin_sentence,\n",
        "            \"semantic_sim\": float(sem_sim[ci]),\n",
        "            \"tfidf_sim\": float(tfidf_sim[ci]),\n",
        "            \"jaccard\": float(jac),\n",
        "            \"levenshtein\": float(lev_ratio),\n",
        "            \"combined_sim\": float(final_combined),\n",
        "            \"modification_label\": label,\n",
        "        })\n",
        "\n",
        "    t_heavy1 = time.perf_counter()\n",
        "    avg_heavy_per_final = heavy_calls / max(1, len(final_sents))\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    origin_dist = (df[\"origin_version\"].fillna(\"none\").value_counts(normalize=True)\n",
        "                   .reindex([\"draft\",\"refined\",\"edited\",\"none\"], fill_value=0.0).to_dict())\n",
        "    mod_dist = (df[\"modification_label\"].fillna(\"major\").value_counts(normalize=True)\n",
        "                .reindex([\"unchanged\",\"minor\",\"major\"], fill_value=0.0).to_dict())\n",
        "\n",
        "    article_name = article_path.name if article_path.is_dir() else Path(cfg.data_dir).name\n",
        "\n",
        "    out_dir = Path(cfg.out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    csv_path    = out_dir / f\"{article_name}_final_sentence_attribution.csv\"\n",
        "    json_path   = out_dir / f\"{article_name}_complete_summary.json\"\n",
        "    footer_path = out_dir / f\"{article_name}_footer_metrics.json\"\n",
        "\n",
        "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    payload = {\n",
        "        \"version\": \"1.4c.3\",\n",
        "        \"article_name\": article_name,\n",
        "        \"config\": {\n",
        "            \"model_name\": cfg.model_name,\n",
        "            \"topk_candidates\": cfg.topk_candidates,\n",
        "            \"weights\": {\"semantic\": cfg.weight_semantic, \"tfidf\": cfg.weight_tfidf},\n",
        "            \"unchanged_threshold\": cfg.unchanged_threshold,\n",
        "            \"minor_change_threshold\": cfg.minor_change_threshold,\n",
        "        },\n",
        "        \"summary\": {\n",
        "            \"origin_distribution\": origin_dist,\n",
        "            \"modification_distribution\": mod_dist,\n",
        "            \"counts\": {\n",
        "                \"sentences_final\": int(len(final_sents)),\n",
        "                \"heavy_comparisons\": int(heavy_calls),\n",
        "                \"avg_heavy_per_final\": float(avg_heavy_per_final),\n",
        "            }\n",
        "        },\n",
        "        \"rows\": rows\n",
        "    }\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    footer = {\n",
        "        \"article_name\": article_name,\n",
        "        \"version\": \"1.4c.3\",\n",
        "        \"elapsed_heavy_seconds\": float(t_heavy1 - t_heavy0),\n",
        "        \"counts\": payload[\"summary\"][\"counts\"]\n",
        "    }\n",
        "    with open(footer_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(footer, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Plain-English Diagnostic\n",
        "    msg = []\n",
        "    msg.append(f\"Analysis completed for '{article_name}'.\")\n",
        "    msg.append(f\"- Final sentences analyzed: {len(final_sents)}\")\n",
        "    msg.append(f\"- Heavy comparisons executed: {heavy_calls}\")\n",
        "    msg.append(f\"- Average heavy comparisons per final sentence: {avg_heavy_per_final:.2f}\")\n",
        "    msg.append(\"Interpretation:\")\n",
        "    if len(candidates) == 0:\n",
        "        msg.append(\"• No Draft/Refined/Edited candidates found. Origins are unspecified and heavy metrics were skipped where possible.\")\n",
        "    else:\n",
        "        k = cfg.topk_candidates\n",
        "        if avg_heavy_per_final <= k * 1.2:\n",
        "            msg.append(f\"• Close to top‑k (k={k}). Heavy metrics are gated to the shortlist as intended.\")\n",
        "        else:\n",
        "            msg.append(f\"• Higher than expected for top‑k={k}. Consider verifying the loop only iterates over top‑k indices or lowering k.\")\n",
        "    msg.append(f\"Outputs written to: {out_dir}\")\n",
        "    print(\"\\n\".join(msg))\n",
        "\n",
        "    return {\n",
        "        \"article_name\": article_name,\n",
        "        \"csv\": str(csv_path),\n",
        "        \"json\": str(json_path),\n",
        "        \"footer\": str(footer_path)\n",
        "    }\n",
        "\n",
        "print(\"Analyzer ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "33b742ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33b742ba",
        "outputId": "f18a1b5c-c021-4d31-f031-b586e892cf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis completed for 'data'.\n",
            "- Final sentences analyzed: 103\n",
            "- Heavy comparisons executed: 1030\n",
            "- Average heavy comparisons per final sentence: 10.00\n",
            "Interpretation:\n",
            "• Close to top‑k (k=10). Heavy metrics are gated to the shortlist as intended.\n",
            "Outputs written to: output\n",
            "\n",
            "Summary of outputs:\n",
            "- data -> JSON: output/data_complete_summary.json | CSV: output/data_final_sentence_attribution.csv\n"
          ]
        }
      ],
      "source": [
        "## CELL 6: This code snippet iterates through a list of article locations (articles), runs the analyze_article function on each location, and collects the results.\n",
        "\n",
        "# results = []: Initializes an empty list to store the analysis results for each article.\n",
        "# for art in articles:: This loop iterates through each item in the articles list. Based on the previous cell's output, articles contains the path to the data directory (./data).\n",
        "# res = analyze_article(art): Calls the analyze_article function for the current article location (art). This function performs the core analysis of comparing document versions.\n",
        "# if res:: Checks if the analyze_article function returned a result. The function returns None if no \"final\" version is found or if the \"final\" version has no sentences.\n",
        "# results.append(res): If analyze_article returned a result (meaning the analysis was performed), the result is added to the results list.\n",
        "# if not results:: After the loop finishes, this checks if the results list is empty. This would happen if analyze_article returned None for all article locations.\n",
        "# print(\"No outputs produced. Ensure your ./data contains expected markdown files.\"): If results is empty, this message is printed, indicating that no analysis was completed.\n",
        "# else:: If results is not empty, the code in this block is executed.\n",
        "# print(\"\\nSummary of outputs:\"): Prints a header for the summary.\n",
        "# for r in results:: This loop iterates through each result dictionary stored in the results list.\n",
        "# print(f\"- {r['article_name']} -> JSON: {r['json']} | CSV: {r['csv']}\"): For each result, it prints a formatted string showing the article name and the paths to the generated JSON and CSV output files.\n",
        "\n",
        "# In summary, this code orchestrates the analysis process for all discovered article locations and then provides a summary of the generated output files.\n",
        "\n",
        "results = []\n",
        "for art in articles:\n",
        "    res = analyze_article(art)\n",
        "    if res:\n",
        "        results.append(res)\n",
        "\n",
        "if not results:\n",
        "    print(\"No outputs produced. Ensure your ./data contains expected markdown files.\")\n",
        "else:\n",
        "    print(\"\\nSummary of outputs:\")\n",
        "    for r in results:\n",
        "        print(f\"- {r['article_name']} -> JSON: {r['json']} | CSV: {r['csv']}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}